<!-- build time:Wed Jan 22 2020 17:55:48 GMT+0800 (China Standard Time) --><!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="google-site-verification" content="DO25iswIsaKZ5NZbYreVDjWtBKTyo1yFAROjSRcJD64"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css"><link href="//fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Aitozi" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2"><meta name="description" content="What makes a difference? Persistence!"><meta property="og:type" content="website"><meta property="og:title" content="Aitozi"><meta property="og:url" content="http://www.aitozi.com/page/2/index.html"><meta property="og:site_name" content="Aitozi"><meta property="og:description" content="What makes a difference? Persistence!"><meta property="og:locale" content="zh-Hans"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Aitozi"><meta name="twitter:description" content="What makes a difference? Persistence!"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post",offset:12,offset_float:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:!0,duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://www.aitozi.com/page/2/"><title>Aitozi</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Aitozi</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description"></h1></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-timerservice-based-on-rocksdb-2.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-timerservice-based-on-rocksdb-2.html" itemprop="url">下篇·flink基于rocksdb的timerService</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T12:13:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-timerservice-based-on-rocksdb-2.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-timerservice-based-on-rocksdb-2.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">2.2k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">9</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>接上文分析，要将timer改成基于rocksdb，其实就是要对存储timer的set和queue提供基于rocksdb的存储方案。以下我们基于flink1.7版本源码分析</p><p>&lt;!--more--&gt;</p><p><strong>registerProcessingTimeTimer</strong></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public void registerProcessingTimeTimer(N namespace, long time) &#123;</span><br><span class="line">	InternalTimer&lt;K, N&gt; oldHead = processingTimeTimersQueue.peek();</span><br><span class="line">	if (processingTimeTimersQueue.add(new TimerHeapInternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace))) &#123;</span><br><span class="line">		long nextTriggerTime = oldHead != null ? oldHead.getTimestamp() : Long.MAX_VALUE;</span><br><span class="line">		// check if we need to re-schedule our timer to earlier</span><br><span class="line">		// 如果新加入的timer的时间更早触发，那么就需要把先前的timer取消</span><br><span class="line">		if (time &lt; nextTriggerTime) &#123;</span><br><span class="line">			if (nextTimer != null) &#123;</span><br><span class="line">				nextTimer.cancel(false);</span><br><span class="line">			&#125;</span><br><span class="line">			nextTimer = processingTimeService.registerTimer(time, this);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以和看到1.4版本中的基本逻辑是一致的，只是存储方式变化了，下面我们就来分析一下新的存储方式是怎么实现的。在存储的选择上依然有Heap和RocksDB两个方式</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">switch (priorityQueueStateType) &#123;</span><br><span class="line">			case HEAP:</span><br><span class="line">				this.priorityQueueFactory = new HeapPriorityQueueSetFactory(keyGroupRange, numberOfKeyGroups, 128);</span><br><span class="line">				break;</span><br><span class="line">			case ROCKSDB:</span><br><span class="line">				this.priorityQueueFactory = new RocksDBPriorityQueueSetFactory();</span><br><span class="line">				break;</span><br><span class="line">			default:</span><br><span class="line">				throw new IllegalArgumentException(&quot;Unknown priority queue state type: &quot; + priorityQueueStateType);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><p>从timerService的需求来看我们可以看到这样的几个需求：</p><ol><li>能够每次poll出最近需要触发的timer，实际上是需要维护一个小顶堆</li><li>能够对每一个key的timer去重</li></ol><p>针对这两个需求，总体来看基于Heap的实现是通过基于数组实现了一个二叉堆，具体实现类为<code>HeapPriorityQueue</code>, 然后针对去重的功能又继承该<code>PQ</code>，通过一个hashmap数组，数组的每一个元素代表一个KG的一组不重复timer，同时这组timer内部也维护了timer在二叉堆中存储的下标，方便<code>deleteTimer</code>时的快速删除。</p><h4>基于Heap的实现</h4><p><code>HeapPriorityQueueElement</code>,<code>AbstractHeapPriorityQueue</code>,<code>HeapPriorityQueue</code>,<code>HeapPriorityQueueSet</code></p><ol><li>存储基于数组，通过<code>HeapPriorityQueueElement</code>记录自己所在的index，可以达到快速删除的目的</li><li>数组中存储的是一个二叉树，数组的起始位置是从1开始，为了使一些热点方法做更少的计算</li></ol><p>在实现上是采用template的设计模式，主要实现逻辑交由子类来实现:</p><ul><li>addInternal</li><li>removeInternal</li><li>getHeadElementIndex</li></ul><h5>addInternal</h5><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public boolean add(@Nonnull T toAdd) &#123;</span><br><span class="line">	addInternal(toAdd);</span><br><span class="line">	return toAdd.getInternalIndex() == getHeadElementIndex();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>添加一个timer至数组中，返回值<code>false</code>表示队首的元素没有改变，<code>true</code>则表示改变了或者不确定</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">protected void addInternal(@Nonnull T element) &#123;</span><br><span class="line">	final int newSize = increaseSizeByOne();</span><br><span class="line">	moveElementToIdx(element, newSize);</span><br><span class="line">	siftUp(newSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">private int increaseSizeByOne() &#123;</span><br><span class="line">	final int oldArraySize = queue.length;</span><br><span class="line">	final int minRequiredNewSize = ++size;</span><br><span class="line">	if (minRequiredNewSize &gt;= oldArraySize) &#123;</span><br><span class="line">		final int grow = (oldArraySize &lt; 64) ? oldArraySize + 2 : oldArraySize &gt;&gt; 1;</span><br><span class="line">		// 当存储元素的个数大于数组长度时，需要进行扩容，通过`Arrays.copyOf`进行数组内容的拷贝</span><br><span class="line">		resizeQueueArray(oldArraySize + grow, minRequiredNewSize);</span><br><span class="line">	&#125;</span><br><span class="line">	// TODO implement shrinking as well?</span><br><span class="line">	return minRequiredNewSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 将新加入的元素存储到相应的idx处，并且记录该元素在queue中的位置</span><br><span class="line">protected void moveElementToIdx(T element, int idx) &#123;</span><br><span class="line">		queue[idx] = element;</span><br><span class="line">		element.setInternalIndex(idx);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private void siftUp(int idx) &#123;</span><br><span class="line">		final T[] heap = this.queue;</span><br><span class="line">		final T currentElement = heap[idx];</span><br><span class="line">		int parentIdx = idx &gt;&gt;&gt; 1;</span><br><span class="line">		</span><br><span class="line">		// 每次将比较的index，缩小一半，如果被比较元素的优先级高于新插入的元素就将被比较元素后移，直至比较到第一个元素。这样能够保证idx为1的元素是最早时间触发的</span><br><span class="line">		while (parentIdx &gt; 0 &amp;&amp; isElementPriorityLessThen(currentElement, heap[parentIdx])) &#123;</span><br><span class="line">			moveElementToIdx(heap[parentIdx], idx);</span><br><span class="line">			idx = parentIdx;</span><br><span class="line">			parentIdx &gt;&gt;&gt;= 1;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		moveElementToIdx(currentElement, idx);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 比较两个值的优先级</span><br><span class="line">private boolean isElementPriorityLessThen(T a, T b) &#123;</span><br><span class="line">		return elementPriorityComparator.comparePriority(a, b) &lt; 0;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><h5>removeInternal</h5><ol><li>抽取第一个timer用以触发</li><li>用户删除某个timer的行为</li></ol><p>删除的方式是通过idx下标来实现快速删除的，这也就是<code>HeapPriorityQueueElement</code>中记录idx的作用</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">protected T removeInternal(int removeIdx) &#123;</span><br><span class="line">	T[] heap = this.queue;</span><br><span class="line">	T removedValue = heap[removeIdx];</span><br><span class="line"></span><br><span class="line">	// 要删除的idx应该和内部存储value值保存的idx一致</span><br><span class="line">	assert removedValue.getInternalIndex() == removeIdx;</span><br><span class="line"></span><br><span class="line">	final int oldSize = size;</span><br><span class="line"></span><br><span class="line">	// 删除的不是数组的最后一个元素需要进行位置的调整</span><br><span class="line">	if (removeIdx != oldSize) &#123;</span><br><span class="line">		T element = heap[oldSize];</span><br><span class="line">		// 将原先的最后一个元素放置到要删除的idx处，但是这样的放置没有考虑优先级</span><br><span class="line">		moveElementToIdx(element, removeIdx);</span><br><span class="line">		adjustElementAtIndex(element, removeIdx);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	heap[oldSize] = null;</span><br><span class="line"></span><br><span class="line">	--size;</span><br><span class="line">	return removedValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private void adjustElementAtIndex(T element, int index) &#123;</span><br><span class="line">	siftDown(index);</span><br><span class="line">	if (queue[index] == element) &#123;</span><br><span class="line">		siftUp(index);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private void siftDown(int idx) &#123;</span><br><span class="line">	final T[] heap = this.queue;</span><br><span class="line">	final int heapSize = this.size;</span><br><span class="line"></span><br><span class="line">	final T currentElement = heap[idx];</span><br><span class="line">	int firstChildIdx = idx &lt;&lt; 1;</span><br><span class="line">	int secondChildIdx = firstChildIdx + 1;</span><br><span class="line"></span><br><span class="line">	if (isElementIndexValid(secondChildIdx, heapSize) &amp;&amp;</span><br><span class="line">		isElementPriorityLessThen(heap[secondChildIdx], heap[firstChildIdx])) &#123;</span><br><span class="line">		firstChildIdx = secondChildIdx;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	while (isElementIndexValid(firstChildIdx, heapSize) &amp;&amp;</span><br><span class="line">		isElementPriorityLessThen(heap[firstChildIdx], currentElement)) &#123;</span><br><span class="line">		moveElementToIdx(heap[firstChildIdx], idx);</span><br><span class="line">		idx = firstChildIdx;</span><br><span class="line">		firstChildIdx = idx &lt;&lt; 1;</span><br><span class="line">		secondChildIdx = firstChildIdx + 1;</span><br><span class="line"></span><br><span class="line">		if (isElementIndexValid(secondChildIdx, heapSize) &amp;&amp;</span><br><span class="line">			isElementPriorityLessThen(heap[secondChildIdx], heap[firstChildIdx])) &#123;</span><br><span class="line">			firstChildIdx = secondChildIdx;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	moveElementToIdx(currentElement, idx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>以上的操作大致上是一个二叉堆的增删的调整过程，涉及的具体算法可以查阅下文末的资料。</p><hr><p>以下来分析rocksdb存储的实现</p><h4>KeyGroupPartitionedPriorityQueue</h4><p>基于rocksdb的存储是通过这个<code>KeyGroupPartitionedPriorityQueue</code>类来实现的，这个类中通过一个内存优先级队列，也就是上文中提到的内部实现的<code>HeapPriorityQueue</code>，用以存储所有KG的timer，而每一个分组的timer是如何存储呢？</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; keyGroupedHeaps.length; i++) &#123;</span><br><span class="line">			final PQ keyGroupSubHeap =</span><br><span class="line">				orderedCacheFactory.create(firstKeyGroup + i, totalKeyGroups, keyExtractor, elementPriorityComparator);</span><br><span class="line">			keyGroupedHeaps[i] = keyGroupSubHeap;</span><br><span class="line">			heapOfKeyGroupedHeaps.add(keyGroupSubHeap);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><p>在这里的构造函数可以看到，其实是通过<code>orderedCacheFactory</code>,从字面意思看是一个有序的缓存，也就是为每一个KG创建一个有序的缓存类，并将其添加到优先级队列中，这里的<code>subHeap</code>也是一个可比较的类，相当于去取这两个<code>subHeap</code>的堆顶的元素拿出来比较下就可以知道这两个subheap的排序方式了。</p><p>比如<code>poll</code>的逻辑,首先先从HeapPQ中挑出堆顶（一个subPQ），然后再从这个PQ中取出堆顶就是要触发的timer了，而这个subPQ就是真是数据（timer）存储的地方了。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public T poll() &#123;</span><br><span class="line">	final PQ headList = heapOfKeyGroupedHeaps.peek();</span><br><span class="line">	final T head = headList.poll();</span><br><span class="line">	heapOfKeyGroupedHeaps.adjustModifiedElement(headList);</span><br><span class="line">	return head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>RocksDBCachingPriorityQueueSet</h4><p>这个是上节中<code>subHeap</code>的实现类</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">private void checkRefillCacheFromStore() &#123;</span><br><span class="line">		// 不是所有的元素都在cache(treeset)中，并且cache为空  </span><br><span class="line">		if (!allElementsInCache &amp;&amp; orderedCache.isEmpty()) &#123;</span><br><span class="line">			try (final RocksBytesIterator iterator = orderedBytesIterator()) &#123;</span><br><span class="line">				// 捞取rocksdb中这个columnFamily的部分数据填充treeset至maxsize</span><br><span class="line">				orderedCache.bulkLoadFromOrderedIterator(iterator);</span><br><span class="line">				allElementsInCache = !iterator.hasNext();</span><br><span class="line">			&#125; catch (Exception e) &#123;</span><br><span class="line">				throw new FlinkRuntimeException(&quot;Exception while refilling store from iterator.&quot;, e);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public E peek() &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		if (peekCache != null) &#123;</span><br><span class="line">			// 这个是维护的全局变量，只有在堆顶改变后在会置为null</span><br><span class="line">			return peekCache;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		byte[] firstBytes = orderedCache.peekFirst();</span><br><span class="line">		if (firstBytes != null) &#123;</span><br><span class="line">			peekCache = deserializeElement(firstBytes);</span><br><span class="line">			return peekCache;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			return null;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public E poll() &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] firstBytes = orderedCache.pollFirst();</span><br><span class="line"></span><br><span class="line">		if (firstBytes == null) &#123;</span><br><span class="line">			return null;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// write-through sync</span><br><span class="line">		// 为什么不需要删除treeset中的元素呢？</span><br><span class="line">		removeFromRocksDB(firstBytes);</span><br><span class="line"></span><br><span class="line">		// 删除了这个columnFamily最后一个元素</span><br><span class="line">		if (orderedCache.isEmpty()) &#123;</span><br><span class="line">			seekHint = firstBytes;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// 少一步反序列化的操作</span><br><span class="line">		if (peekCache != null) &#123;</span><br><span class="line">			E fromCache = peekCache;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return fromCache;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			return deserializeElement(firstBytes);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public boolean add(@Nonnull E toAdd) &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] toAddBytes = serializeElement(toAdd);</span><br><span class="line"></span><br><span class="line">		final boolean cacheFull = orderedCache.isFull();</span><br><span class="line"></span><br><span class="line">		// 如果cache没满并且之前所有元素都在cache中了  或者新加入的元素的优先级通过byte数组的优先级比较发现应该在堆顶</span><br><span class="line">		if ((!cacheFull &amp;&amp; allElementsInCache) ||</span><br><span class="line">			LEXICOGRAPHIC_BYTE_COMPARATOR.compare(toAddBytes, orderedCache.peekLast()) &lt; 0) &#123;</span><br><span class="line"></span><br><span class="line">			if (cacheFull) &#123;</span><br><span class="line">				// we drop the element with lowest priority from the cache</span><br><span class="line">				orderedCache.pollLast();</span><br><span class="line">				// the dropped element is now only in the store</span><br><span class="line">				allElementsInCache = false;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			// 用来判重</span><br><span class="line">			if (orderedCache.add(toAddBytes)) &#123;</span><br><span class="line">				// write-through sync</span><br><span class="line">				addToRocksDB(toAddBytes);</span><br><span class="line">				if (toAddBytes == orderedCache.peekFirst()) &#123;</span><br><span class="line">					// 说明新的写入导致了堆顶变化</span><br><span class="line">					peekCache = null;</span><br><span class="line">					return true;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			// 如果cache满了，或者不是所有的元素都在cache中，说明新来的数据一定不是堆顶的数据</span><br><span class="line">			// we only added to the store</span><br><span class="line">			addToRocksDB(toAddBytes);</span><br><span class="line">			allElementsInCache = false;</span><br><span class="line">		&#125;</span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(@Nonnull E toRemove) &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] oldHead = orderedCache.peekFirst();</span><br><span class="line"></span><br><span class="line">		if (oldHead == null) &#123;</span><br><span class="line">			return false;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		final byte[] toRemoveBytes = serializeElement(toRemove);</span><br><span class="line"></span><br><span class="line">		// write-through sync</span><br><span class="line">		removeFromRocksDB(toRemoveBytes);</span><br><span class="line">		orderedCache.remove(toRemoveBytes);</span><br><span class="line"></span><br><span class="line">		if (orderedCache.isEmpty()) &#123;</span><br><span class="line">			seekHint = toRemoveBytes;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (oldHead != orderedCache.peekFirst()) &#123;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p>Iterator中seekHint的作用：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private RocksBytesIterator(@Nonnull RocksIteratorWrapper iterator) &#123;</span><br><span class="line">			this.iterator = iterator;</span><br><span class="line">			try &#123;</span><br><span class="line">				// We use our knowledge about the lower bound to issue a seek that is as close to the first element in</span><br><span class="line">				// the key-group as possible, i.e. we generate the next possible key after seekHint by appending one</span><br><span class="line">				// zero-byte.</span><br><span class="line">				iterator.seek(Arrays.copyOf(seekHint, seekHint.length + 1));</span><br><span class="line">				currentElement = nextElementIfAvailable();</span><br><span class="line">			&#125; catch (Exception ex) &#123;</span><br><span class="line">				// ensure resource cleanup also in the face of (runtime) exceptions in the constructor.</span><br><span class="line">				iterator.close();</span><br><span class="line">				throw new FlinkRuntimeException(&quot;Could not initialize ordered iterator.&quot;, ex);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><h4>再说checkpoint</h4><p>在doc中作者也提到之所以要做这个feature除了因为timer过多会导致OOM等问题，还有一个原因是因为timer的属性虽然和keyed state很类似，但是代码管理以及checkpoint的方式都是单独的一块逻辑，并且checkpoint的持久化过程还是同步的（因为是以raw keyedstate的方式去进行的），再修改之后，每次注册的timeservice都会注册到<code>kvstatInfo</code>中，将checkpoint的逻辑统一到statebackend中并且实现了异步化。</p><p><a href="https://blog.csdn.net/u010224394/article/details/8834969" target="_blank" rel="noopener">https://blog.csdn.net/u010224394/article/details/8834969</a></p><p><a href="https://github.com/apache/flink/pull/6159" target="_blank" rel="noopener">https://github.com/apache/flink/pull/6159</a></p><p><a href="https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-timerservice-based-on-rocksdb.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-timerservice-based-on-rocksdb.html" itemprop="url">上篇·flink基于rocksdb的timerService</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T12:08:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-timerservice-based-on-rocksdb.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-timerservice-based-on-rocksdb.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.6k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">7</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>本文主要介绍flink中<code>TimerService based on Rocksdb</code>实现以及和之前版本的一个比较。</p><p>&lt;!--more--&gt;</p><p><strong>动机</strong></p><ol><li>timer和keyed state分开单独管理，keyed state是由<code>KeyedStateBackend</code>管理，而timer是由<code>InternalTimerServeice</code>管理</li><li><code>InternalTimerServeice</code>现有的实现是基于heap的<code>HeapInternalTimerService</code>，当timer数量较多时会有OOM的问题.如果能像keyed state一样基于<code>KeyedStateBackend</code>管理，就能在timer数量比较多的时候选用rocksdb作为backend来解决扩展性的问题</li><li>timer目前的checkpoint过程是通过raw keyed state的方式，在同步的过程中完成写出到外置存储，并且对于snapshot和restore timer都单独维护了一份代码。这块代码和其他的keyed state的实现有很多相同之处（分隔到keygroup来实现rescale，元数据的序列化和持久化..）</li></ol><p><strong>实现目标</strong></p><ol><li>Have an implementation of timer services that operates on RocksDB.</li><li>Support asynchronous snapshots for all timer state.</li><li>Support incremental snapshots for timer state in RocksDB.</li><li>Integrate timer state as another form of keyed state in keyed state backends in a way that leverages the existing snapshotting code to eliminate special casing code paths that do similar things. As as nice side effect, this would also free the raw keyed state for user state.</li></ol><p><strong>源码分析</strong></p><p>首先我们来看一下1.4版本中timerService是怎么实现的,timerService 实现了以下两个接口：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">InternalTimerService</span><br><span class="line">    long currentProcessingTime();</span><br><span class="line">    long currentWatermark();</span><br><span class="line">    void registerProcessingTimeTimer(N namespace, long time);</span><br><span class="line">    void deleteProcessingTimeTimer(N namespace, long time);</span><br><span class="line">    void registerEventTimeTimer(N namespace, long time);</span><br><span class="line">    void deleteEventTimeTimer(N namespace, long time);</span><br><span class="line">提供的是当前时间获取和注册timer的方法</span><br><span class="line"></span><br><span class="line">ProcessingTimeCallback</span><br><span class="line">    void onProcessingTime(long timestamp) throws Exception;</span><br></pre></td></tr></table></figure><p></p><p>在<code>HeapInternalTimerService</code>中分别维护了processing time和event time的timer集合</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private final Set&lt;InternalTimer&lt;K, N&gt;&gt;[] processingTimeTimersByKeyGroup;</span><br><span class="line">private final PriorityQueue&lt;InternalTimer&lt;K, N&gt;&gt; processingTimeTimersQueue;</span><br><span class="line"></span><br><span class="line">private final Set&lt;InternalTimer&lt;K, N&gt;&gt;[] eventTimeTimersByKeyGroup;</span><br><span class="line">private final PriorityQueue&lt;InternalTimer&lt;K, N&gt;&gt; eventTimeTimersQueue;</span><br></pre></td></tr></table></figure><p></p><p><code>InternalTimer</code>是一个<code>Comparable</code>, 按照timer触发的时间进行比较，timer是由<code>key</code>,<code>namespace</code>,<code>timestamp</code>唯一确定，其实也可以理解成如果同一个key，namespace下只可以有一个时间事件被触发。<code>regsterTimer</code>实际上就是在executor中注册一个任务</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">return timerService.schedule(</span><br><span class="line">                    new TriggerTask(status, task, checkpointLock, target, timestamp), delay, TimeUnit.MILLISECONDS);</span><br></pre></td></tr></table></figure><p></p><p>同时每个timerService中还维护了一个<code>ProcessingTimeService</code>用以处理和processing time相关的时间操作，是对<code>ScheduledThreadPoolExecutor</code>的包装，提供一些周期性执行和将来某时执行一次的操作.</p><p>我们在回头看<code>HeapInternalTimerService</code>的实现：</p><h4>registerProcessingTimeTimer</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public void registerProcessingTimeTimer(N namespace, long time) &#123;</span><br><span class="line">    InternalTimer&lt;K, N&gt; timer = new InternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace);</span><br><span class="line"></span><br><span class="line">    // make sure we only put one timer per key into the queue</span><br><span class="line">    // 在存储timer的时候会存储两份，一份是通过Set的形式将各个Keygroup的区分开，另一份是按照时间顺序排除存储在一个`PriorityQueue`中</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getProcessingTimeTimerSetForTimer(timer);</span><br><span class="line">    if (timerSet.add(timer)) &#123;</span><br><span class="line"></span><br><span class="line">        InternalTimer&lt;K, N&gt; oldHead = processingTimeTimersQueue.peek();</span><br><span class="line">        long nextTriggerTime = oldHead != null ? oldHead.getTimestamp() : Long.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">        processingTimeTimersQueue.add(timer);</span><br><span class="line"></span><br><span class="line">        // check if we need to re-schedule our timer to earlier</span><br><span class="line">        // 如果新注册的timer比最近要触发的timer时间早，那么就会终止最近要触发的timer（如果已经跑起来了就不中断了）</span><br><span class="line">        if (time &lt; nextTriggerTime) &#123;</span><br><span class="line">            if (nextTimer != null) &#123;</span><br><span class="line">                nextTimer.cancel(false);</span><br><span class="line">            &#125;</span><br><span class="line">            // 通过ScheduledThreadPoolExecutor注册一个task</span><br><span class="line">            nextTimer = processingTimeService.registerTimer(time, this);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 获取这个timer的key所属的已经注册的timer列表，从上面的注释我们可以看出是为了保证不注册重复timer</span><br><span class="line">private Set&lt;InternalTimer&lt;K, N&gt;&gt; getProcessingTimeTimerSetForTimer(InternalTimer&lt;K, N&gt; timer) &#123;</span><br><span class="line">    checkArgument(localKeyGroupRange != null, &quot;The operator has not been initialized.&quot;);</span><br><span class="line">    int keyGroupIdx = KeyGroupRangeAssignment.assignToKeyGroup(timer.getKey(), this.totalKeyGroups);</span><br><span class="line">    return getProcessingTimeTimerSetForKeyGroup(keyGroupIdx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private Set&lt;InternalTimer&lt;K, N&gt;&gt; getProcessingTimeTimerSetForKeyGroup(int keyGroupIdx) &#123;</span><br><span class="line">    int localIdx = getIndexForKeyGroup(keyGroupIdx);</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timers = processingTimeTimersByKeyGroup[localIdx];</span><br><span class="line">    // 如过这个set没有出现过，就构建一个新的set存放这个key的timer</span><br><span class="line">    if (timers == null) &#123;</span><br><span class="line">        timers = new HashSet&lt;&gt;();</span><br><span class="line">        processingTimeTimersByKeyGroup[localIdx] = timers;</span><br><span class="line">    &#125;</span><br><span class="line">    return timers;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private int getIndexForKeyGroup(int keyGroupIdx) &#123;</span><br><span class="line">    checkArgument(localKeyGroupRange.contains(keyGroupIdx),</span><br><span class="line">        &quot;Key Group &quot; + keyGroupIdx + &quot; does not belong to the local range.&quot;);</span><br><span class="line">    return keyGroupIdx - this.localKeyGroupRangeStartIdx;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>registerEventTimeTimer</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void registerEventTimeTimer(N namespace, long time) &#123;</span><br><span class="line">    InternalTimer&lt;K, N&gt; timer = new InternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace);</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getEventTimeTimerSetForTimer(timer);</span><br><span class="line">    if (timerSet.add(timer)) &#123;</span><br><span class="line">        eventTimeTimersQueue.add(timer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以看到eventtimer注册就不需要校验是否有将要执行的任务，因为eventtimer的实现不依赖于schedulerExxecutor。</p><h4>onProcessingTime</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">// 这个方法是配合registerProcessingTimer，通过SystemProcessingTimeService来实现timer语义，在timer中注册的任务会回调这个onProcessing方法</span><br><span class="line">public void onProcessingTime(long time) throws Exception &#123;</span><br><span class="line">    // null out the timer in case the Triggerable calls registerProcessingTimeTimer()</span><br><span class="line">    // inside the callback.</span><br><span class="line">    // 如果不置为null，在执行triggerTarget.onProcessingTime(timer);里面执行了registerProcessingTimeTimer会调用本任务的cancel</span><br><span class="line">    nextTimer = null;</span><br><span class="line"></span><br><span class="line">    InternalTimer&lt;K, N&gt; timer;</span><br><span class="line"></span><br><span class="line">    // 将processingTimeTimersQueue中所有小于当前时间的任务都取出进行出发</span><br><span class="line">    while ((timer = processingTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;</span><br><span class="line"></span><br><span class="line">        // 删除set中存储的timer</span><br><span class="line">        Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getProcessingTimeTimerSetForTimer(timer);</span><br><span class="line"></span><br><span class="line">        timerSet.remove(timer);</span><br><span class="line">        processingTimeTimersQueue.remove();</span><br><span class="line"></span><br><span class="line">        // 每次触发之前需要设置当前的key</span><br><span class="line">        keyContext.setCurrentKey(timer.getKey());</span><br><span class="line">        triggerTarget.onProcessingTime(timer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 说明队列中还存在还没到时间需要触发的timer，需要注册新的FutureTask</span><br><span class="line">    if (timer != null) &#123;</span><br><span class="line">        if (nextTimer == null) &#123;</span><br><span class="line">            nextTimer = processingTimeService.registerTimer(timer.getTimestamp(), this);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>advanceWatermark</h4><p>processing timer是基于executor来实现的，eventtime 的timer触发就依赖于watermark来触发，每次收到上游的watermark会触发调用<code>advanceWatermark</code>来将eventtime queue中的timer取出进行触发</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public void processWatermark(Watermark mark) throws Exception &#123;</span><br><span class="line">    if (timeServiceManager != null) &#123;</span><br><span class="line">        timeServiceManager.advanceWatermark(mark);</span><br><span class="line">    &#125;</span><br><span class="line">    output.emitWatermark(mark);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 这里的time就是最近的这次watermark的时间</span><br><span class="line">public void advanceWatermark(long time) throws Exception &#123;</span><br><span class="line">    currentWatermark = time;</span><br><span class="line"></span><br><span class="line">    InternalTimer&lt;K, N&gt; timer;</span><br><span class="line"></span><br><span class="line">    // 同样是取出所有的小于watermark的timer进行触发</span><br><span class="line">    while ((timer = eventTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;</span><br><span class="line"></span><br><span class="line">        Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getEventTimeTimerSetForTimer(timer);</span><br><span class="line">        timerSet.remove(timer);</span><br><span class="line">        eventTimeTimersQueue.remove();</span><br><span class="line"></span><br><span class="line">        keyContext.setCurrentKey(timer.getKey());</span><br><span class="line">        triggerTarget.onEventTime(timer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>snapshot</h4><p>之前在分析state实现的时候也分析过，在对operator进行snapshot的时候有一步就是对timerservice的数据进行snapshot</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">KeyGroupsList allKeyGroups = out.getKeyGroupList();</span><br><span class="line">for (int keyGroupIdx : allKeyGroups) &#123;</span><br><span class="line">    out.startNewKeyGroup(keyGroupIdx);</span><br><span class="line"></span><br><span class="line">    timeServiceManager.snapshotStateForKeyGroup(</span><br><span class="line">        new DataOutputViewStreamWrapper(out), keyGroupIdx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public void snapshotStateForKeyGroup(DataOutputView stream, int keyGroupIdx) throws IOException &#123;</span><br><span class="line">    InternalTimerServiceSerializationProxy&lt;K, N&gt; serializationProxy =</span><br><span class="line">        new InternalTimerServiceSerializationProxy&lt;&gt;(timerServices, keyGroupIdx);</span><br><span class="line"></span><br><span class="line">    serializationProxy.write(stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>proxy这块主要是为兼容做了很多的工作</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public void write(DataOutputView out) throws IOException &#123;</span><br><span class="line">    super.write(out);</span><br><span class="line"></span><br><span class="line">    out.writeInt(timerServices.size());</span><br><span class="line">    for (Map.Entry&lt;String, HeapInternalTimerService&lt;K, N&gt;&gt; entry : timerServices.entrySet()) &#123;</span><br><span class="line">        String serviceName = entry.getKey();</span><br><span class="line">        HeapInternalTimerService&lt;K, N&gt; timerService = entry.getValue();</span><br><span class="line"></span><br><span class="line">        out.writeUTF(serviceName);</span><br><span class="line">        InternalTimersSnapshotReaderWriters</span><br><span class="line">            .getWriterForVersion(VERSION, timerService.snapshotTimersForKeyGroup(keyGroupIdx))</span><br><span class="line">            .writeTimersSnapshot(out);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>restore</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">protected void read(DataInputView in, boolean wasVersioned) throws IOException &#123;</span><br><span class="line">    int noOfTimerServices = in.readInt();</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; noOfTimerServices; i++) &#123;</span><br><span class="line">        String serviceName = in.readUTF();</span><br><span class="line"></span><br><span class="line">        HeapInternalTimerService&lt;K, N&gt; timerService = timerServices.get(serviceName);</span><br><span class="line">        if (timerService == null) &#123;</span><br><span class="line">            timerService = new HeapInternalTimerService&lt;&gt;(</span><br><span class="line">                totalKeyGroups,</span><br><span class="line">                localKeyGroupRange,</span><br><span class="line">                keyContext,</span><br><span class="line">                processingTimeService);</span><br><span class="line">            timerServices.put(serviceName, timerService);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        int readerVersion = wasVersioned ? getReadVersion() : InternalTimersSnapshotReaderWriters.NO_VERSION;</span><br><span class="line">        InternalTimersSnapshot&lt;?, ?&gt; restoredTimersSnapshot = InternalTimersSnapshotReaderWriters</span><br><span class="line">            .getReaderForVersion(readerVersion, userCodeClassLoader)</span><br><span class="line">            .readTimersSnapshot(in);</span><br><span class="line"></span><br><span class="line">        timerService.restoreTimersForKeyGroup(restoredTimersSnapshot, keyGroupIdx);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><p>本文主要是对1.4版本的分析，下一篇文章基于1.7版本再分析<code>timerservice on rocksdb</code>的实现</p><p>参考:</p><p><a href="https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit#heading=h.17v0k3363r6q" target="_blank" rel="noopener">https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit#heading=h.17v0k3363r6q</a></p><p><a href="https://issues.apache.org/jira/browse/FLINK-9485" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/FLINK-9485</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-network-feature.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-network-feature.html" itemprop="url">flink网络传输的前世今生</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T11:57:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-network-feature.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-network-feature.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">2k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">8</span></div></div></header><div class="post-body" itemprop="articleBody"><p>flink的网络传输在1.5版本进行了重构，本文就这个feature来对flink网络传输进行系统的源码分析</p><p>&lt;!--more--&gt;</p><h3>发送端</h3><p>首先我们先来看数据发送端的主要流程如下：</p><p><strong>数据发送链路</strong></p><blockquote><p><code>RecordWriter =&gt; ResultPartition =&gt; ResultSubPartition =&gt; ResultSubpartitionView =&gt; BufferAvailabilityListener =&gt; PartitionRequestQueue</code> 解释一下： 用户程序中调用<code>output.collect()</code>,首先会通过<code>RecordWriter</code>进行数据或者event的序列化。并且将其从堆内内存拷贝至堆外内存，然后添加至相应的<code>ResultPartition</code>中。<code>ResultPartition</code>根据数据<code>selectChannel</code>发送给下游的哪个<code>subIndex</code>,<code>BufferConsumer</code>就会被添加到相应的subpartition所维护的一个双端队列中。在某些条件下需要通过,在服务启动最开始注册上来的<code>ResultSubpartitionView</code>去通知消费端来进行消费buffer，view做的事情就是通过调用<code>BufferAvailableListener</code>的具体实现来进行通知事件通知。最终在netty端，通过<code>PartitionRequestQueue</code>进行最终的buffer发送。</p></blockquote><p>上面讲述了大体的流程，下面我们来结合代码来进行细节分析，下面代码可能会结合1.4和1.7两个版本来进行讲解</p><h4>RecordWriter</h4><h4>RecordSerializer</h4><p>在1.4版本中序列化器是和下游的并发度一一绑定的，这样会导致一个问题，比如发送下游是hash的分区模式的话，在上游的每一个并发度就会存储5MB的序列化后的缓存数据，当下游的并发较大的时候就会占据比较大的内存，带来一定的gc问题。序列化器会负责做这样几件事情：</p><ul><li>数据的序列化<ul><li>在写数据的时候并不会校验缓存块的大小</li><li>写的时候同时用一个4字节的bytebuffer记录数据的大小，有多少个字节</li></ul></li><li>数据序列化结果的拷贝，对拷贝结果的判断<ul><li>数据拷贝了一部分，memorysegment已经满了</li><li>拷贝了完整记录</li><li>拷贝了完整记录，并且segment满了</li></ul></li><li>缓存清理</li><li>...</li></ul><p>重点拷贝过程</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">private boolean copyFromSerializerToTargetChannel(int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	// We should reset the initial position of the intermediate serialization buffer before</span><br><span class="line">	// copying, so the serialization results can be copied to multiple target buffers.</span><br><span class="line">	// 这一步reset是为了在数据发送如果是broadcast这种一份数据需要发送多个下游通道的时候，就可以只序列化一次，后续数据发送的时候只需要将bytebuffer</span><br><span class="line">	// 的position值值置到0就可以了。</span><br><span class="line">	serializer.reset();</span><br><span class="line"></span><br><span class="line">	boolean pruneTriggered = false;</span><br><span class="line">	BufferBuilder bufferBuilder = getBufferBuilder(targetChannel);</span><br><span class="line">	SerializationResult result = serializer.copyToBufferBuilder(bufferBuilder);</span><br><span class="line">	// buffer没写满说明数据肯定已经写完了，直接进行下面的逻辑</span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		// buffer写满了，首先将bufferBuilder标记为写完了，就是将positionMarker置为相反数</span><br><span class="line">		numBytesOut.inc(bufferBuilder.finish());</span><br><span class="line">		numBuffersOut.inc();</span><br><span class="line"></span><br><span class="line">		// If this was a full record, we are done. Not breaking out of the loop at this point</span><br><span class="line">		// will lead to another buffer request before breaking out (that would not be a</span><br><span class="line">		// problem per se, but it can lead to stalls in the pipeline).</span><br><span class="line">		// buffer写满，并且记录也写满了，那么发送到这个channel就完成了，否则就需要继续申请bufferBuilder继续拷贝</span><br><span class="line">		if (result.isFullRecord()) &#123;</span><br><span class="line">			pruneTriggered = true;</span><br><span class="line">			bufferBuilders[targetChannel] = Optional.empty();</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		bufferBuilder = requestNewBufferBuilder(targetChannel);</span><br><span class="line">		result = serializer.copyToBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public SerializationResult copyToBufferBuilder(BufferBuilder targetBuffer) &#123;</span><br><span class="line">	targetBuffer.append(lengthBuffer);</span><br><span class="line">	targetBuffer.append(dataBuffer);</span><br><span class="line">	targetBuffer.commit();</span><br><span class="line"></span><br><span class="line">	return getSerializationResult(targetBuffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public int append(ByteBuffer source) &#123;</span><br><span class="line">	checkState(!isFinished());</span><br><span class="line"></span><br><span class="line">	int needed = source.remaining();</span><br><span class="line">	int available = getMaxCapacity() - positionMarker.getCached();</span><br><span class="line">	// segment不一定足够大，可能存不下这批buffer, 堆外内存拷贝的时候需要提前计算好可以拷贝的量，否则会有异常</span><br><span class="line">	int toCopy = Math.min(needed, available);</span><br><span class="line"></span><br><span class="line">	// 将source buffer中的数据/堆内存，put至memorySegment中，利用Unsafe进行数据拷贝</span><br><span class="line">	memorySegment.put(positionMarker.getCached(), source, toCopy);</span><br><span class="line">	// 设置新的position</span><br><span class="line">	positionMarker.move(toCopy);</span><br><span class="line">	return toCopy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>BufferBuilder，BufferConsumer，PositionMarker</h4><p>在上面copy代码中看到其实拷贝的时候是依赖buffer的,如果没有申请到<code>BufferBuiler</code>,是会一直blocking的，那么这个bufferbuilder是什么呢？</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">private BufferBuilder requestNewBufferBuilder(int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	checkState(!bufferBuilders[targetChannel].isPresent() || bufferBuilders[targetChannel].get().isFinished());</span><br><span class="line"></span><br><span class="line">	BufferBuilder bufferBuilder = targetPartition.getBufferProvider().requestBufferBuilderBlocking();</span><br><span class="line">	bufferBuilders[targetChannel] = Optional.of(bufferBuilder);</span><br><span class="line">	// 一个bufferbuilder对应一个bufferconsumer</span><br><span class="line">	targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(), targetChannel);</span><br><span class="line">	return bufferBuilder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>在向<code>BufferProvider</code>，一般是localBufferPool申请完得到一个memorysegment后，将其封装成一个bufferbuilder，每一个bufferbuilder会对应 一个bufferconsumer和positionMarker，positionMarker会标记生产端的数据写到多少个字节了，这个在消费端的时候也会用到这个position， 由于是多线程使用所以position的值需要被标记成<code>volatile</code>来保证数据的可见性，每次消费端拉取数据的时候，对于没有写完的buffer同样可以进行消费， 消费前更新一个buffer的position真实位置，这里用到了一个小技巧，由于数据在生产的时候需要频繁的更新position，如果是<code>volatile</code>的， 虽然比较轻量，频繁更新也是比较大的开销，因此加入了一个<code>cachedPosition</code>，在写数据的时候只需要更新builder中的<code>cachedPosition</code>，生产端每次 完成一批的书写才会commit给<code>volatile position</code>，以此来减少缓存刷新。</p><p>从一个正在写的bufferbuiler中构建一个可消费的slice</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public Buffer build() &#123;</span><br><span class="line">	// 获取最近builder，commit到的position</span><br><span class="line">	writerPosition.update();</span><br><span class="line">	int cachedWriterPosition = writerPosition.getCached();</span><br><span class="line">	// slice 切分只读区块</span><br><span class="line">	Buffer slice = buffer.readOnlySlice(currentReaderPosition, cachedWriterPosition - currentReaderPosition);</span><br><span class="line">	currentReaderPosition = cachedWriterPosition;</span><br><span class="line">	// 增加引用计数</span><br><span class="line">	return slice.retainBuffer();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>PartitionRequestQueue</h4><p>在将bufferConsumer添加到subpartition的队列之后，同时会在partitionRequestQueue中维护一个availableReader的队列，这个队列表示可以往下 下游发送的buffer数据，这样通过一个<code>while true</code>循环持续的将队列中的数据往下游发送，当然这个<code>availableReader</code>队列的维护既考量了上游subpartition 有没有buffer的因素，也考量了下游要发送的receiver端的credit的情况，如果没有credit也是无法进入这个待发送队列的。</p><h3>消费端</h3><p><strong>数据接收链路</strong></p><blockquote><p><code>CreditBasedPartitionRequestClientHandler =&gt; RemoteInputChannel =&gt; SingleInputGate =&gt; BarrierHandler =&gt; StreamInputProcessor =&gt; StreamOperator</code> 首先会通过netty client进行数据的接收，然后从localbufferpool申请内存接收数据，然后根据backlog的信息去决定是不是要给上游分发credit，以及数据处理的流程</p></blockquote><p>这里主要分析下credit的判断逻辑</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Receives the backlog from the producer&apos;s buffer response. If the number of available</span><br><span class="line"> * buffers is less than backlog + initialCredit, it will request floating buffers from the buffer</span><br><span class="line"> * pool, and then notify unannounced credits to the producer.</span><br><span class="line"> *</span><br><span class="line"> * @param backlog The number of unsent buffers in the producer&apos;s sub partition.</span><br><span class="line"> */</span><br><span class="line">void onSenderBacklog(int backlog) throws IOException &#123;</span><br><span class="line">	int numRequestedBuffers = 0;</span><br><span class="line"></span><br><span class="line">	synchronized (bufferQueue) &#123;</span><br><span class="line">		// Similar to notifyBufferAvailable(), make sure that we never add a buffer</span><br><span class="line">		// after releaseAllResources() released all buffers (see above for details).</span><br><span class="line">		if (isReleased.get()) &#123;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		numRequiredBuffers = backlog + initialCredit;</span><br><span class="line">		// 检查当前input通道的buffer是否做够上游produce所需要的buffer，如果不够就去bufferpool申请</span><br><span class="line">		while (bufferQueue.getAvailableBufferSize() &lt; numRequiredBuffers &amp;&amp; !isWaitingForFloatingBuffers) &#123;</span><br><span class="line">			Buffer buffer = inputGate.getBufferPool().requestBuffer();</span><br><span class="line">			if (buffer != null) &#123;</span><br><span class="line">				// 申请到buffer之后先占据住</span><br><span class="line">				bufferQueue.addFloatingBuffer(buffer);</span><br><span class="line">				numRequestedBuffers++;</span><br><span class="line">				//  没有足够的buffer，那么注册回调等buffer回收</span><br><span class="line">			&#125; else if (inputGate.getBufferProvider().addBufferListener(this)) &#123;</span><br><span class="line">				// If the channel has not got enough buffers, register it as listener to wait for more floating buffers.</span><br><span class="line">				isWaitingForFloatingBuffers = true;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	// 如果生产端有buffer需求，并且之前的unannouncedCredit为0那么就需要通知上游有buffer了</span><br><span class="line">	if (numRequestedBuffers &gt; 0 &amp;&amp; unannouncedCredit.getAndAdd(numRequestedBuffers) == 0) &#123;</span><br><span class="line">		notifyCreditAvailable();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h3>整理流程图</h3><p><img src="https://raw.githubusercontent.com/Aitozi/images/master/flink/flink%E7%BD%91%E7%BB%9C%E6%A0%88%E5%9B%BE%E8%A7%A3.png" alt="flink-network" title="flink-network"></p><h3>netty内存的优化</h3><p>以下是message encode的时候的一段代码</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// only allocate header buffer - we will combine it with the data buffer below</span><br><span class="line">headerBuf = allocateBuffer(allocator, ID, messageHeaderLength, buffer.readableBytes(), false);</span><br><span class="line"></span><br><span class="line">receiverId.writeTo(headerBuf);</span><br><span class="line">headerBuf.writeInt(sequenceNumber);</span><br><span class="line">headerBuf.writeInt(backlog);</span><br><span class="line">headerBuf.writeBoolean(isBuffer);</span><br><span class="line">headerBuf.writeInt(buffer.readableBytes());</span><br><span class="line"></span><br><span class="line">CompositeByteBuf composityBuf = allocator.compositeDirectBuffer();</span><br><span class="line">composityBuf.addComponent(headerBuf);</span><br><span class="line">composityBuf.addComponent(buffer);</span><br><span class="line">// update writer index since we have data written to the components:</span><br><span class="line">composityBuf.writerIndex(headerBuf.writerIndex() + buffer.writerIndex());</span><br><span class="line">return composityBuf;</span><br></pre></td></tr></table></figure><p></p><p>可以看到这里和以前版本不一样的地方就是不需要再去申请一块netty内存做一次拷贝，因为这里将buffer对象的实现直接改成了继承netty的ByteBuf类， 所以减少了一次netty申请directBuffer以及从堆外拷贝到netty directBuffer的开销。在buffer处理完由netty回收时会放回<code>localBufferPool</code>中</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void deallocate() &#123;</span><br><span class="line">	recycler.recycle(memorySegment); // 在网络传输完内存释放的时候直接将segment回收到localbufferpool中</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h3>和flink1.4相比有了哪些改进</h3><p>https://docs.google.com/document/d/1chTOuOqe0sBsjldA_r-wXYeSIhU2zRGpUaTaik7QZ84</p><p>https://issues.apache.org/jira/browse/FLINK-7282?subTaskView=all</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/git-advance-tips-keeping-on-updating.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/git-advance-tips-keeping-on-updating.html" itemprop="url">git常用命令大全</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T11:40:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/编程工具/" itemprop="url" rel="index"><span itemprop="name">编程工具</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/git-advance-tips-keeping-on-updating.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="git-advance-tips-keeping-on-updating.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">686 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">3</span></div></div></header><div class="post-body" itemprop="articleBody"><p>主要是工作中常用的一些git命令和一些场景的使用方式</p><p>&lt;!--more--&gt;</p><h2>常见命令</h2><h3>checkout</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b release-1.7.2 origin/release-1.7.2  # 从远端仓库checkout出release-1.7.2分支</span><br><span class="line">git checkout -- filename # 回退某文件至修改前的状态，也可用于误删文件恢复</span><br><span class="line">git checkout 0c6ded6af7068ff9fa4505d81855a38fc9861871 filename # 将某文件回退至某个版本</span><br></pre></td></tr></table></figure><p></p><h3>commit</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit --amend   # 修改commit信息</span><br></pre></td></tr></table></figure><p></p><h3>stash</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git stash # 保存工作现场  没有commit的内容</span><br><span class="line">git stash list # 查看stash队列</span><br><span class="line">git stash apply stash@&#123;num&#125;  # 恢复对应的stash</span><br><span class="line">git stash pop # 应用并删除最上面的stash</span><br></pre></td></tr></table></figure><p></p><h3>push</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br><span class="line">git push origin yarn_hdfs:yarn_and_hdfs_tools</span><br></pre></td></tr></table></figure><p></p><h3>tag</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git ls-remote --tags upstream # 查看远端的tag列表</span><br><span class="line">git fetch --all --tags --prune # 获取远程所有的tag，如果有origin和upstream两个，那么都会拉下来 https://stackoverflow.com/questions/35979642/what-is-git-tag-how-to-create-tags-how-to-checkout-git-remote-tags  有时远端仓库更新了tag就需要拉一次</span><br><span class="line">git tag --list # 列出所有的tag</span><br><span class="line">git checkout -b tset v0.1.0  # checkout到某tag</span><br></pre></td></tr></table></figure><p></p><h3>rebase</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git rebase -i commid # [当前commit,指定commitId) 左开右闭 # 修改commit信息，合并commit, 调整commit顺序，将一个类型的commit合并在一起</span><br><span class="line">git rebase -i HEAD~2</span><br></pre></td></tr></table></figure><p></p><h3>cherry-pick</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git cherry-pick A..B # 合并单个和多个</span><br><span class="line">git cherry-pick A</span><br></pre></td></tr></table></figure><p></p><h3>reset</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard &lt;sha1-commit-id&gt; # 直接删除到这个commitId</span><br><span class="line">git reset --soft</span><br></pre></td></tr></table></figure><p></p><h3>branch</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch -m &lt;old_name&gt; &lt;new_name&gt; # 重命名 branch 名称</span><br><span class="line">git branch -m &lt;new_name&gt; # 重命名 branch 名称</span><br></pre></td></tr></table></figure><p></p><h3>log</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git log --graph --oneline --decorate # 查看提交历史,https://segmentfault.com/a/1190000008039809</span><br><span class="line">git log --merges # merge 历史</span><br></pre></td></tr></table></figure><p></p><h2>常见操作方式</h2><h3>为仓库添加一个源</h3><p>例如在内部flink仓库添加一个社区的源用以合并代码</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add upstream https://github.com/apache/flink.git</span><br><span class="line">git pull upstream master # 指定上游和分支拉取代码</span><br></pre></td></tr></table></figure><p></p><h3>设置新的分支与远程分支的对应关系</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch --set-upstream-to=origin/dev_1.3.2_minwenjun</span><br><span class="line">git branch --set-upstream release-1.2.0-100 origin/release-1.2.0-100</span><br></pre></td></tr></table></figure><p></p><h3>克隆单个分支的代码</h3><p>常用于review大的MR，单独拉取用户提交的一个分支</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone [url] -b [branch-name] --single-branch</span><br><span class="line">git clone https://github.com/sihuazhou/flink.git -b FLINK-9804 --single-branch</span><br></pre></td></tr></table></figure><p></p><h3>cherry-pick merge commit</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://stackoverflow.com/questions/9229301/git-cherry-pick-says-38c74d-is-a-merge-but-no-m-option-was-given</span><br><span class="line">git cherry-pick -m 1 fd9f578</span><br><span class="line">git show --pretty=raw fd48e1ab722c20c196adb3e68583ba0d046b9cad (merge commit)</span><br></pre></td></tr></table></figure><p></p><h3>将当前代码提交到另一个仓库</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin_repo_b git@server_ip:/path/repo_b.git</span><br><span class="line">git push origin_repo_b branch_a(要推的那个本地分支的名字)</span><br></pre></td></tr></table></figure><p></p><h3>git修改传输协议</h3><p>修改你本地的ssh remote url. 不用https协议，改用git协议</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br><span class="line">git remote set-url origin</span><br><span class="line"></span><br><span class="line">[minwenjun@bigdata-test04 flink-metric-analyse]$ git remote set-url origin git@github.com:minwenjun/flink-metric-analyse.git</span><br><span class="line">[minwenjun@bigdata-test04 flink-metric-analyse]$ git remote -v</span><br><span class="line">origin	git@ github.com:minwenjun/flink-metric-analyse.git (fetch)</span><br><span class="line">origin	git@github.com:minwenjun/flink-metric-analyse.git (push)</span><br></pre></td></tr></table></figure><p></p><p>参考资料:</p><p><a href="https://yuzhouwan.com/posts/30041/" target="_blank" rel="noopener">https://yuzhouwan.com/posts/30041/</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/maven-noclassdeffounderror.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/maven-noclassdeffounderror.html" itemprop="url">maven java.lang.NoClassDefFoundError with provided scope</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T23:12:03+08:00">2019-03-15 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/问题排查/" itemprop="url" rel="index"><span itemprop="name">问题排查</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/maven-noclassdeffounderror.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="maven-noclassdeffounderror.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">327 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">1</span></div></div></header><div class="post-body" itemprop="articleBody"><p>关于maven中执行类遇到的<code>java.lang.NoClassDefFoundError</code>的问题</p><p>&lt;!-- more --&gt;</p><p>昨天有个同事问我，在Flink某个包中加了一个类用来进行测试，结果运行就会报如下错误</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/flink/api/common/serialization/DeserializationSchema</span><br><span class="line">	at com.didi.flink.app.FlinkTableSinkTest.main(FlinkTableSinkTest.scala)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.flink.api.common.serialization.DeserializationSchema</span><br><span class="line">	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">	... 1 more</span><br></pre></td></tr></table></figure><p></p><p>排查后怀疑是pom中该jar的依赖scope是provided导致的,测试删除后就解决了。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;flink-streaming-java_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</span><br><span class="line">	&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><p>但是觉得这样会很麻烦，所有其他用到的类都需要去除provided了？顺手Google了一下，Stack Overflow上有人问过同样的问题（这个人竟然是之前blink meetup上的flink+zeppelin的演讲者<em>章剑锋（简锋）</em>）</p><p><a href="https://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij" target="_blank" rel="noopener">https://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij</a></p><p>简单的说是因为provided的scope只在编译期和test期间有效，所以正确的姿势应该是测试类就放在测试包下面测试，这样provided的包依然是有效的</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/2019-flag.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2019-flag.html" itemprop="url">to be or not to be in 2019</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T01:25:03+08:00">2019-03-15 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/杂七杂八/" itemprop="url" rel="index"><span itemprop="name">杂七杂八</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2019-flag.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019-flag.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">100 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">1</span></div></div></header><div class="post-body" itemprop="articleBody"><p>2019年的flag</p><p>&lt;!-- more --&gt;</p><p>2019年的Q1快接近尾声了，是时候给今年来一个flag了，今年有以下3个目标：</p><ol><li>跑步500公里</li><li>读书10本+ <em>技术书籍不低于3本</em></li><li>flink，netty，hbase系列的源码分析博客及仓库更新</li><li>机器学习简单入门</li><li>简单学会尤克里里的弹奏</li><li>努力工作，攒钱</li></ol><p>截止时间:</p><p>-----------------------------------2020.01.01-----------------------------------------------</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/string-stringbuilder-stringbuffer.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/string-stringbuilder-stringbuffer.html" itemprop="url">String,StringBuffer,StringBuilder的区别</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-28T00:13:48+08:00">2018-08-28 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/string-stringbuilder-stringbuffer.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="string-stringbuilder-stringbuffer.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.7k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">6</span></div></div></header><div class="post-body" itemprop="articleBody"><p>常用的jdk的组件的源码分析之：<code>String</code>,<code>StringBuffer</code>,<code>StringBuilder</code></p><p>&lt;!-- more --&gt;</p><p>String 字符串常量 StringBuffer 字符串变量（线程安全） StringBuilder 字符串变量（非线程安全）</p><p>String和StringBuffer的主要性能区别其实在于 String是不可变的对象, 因此在每次对String类型进行改变的时候其实都等同于生成了一个新的 String对象，然后将指针指向新的String对象，所以经常改变内容的字符串最好不要用String，因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后，JVM的GC就会开始工作，那速度是一定会相当慢的。</p><p>那么String为什么要是不可变的呢？</p><h3>String类不可变的好处</h3><ol><li>只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现，String interning是指对不同的字符串仅仅只保存一个，即不会保存多个相同的字符串。因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。</li><li>如果字符串是可变的，那么会引起很严重的安全问题。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变字符串指向的对象的值，造成安全漏洞。</li><li>因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。</li><li>类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。譬如你想加载java.sql.Connection类，而这个值被改成了myhacked.Connection，那么会对你的数据库造成不可知的破坏。</li><li>因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。也同时指出一个理念，千万不要把可变类型作为HashMap和HashSet的键值</li></ol><h3>在java中如何设计不可变</h3><ol><li>对于属性不提供设值的方法</li><li>所有的属性定义为private final</li><li>类声明为final不允许继承</li><li>return deep cloned objects with copied content for all mutable fields in class</li></ol><p>翻看string的源码，可以看到string的本质是个char数组，并且使用final关键字修饰。但是char数组用final修饰只能让数组的引用地址不变，array数组还是可变的，主要是SUN的工程师没有暴露内部成员字段，所以String不可变主要在底层实现，而不是在final。</p><h3>String的内存存储</h3><p>一般而言，Java 对象在虚拟机的结构如下：</p><ul><li>对象头（object header）：8 个字节</li><li>Java 原始类型数据：如 int, float, char 等类型的数据，各类型数据占内存。<ul><li>boolean 1</li><li>byte</li><li>char 2</li><li>short</li><li>int 4</li><li>long 8</li></ul></li><li>引用（reference）：4 个字节</li><li>填充符（padding）</li></ul><p>然而，一个 Java 对象实际还会占用些额外的空间，如：对象的 class 信息、ID、在虚拟机中的状态。在 Oracle JDK 的 Hotspot 虚拟机中，一个普通的对象需要额外 8 个字节。</p><p>String对象的声明</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private final char value[]; </span><br><span class="line">private final int offset; </span><br><span class="line">private final int count; </span><br><span class="line">private int hash;</span><br></pre></td></tr></table></figure><p></p><p>那么因该如何计算该 String 所占的空间？</p><p>首先计算一个空的 char 数组所占空间，在 Java 里数组也是对象，因而数组也有对象头，故一个数组所占的空间为对象头所占的空间加上数组长度，即 8 + 4 = 12 字节 , 经过填充后为 16 字节。</p><p>那么一个空 String 所占空间为：</p><p>对象头（8 字节）+ char 数组（16 字节）+ 3 个 int（3 × 4 = 12 字节）+1 个 char 数组的引用 (4 字节 ) = 40 字节。</p><p>因此一个实际的 String 所占空间的计算公式如下：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8*( ( 8+2*n+4+12)+7 ) / 8 = 8*(int) ( ( ( (n) *2 )+43) /8 )</span><br></pre></td></tr></table></figure><p></p><p>在java中对String对象特殊对待，所以在heap上分为两块，一块是String constant pool存储java字符串常量，另一块存储普通对象和字符串对象，主要区别：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String a = &quot;abc&quot;;</span><br><span class="line">String b = new String(&quot;acb&quot;)</span><br></pre></td></tr></table></figure><p></p><p>第一种jvm会先去查找constant pool是否存在此常量，不存在就在constant pool上进行创建，第二种是在堆上创建对象，并且不会加入到constant pool上，因此可能会带来字符串重复占用内存的问题。可以调用String.intern()加入到String constant pool中，其实是JVM heap 中 PermGen 相应的区域。</p><p>jdk1.6和1.7还有所不同，jdk1.7的常量池是在堆中的</p><h3>StringBuffer</h3><p>StringBuffer和String不同，每次修改都会对 StringBuffer 对象本身进行操作，而不是生成新的对象，再改变对象引用。所以在一般情况下我们推荐使用 StringBuffer ，特别是字符串对象经常改变的情况下。而在某些特别情况下， String 对象的字符串拼接其实是被JVM解释成了 StringBuffer 对象的拼接，所以这些时候 String 对象的速度并不会比 StringBuffer 对象慢，而特别是以下的字符串对象生成中， String效率是远要比 StringBuffer 快的：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String S1 = “This is only a” + “ simple” + “ test”;</span><br><span class="line">StringBuffer Sb = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);</span><br></pre></td></tr></table></figure><p></p><p>你会很惊讶的发现，生成 String S1 对象的速度简直太快了，而这个时候 StringBuffer 居然速度上根本一点都不占优势。其实这是 JVM 的一个把戏，在 JVM 眼里，这个</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String S1 = “This is only a” + “ simple” + “test”;</span><br><span class="line">其实就是：</span><br><span class="line">String S1 = “This is only a simple test”;</span><br></pre></td></tr></table></figure><p></p><p>当然不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的 String 对象的话，速度就没那么快了，譬如：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String S2 = “This is only a”;</span><br><span class="line">String S3 = “ simple”;</span><br><span class="line">String S4 = “ test”;</span><br><span class="line">String S1 = S2 +S3 + S4;</span><br></pre></td></tr></table></figure><p></p><p>这时候 JVM 会规规矩矩的按照原来的方式去做</p><p><a href="https://www.ibm.com/developerworks/cn/java/j-lo-optmizestring/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/java/j-lo-optmizestring/index.html</a></p><p><a href="https://blog.csdn.net/qq_36357995/article/details/79985538" target="_blank" rel="noopener">https://blog.csdn.net/qq_36357995/article/details/79985538</a></p><p><a href="https://segmentfault.com/a/1190000004261063" target="_blank" rel="noopener">https://segmentfault.com/a/1190000004261063</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/rocksdb-wiki.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/rocksdb-wiki.html" itemprop="url">rocksdb概念简介</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-23T23:20:44+08:00">2018-08-23 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/刨根问底/" itemprop="url" rel="index"><span itemprop="name">刨根问底</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/rocksdb-wiki.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="rocksdb-wiki.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.6k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">5</span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文翻译自：https://github.com/facebook/rocksdb/wiki/rocksdb-basics</p><p>主要是rocksdb的一些概念理解和介绍</p><p>&lt;!-- more --&gt;</p><p>rocksdb主要组成部分memtable,sstfile,logfile，rocksdb 支持将database切分成多个columnFamily，所有的数据库创建如果没有指定的话会是一个default column 他支持批量原子写入，key和value都是纯byte流，key和value的大小都没有做限制</p><p>所有database中的数据都是以一个有序的形式被放置（怎么做的呢？后append的数据怎么有序），应用可以指定key的comparison方法，来指定key的排序方式，Iterator API可以在database做一个RangeScan操作，他会指向一个特定的key，然后进行一个一个遍历。在调用iterator的时候会创建database的即时视图，因此所有查询的key都是一致的。</p><h3>Snapshot</h3><p>Snapshot Api也支持创建database某一时间点的视图，Get和Iterator Api可以用以读取指定snapshot的数据，从某种意义上说，snapshot和iterator都会提供database的当前视图，但是他们的实现不同。iterator是短期的/前台线程的scan，而长期/后台的scan最好是通过snapshot。iterator会对所有底层与pint-in-time database视图相关的的文件保留一个引用计数，这些文件知道iterator结束之后才会被删除。然而snapshot不会阻碍文件的删除，取而代之的是在compaction的过程会意识到snapshots的存在，直接不会删除在已经存在于snapshot中的key。snapshot在database重启的会丢失，reload rocksdb library会释放所有的snapshot</p><h3>Prefix Iterators</h3><p>大多数基于LSM设计的存储引擎都不太能支持高效的RangeScan API，因为他需要查阅每个文件，但是真正的应用并不是纯粹的随机读取key，一般会以一个key-prefix去查询，rocksdb利用了这个特点做了一些优化。应用可以配置prefix_extractor来指定key-prefix，rocksdb决定，存储的blooms，iterator可以通过ReadOptios指定prefix，然后rocksDB将会使用这些bloom bits来避免查询那些不包含那些key-perfix开始的key的文件。</p><h3>Persistence</h3><p>rocksdb有一个事务日志，所有的puts操作会被存储在memtables中，同时也会可选的写入事务日志中，在重启的时候，会重新执行事务日志中的记录。事务日志可以配置和sst文件放在不同的目录。这是因为有时你并不想持久化数据文件，同时又可以将事务日志持久化到一个相对较慢的持久化存储中，来确保数据不会丢失。 每一个Put都有一个标志，通过WriteOptios来标志是否需要写入事务日志中，同时也可以配置是否需要同步等到数据已经被写入到事务日志完成之后才将Put操作标记为commit完成。</p><p>在内部实现中，RocksDB会使用batch-commit的机制去批量的将事务操作提交到事务日志中，所以在一次同步调用中会提交多个transactions</p><h3>Fault Tolerance</h3><p>Rocksdb使用checksum去检测存储是否有损坏</p><h3>Multi-Threaded Compactions</h3><p>compaction的存在是为了删除同一个key的多个副本，这种情况发生在用户更新了某个key的值，compaction也负责将要删除的key进行删除。整个database是存储在sstable中的，当memtable满了的时候会写入到Level-0（L0）的文件中，RocksDB在将数据从memtable flush到文件的时候会先将重复的key进行删除。然后一些文件会周期性的读入并形成更大的文件，这就是compaction的过程。</p><p>对于一个LSM的database的写入的吞吐量取决于compaction所能达到的速度，特别是数据存储在ssd或者RAM中。RocksDB可以配置为启用多个并发compaction线程。据观察，与单线程compaction相比，基于ssd的数据库的持续写入速率可能在多线程compaction的情况下增加10倍之多</p><h3>compaction Styles</h3><p>通常的style的compaction是完全基于排序的，运行与L0文件或者L1+. Compaction会挑选一些按时间顺序相邻文件，然后将其合并成一个新的sstable</p><p>level style compaction在数据库存储会分为多个等级，最近的数据存储在L0层，最老的数据存储在Lmax层，只有L0层会存在重叠的key，一次compaction会将Ln的file和Ln+1的file做compaction然后形成新的文件替换Ln+1的文件，Universal Style 和Level style相比通常会有较低的写入放大但是较高的磁盘占用和读放大</p><p>（写入放大）： https://www.zhihu.com/question/31024021 https://www.wikiwand.com/zh-hans/%E5%86%99%E5%85%A5%E6%94%BE%E5%A4%A7</p><p>同时RocksDB也支持用户自定义compaction方式，可以通过<code>Options.disable_auto_compaction</code>关闭原生的compaction算法，同时<code>GetLiveFilesMetaData</code>接口可以让外置组件查看每一个database中的数据文件从而决定哪些数据需要merge和合并。通过调用<code>CompactFiles</code>来进行文件的合并，<code>DeleteFile</code>来进行文件的删除</p><h3>metadata storage</h3><p>数据库中的MANIFEST文件记录了数据库的状态，compaction线程会新增新文件，删除旧文件，这些操作会通过 MANIFEST记录来持久化，同样记录操作也是用了batch-commit的算法来缓冲重复的对MANIFEST文件的同步写入</p><h3>Avoiding Stalls</h3><p>后台的compaction线程会将memtable中的内容flush到文件中，如果所有的后台线程都忙着做长时间的compaction，那么突然一个大流量的写入可能就会把memtable写满，这就会导致新的写入被hung住，这个问题可以通过配置rocksdb保持特定的几个线程专门保留来进行flush操作</p><h3>Compaction Filter</h3><p>一些应用可能在compaction的时候可能期望对key做出一些处理，比如数据库内部实现可能需要支持TTL，来删除过期的key，这可以通过自定义实现compaction filter来实现。他提供了用户在compaction的过程中修改key value以及丢弃这个key的数据的能力</p><h3>Read only mode</h3><p>database可以以read only的模式打开这样数据库保证所有的数据都不可修改，同时也会极大的提升读性能，因为完全了避免了锁</p><h3>Full Backups, Incremental Backups and Replication</h3><p>RocksDB支持增量的备份，BackupableDB使得Rocksdb的备份很简单，后续会深入介绍</p><p>增量的复制需要能够找到数据库最近的改变，GetUpdatesSince API支持应用tail最近的事务日志，因此他能够连续的获取事务日志，然后将其应用于远程的复制或者备份</p><p>未完待续</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-state.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-state.html" itemprop="url">flink中状态实现的深入理解</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T16:35:29+08:00">2018-08-04 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-state.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-state.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">3.2k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">13</span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文是源于要在内部分享，所以提前整理了一些flink中的状态的一些知识，flink状态所包含的东西很多，在下面列举了一些，还有一 些在本文没有体现，后续会单独的挑出来再进行讲解</p><p>&lt;!-- more --&gt;</p><ul><li>state的层次结构</li><li>keyedState =&gt; windowState</li><li>OperatorState =&gt; kafkaOffset</li><li>stateBackend</li><li>snapshot/restore</li><li><em>internalTimerService</em></li><li><strong>RocksDB操作的初探</strong></li><li><em>state ttL</em></li><li><em>state local recovery</em></li><li><strong>QueryableState</strong></li><li><strong>increamental checkpoint</strong></li><li>state redistribution</li><li><em>broadcasting state</em></li><li><strong>CheckpointStreamFactory</strong></li></ul><hr><h3>内部和外部状态</h3><p>flink状态分为了内部和外部使用接口，但是两个层级都是一一对应，内部接口都实现了外部接口，主要是有两个目的</p><ul><li>内部接口提供了更多的方法，包括获取state中的serialize之后的byte，以及Namespace的操作方法。内部状态主要用于内部runtime实现时所需要用到的一些状态比如window中的windowState，CEP中的sharedBuffer,kafkaConsumer中offset管理的ListState,而外部State接口主要是用户自定义使用的一些状态</li><li>考虑到各个版本的兼容性，外部接口要保障跨版本之间的兼容问题，而内部接口就很少受到这个限制，因此也就比较灵活</li></ul><p>层次结构图：</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-8-2/82936981.jpg" alt></p><h3>状态的使用</h3><p>了解了flink 状态的层次结构，那么编程中和flink内部是如何使用这些状态呢？</p><p>flink中使用状态主要是两部分，一部分是函数中使用状态，另一部分是在operator中使用状态</p><p>方式：</p><ul><li>CheckpointedFunction</li><li>ListCheckpointed</li><li>RuntimeContext （DefaultKeyedStateStore）</li><li>StateContext</li></ul><p>StateContext</p><p>StateInitializationContext</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Iterable&lt;StatePartitionStreamProvider&gt; getRawOperatorStateInputs();</span><br><span class="line"></span><br><span class="line">Iterable&lt;KeyGroupStatePartitionStreamProvider&gt; getRawKeyedStateInputs();</span><br></pre></td></tr></table></figure><p></p><p>ManagedInitializationContext</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OperatorStateStore getOperatorStateStore();</span><br><span class="line">KeyedStateStore getKeyedStateStore();</span><br></pre></td></tr></table></figure><p></p><p>举例：</p><ol><li><p>AbstractStreamOperator封装了这个方法<code>initializeState(StateInitializationContext context)</code>用以在operator中进行raw和managed的状态管理</p></li><li><p>CheckpointedFunction的用法其实也是借助于StateContext进行相关实现</p></li></ol><p><code>CheckpointedFunction#initializeState</code>方法在transformation function的各个并发实例初始化的时候被调用这个方法提供了<code>FunctionInitializationContext</code>的对象，可以通过这个<code>context</code>来获取<code>OperatorStateStore</code>或者<code>KeyedStateStore</code>，也就是说通过这个接口可以注册这两种类型的State，这也是和ListCheckpointed接口不一样的地方，只是说<code>KeyedStateStore</code>只能在keyedstream上才能注册，否则就会报错而已,以下是一个使用这两种类型状态的样例。 可以参见<code>FlinkKafkaConsumerBase</code>通过这个接口来实现offset的管理。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public class MyFunction&lt;T&gt; implements MapFunction&lt;T, T&gt;, CheckpointedFunction &#123;</span><br><span class="line"></span><br><span class="line">     private ReducingState&lt;Long&gt; countPerKey;</span><br><span class="line">     private ListState&lt;Long&gt; countPerPartition;</span><br><span class="line"></span><br><span class="line">     private long localCount;</span><br><span class="line"></span><br><span class="line">     public void initializeState(FunctionInitializationContext context) throws Exception &#123;</span><br><span class="line">         // get the state data structure for the per-key state</span><br><span class="line">         countPerKey = context.getKeyedStateStore().getReducingState(</span><br><span class="line">                 new ReducingStateDescriptor&lt;&gt;(&quot;perKeyCount&quot;, new AddFunction&lt;&gt;(), Long.class));</span><br><span class="line"></span><br><span class="line">         // get the state data structure for the per-partition state</span><br><span class="line">         countPerPartition = context.getOperatorStateStore().getOperatorState(</span><br><span class="line">                 new ListStateDescriptor&lt;&gt;(&quot;perPartitionCount&quot;, Long.class));</span><br><span class="line"></span><br><span class="line">         // initialize the &quot;local count variable&quot; based on the operator state</span><br><span class="line">         for (Long l : countPerPartition.get()) &#123;</span><br><span class="line">             localCount += l;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     public void snapshotState(FunctionSnapshotContext context) throws Exception &#123;</span><br><span class="line">         // the keyed state is always up to date anyways</span><br><span class="line">         // just bring the per-partition state in shape</span><br><span class="line">         countPerPartition.clear();</span><br><span class="line">         countPerPartition.add(localCount);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     public T map(T value) throws Exception &#123;</span><br><span class="line">         // update the states</span><br><span class="line">         countPerKey.add(1L);</span><br><span class="line">         localCount++;</span><br><span class="line"></span><br><span class="line">         return value;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p></p><p>这个Context的继承接口StateSnapshotContext的方法则提供了raw state的存储方法，但是其实没有对用户函数提供相应的接口，只是在引擎中有相关的使用，相比较而言这个接口提供的方法，context比较多，也有一些简单的方法去注册使用operatorstate 和 keyedState。如通过<code>RuntimeContext</code>注册keyedState:</p><p>因此使用简易化程度为:</p><blockquote><p>RuntimeContext &gt; FunctionInitializationContext &gt; StateSnapshotContext</p></blockquote><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">keyedStream.map(new RichFlatMapFunction&lt;MyType, List&lt;MyType&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">     private ListState&lt;MyType&gt; state;</span><br><span class="line"></span><br><span class="line">     public void open(Configuration cfg) &#123;</span><br><span class="line">         state = getRuntimeContext().getListState(</span><br><span class="line">                 new ListStateDescriptor&lt;&gt;(&quot;myState&quot;, MyType.class));</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     public void flatMap(MyType value, Collector&lt;MyType&gt; out) &#123;</span><br><span class="line">         if (value.isDivider()) &#123;</span><br><span class="line">             for (MyType t : state.get()) &#123;</span><br><span class="line">                 out.collect(t);</span><br><span class="line">             &#125;</span><br><span class="line">         &#125; else &#123;</span><br><span class="line">             state.add(value);</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;);</span><br></pre></td></tr></table></figure><p></p><p>通过实现<code>ListCheckpointed</code>来注册OperatorState，但是这个有限制： 一个function只能注册一个state，因为并不能像其他接口一样指定state的名字.</p><p>example：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class CountingFunction&lt;T&gt; implements MapFunction&lt;T, Tuple2&lt;T, Long&gt;&gt;, ListCheckpointed&lt;Long&gt; &#123;</span><br><span class="line"></span><br><span class="line">     // this count is the number of elements in the parallel subtask</span><br><span class="line">     private long count;</span><br><span class="line"></span><br><span class="line">     &#123;@literal @&#125;Override</span><br><span class="line">     public List&lt;Long&gt; snapshotState(long checkpointId, long timestamp) &#123;</span><br><span class="line">         // return a single element - our count</span><br><span class="line">         return Collections.singletonList(count);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     &#123;@literal @&#125;Override</span><br><span class="line">     public void restoreState(List&lt;Long&gt; state) throws Exception &#123;</span><br><span class="line">         // in case of scale in, this adds up counters from different original subtasks</span><br><span class="line">         // in case of scale out, list this may be empty</span><br><span class="line">         for (Long l : state) &#123;</span><br><span class="line">             count += l;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     &#123;@literal @&#125;Override</span><br><span class="line">     public Tuple2&lt;T, Long&gt; map(T value) &#123;</span><br><span class="line">         count++;</span><br><span class="line">         return new Tuple2&lt;&gt;(value, count);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p></p><p>下面比较一下里面的两种stateStore</p><ul><li>KeyedStateStore</li><li>OperatorStateStore</li></ul><p>查看OperatorStateStore接口可以看到OperatorState只提供了ListState一种形式的状态接口,OperatorState和KeyedState主要有以下几个区别：</p><ul><li>keyedState只能应用于KeyedStream，而operatorState都可以</li><li>keyedState可以理解成一个算子为每个subtask的每个key维护了一个状态namespace，而OperatorState是每个subtask共享一个状态</li><li>operatorState只提供了ListState，而keyedState提供了<code>ValueState</code>,<code>ListState</code>,<code>ReducingState</code>,<code>MapState</code></li><li>operatorStateStore的默认实现只有<code>DefaultOperatorStateBackend</code>可以看到他的状态都是存储在堆内存之中，而keyedState根据backend配置的不同，线上都是存储在rocksdb之中</li></ul><h3>snapshot</h3><p>这个让我们着眼于两个Operator的snapshot，<code>AbstractStreamOperator</code> 和 <code>AbstractUdfStreamOperator</code>,这两个基类几乎涵盖了所有相关operator和function在做snapshot的时候会做的处理。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if (null != operatorStateBackend) &#123;</span><br><span class="line">				snapshotInProgress.setOperatorStateManagedFuture(</span><br><span class="line">					operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (null != keyedStateBackend) &#123;</span><br><span class="line">				snapshotInProgress.setKeyedStateManagedFuture(</span><br><span class="line">					keyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><ol><li>按keyGroup去snapshot各个timerService的状态，包括processingTimer和eventTimer（RawKeyedOperatorState）</li><li>将operatorStateBackend和keyedStateBackend中的状态做snapshot</li><li>如果Operator还包含了userFunction，即是一个<code>UdfStreamOperator</code>,那么可以注意到udfStreamOperator覆写了父类的<code>snapshotState(StateSnapshotContext context)</code>方法，其主要目的就是为了将Function中的状态及时的register到相应的backend中，在第二步的时候统一由<code>CheckpointStreamFactory</code>去做快照</li></ol><h4>StreamingFunctionUtils#snapshotFunctionState</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">if (userFunction instanceof CheckpointedFunction) &#123;</span><br><span class="line">			((CheckpointedFunction) userFunction).snapshotState(context);</span><br><span class="line"></span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (userFunction instanceof ListCheckpointed) &#123;</span><br><span class="line">			@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">			List&lt;Serializable&gt; partitionableState = ((ListCheckpointed&lt;Serializable&gt;) userFunction).</span><br><span class="line">				snapshotState(context.getCheckpointId(), context.getCheckpointTimestamp());</span><br><span class="line"></span><br><span class="line">			ListState&lt;Serializable&gt; listState = backend.</span><br><span class="line">				getSerializableListState(DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME);</span><br><span class="line"></span><br><span class="line">			listState.clear();</span><br><span class="line"></span><br><span class="line">			if (null != partitionableState) &#123;</span><br><span class="line">				try &#123;</span><br><span class="line">					for (Serializable statePartition : partitionableState) &#123;</span><br><span class="line">						listState.add(statePartition);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125; catch (Exception e) &#123;</span><br><span class="line">					listState.clear();</span><br><span class="line"></span><br><span class="line">					throw new Exception(&quot;Could not write partitionable state to operator &quot; +</span><br><span class="line">						&quot;state backend.&quot;, e);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以看到这里就只有以上分析的两种类型的checkpoined接口，<code>CheckpointedFunction</code>，只需要执行相应的snapshot方法，相应的函数就已经将要做snapshot的数据打入了相应的state中，而<code>ListCheckpointed</code>接口由于返回的是个List，所以需要手动的通过<code>getSerializableListState</code>注册一个<code>ListState</code>(<em>这也是ListCheckpointed只能注册一个state的原因</em>),然后将List数据挨个存入ListState中。</p><h4>operatorStateBackend#snapshot</h4><ol><li>针对所有注册的state作deepCopy,为了防止在checkpoint的时候数据结构又被修改，deepcopy其实是通过序列化和反序列化的过程（参见<a href="http://aitozi.com/java-serialization.html" target="_blank" rel="noopener">http://aitozi.com/java-serialization.html</a>）</li><li>异步将state以及metainfo的数据写入到hdfs中，使用的是flink的asyncIO（这个也可以后续深入了解下），并返回相应的statehandle用作restore的过程</li><li>在StreamTask触发checkpoint的时候会将一个Task中所有的operator触发一次snapshot，触发部分就是上面1，2两个步骤，其中第二步是会返回一个RunnableFuture，在触发之后会提交一个<code>AsyncCheckpointRunnable</code>异步任务，会阻塞一直等到checkpoint的<code>Future</code>，其实就是去调用这个方法<code>AbstractAsyncIOCallable</code>, 直到完成之后OperatorState会返回一个<code>OperatorStateHandle</code>,这个地方和后文的keyedState返回的handle不一样。</li></ol><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">	public V call() throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		synchronized (this) &#123;</span><br><span class="line">			if (isStopped()) &#123;</span><br><span class="line">				throw new IOException(&quot;Task was already stopped. No I/O handle opened.&quot;);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			ioHandle = openIOHandle();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line"></span><br><span class="line">			return performOperation();</span><br><span class="line"></span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			closeIOHandle();</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><p>在managed keyedState、managed operatorState、raw keyedState、和raw operatorState都完成返回相应的Handle之后，会生成一个SubTaskState来ack jobmanager,这个主要是用在restore的过程中</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SubtaskState subtaskState = createSubtaskStateFromSnapshotStateHandles(</span><br><span class="line">					chainedNonPartitionedOperatorsState,</span><br><span class="line">					chainedOperatorStateBackend,</span><br><span class="line">					chainedOperatorStateStream,</span><br><span class="line">					keyedStateHandleBackend,</span><br><span class="line">					keyedStateHandleStream);</span><br><span class="line">					</span><br><span class="line">owner.getEnvironment().acknowledgeCheckpoint(</span><br><span class="line">	checkpointMetaData.getCheckpointId(),</span><br><span class="line">	checkpointMetrics,</span><br><span class="line">	subtaskState);</span><br></pre></td></tr></table></figure><p></p><p>在jm端，ack的时候又将各个handle封装在<code>pendingCheckpoint =&gt; operatorStates =&gt; operatorState =&gt; operatorSubtaskState</code>中,最后无论是savepoint或者是externalCheckpoint都会将相应的handle序列化存储到hdfs，这也就是所谓的checkpoint元数据。这个可以起个任务观察下zk和hdfs上的文件，补充一下相关的验证。</p><p>至此完成operator state的snapshot/checkpoint阶段</p><h4>KeyedStateBackend#snapshot</h4><p>和operatorStateBackend一样，snapshot也分为了同步和异步两个部分。</p><ol><li>rocksDB的keyedStateBackend的snapshot提供了增量和全量两种方式</li><li>利用rocksdb自身的snapshot进行<code>this.snapshot = stateBackend.db.getSnapshot();</code> 这个过程是同步的，rocksdb这块是怎么snapshot还不是很了解，待后续学习</li><li>之后也是一样异步将数据写入hdfs，返回相应的keyGroupsStateHandle <code>snapshotOperation.closeCheckpointStream();</code></li></ol><p>不同的地方在于增量返回的是<code>IncrementalKeyedStateHandle</code>,而全量返回的是<code>KeyGroupsStateHandle</code>，</p><h3>restore / redistribution</h3><h4>OperatorState的rescale</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void setInitialState(TaskStateHandles taskStateHandles) throws Exception;</span><br></pre></td></tr></table></figure><p></p><p>一个task在真正的执行任务之前所需要做的事情是把状态inject到task中，如果一个任务是失败之后从上次的checkpoint点恢复的话，他的状态就是非空的。streamTask也就靠是否有这样的一个恢复状态来确认算子是不是在restore来branch他的启动逻辑</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (null != taskStateHandles) &#123;</span><br><span class="line">		if (invokable instanceof StatefulTask) &#123;</span><br><span class="line">			StatefulTask op = (StatefulTask) invokable;</span><br><span class="line">			op.setInitialState(taskStateHandles);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			throw new IllegalStateException(&quot;Found operator state for a non-stateful task invokable&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">		// be memory and GC friendly - since the code stays in invoke() for a potentially long time,</span><br><span class="line">		// we clear the reference to the state handle</span><br><span class="line">		//noinspection UnusedAssignment</span><br><span class="line">		taskStateHandles = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>那么追根究底一下这个Handle是怎么带入的呢？</p><p><code>FixedDelayRestartStrategy =&gt; triggerFullRecovery =&gt; Execution#restart =&gt; Execution#scheduleForExecution =&gt; Execution#deployToSlot =&gt; ExecutionVertex =&gt; TaskDeploymentDescriptor =&gt; taskmanger =&gt; task</code></p><p>当然还有另一个途径就是通过向jobmanager submitJob的时候带入restore的checkpoint path， 这两种方式最终都会通过<code>checkpointCoordinator#restoreLatestCheckpointedState</code>来恢复hdfs中的状态来获取到snapshot时候存入的StateHandle。</p><p>恢复的过程如何进行redistribution呢？ 也就是大家关心的并发度变了我的状态的行为是怎么样的。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// re-assign the task states</span><br><span class="line">final Map&lt;OperatorID, OperatorState&gt; operatorStates = latest.getOperatorStates();</span><br><span class="line"></span><br><span class="line">StateAssignmentOperation stateAssignmentOperation =</span><br><span class="line">		new StateAssignmentOperation(tasks, operatorStates, allowNonRestoredState);</span><br><span class="line"></span><br><span class="line">stateAssignmentOperation.assignStates();</span><br></pre></td></tr></table></figure><p></p><ol><li>如果并发度没变那么不做重新的assign，除非state的模式是broadcast，会将一个task的state广播给所有的task</li><li>对于operator state会针对每一个name的state计算出每个subtask中的element个数之和（这就要求每个element之间相互独立）进行roundrobin分配</li><li>keyedState的重新分配相对简单，就是根据新的并发度和最大并发度计算新的keygroupRange，然后根据subtaskIndex获取keyGroupRange，然后获取到相应的keyStateHandle完成状态的切分。</li></ol><p>这里补充关于raw state和managed state在rescale上的差别，由于operator state在reassign的时候是根据metaInfo来计算出所有的List&lt;element&gt;来重新分配，operatorbackend中注册的状态是会保存相应的metainfo，最终也会在snapshot的时候存入OperatorHandle，那raw state的metainfo是在哪里呢？</p><p>其实会在写入hdfs返回相应的handle的时候构建一个默认的，<code>OperatorStateCheckpointOutputStream#closeAndGetHandle</code>,其中状态各个partition的构建来自<code>startNewPartition</code>方法，引擎中我所看到的rawstate仅有timerservice的raw keyedState</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">OperatorStateHandle closeAndGetHandle() throws IOException &#123;</span><br><span class="line">		StreamStateHandle streamStateHandle = delegate.closeAndGetHandle();</span><br><span class="line"></span><br><span class="line">		if (null == streamStateHandle) &#123;</span><br><span class="line">			return null;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (partitionOffsets.isEmpty() &amp;&amp; delegate.getPos() &gt; initialPosition) &#123;</span><br><span class="line">			startNewPartition();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Map&lt;String, OperatorStateHandle.StateMetaInfo&gt; offsetsMap = new HashMap&lt;&gt;(1);</span><br><span class="line"></span><br><span class="line">		OperatorStateHandle.StateMetaInfo metaInfo =</span><br><span class="line">				new OperatorStateHandle.StateMetaInfo(</span><br><span class="line">						partitionOffsets.toArray(),</span><br><span class="line">						OperatorStateHandle.Mode.SPLIT_DISTRIBUTE);</span><br><span class="line"></span><br><span class="line">		offsetsMap.put(DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME, metaInfo);</span><br><span class="line"></span><br><span class="line">		return new OperatorStateHandle(offsetsMap, streamStateHandle);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><h4>KeyedState的keyGroup</h4><p>keyedState重新分配里引入了一个keyGroup的概念，那么这里为什么要引入keygroup这个概念呢？</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-8-3/53377760.jpg" alt></p><p><img src="http://or0igopk2.bkt.clouddn.com/18-8-3/18711916.jpg" alt></p><ol><li>hash(key) = key(identity)</li><li>key_group(key) = hash(key) % number_of_key_groups (等于最大并发)，默认flink任务会设置一个max parallel</li><li>subtask(key) = key_greoup(key) * parallel / number_of_key_groups</li></ol><ul><li>避免在恢复的时候带来随机IO</li><li>避免每个subtask需要将所有的状态数据读取出来pick和自己subtask相关的浪费了很多io资源</li><li>减少元数据的量，不再需要保存每次的key，每一个keygroup组只需保留一个range</li></ul><p>实际实现上的keyGroup range和上图有区别，是连续的:</p><p>比如：subtask1: [0-10], subtask2: [11-12] ...</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int start = operatorIndex == 0 ? 0 : ((operatorIndex * maxParallelism - 1) / parallelism) + 1;</span><br><span class="line">int end = ((operatorIndex + 1) * maxParallelism - 1) / parallelism;</span><br><span class="line">return new KeyGroupRange(start, end);</span><br></pre></td></tr></table></figure><p></p><ul><li>每一个backend（subtask）上只有一个keygroup range</li><li>每一个subtask在restore的时候就接收到了已经分配好的和重启后当前这个并发相绑定的keyStateHandle</li></ul><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">subManagedKeyedState = getManagedKeyedStateHandles(operatorState, keyGroupPartitions.get(subTaskIndex));</span><br><span class="line">subRawKeyedState = getRawKeyedStateHandles(operatorState, keyGroupPartitions.get(subTaskIndex));</span><br></pre></td></tr></table></figure><p></p><p>这里面关键的一步在于，根据新的subtask上的keyGroupRange，从原来的operator的keyGroupsStateHandle中求取本subtask所关心的一部分Handle，可以看到每个KeyGroupsStateHandle都维护了<code>KeyGroupRangeOffsets</code>这样一个变量，来标记这个handle所覆盖的keygrouprange，以及keygrouprange在stream中offset的位置，可以看下再snapshot的时候会记录offset到这个对象中来</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keyGroupRangeOffsets.setKeyGroupOffset(mergeIterator.keyGroup(), outStream.getPos());</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public KeyGroupRangeOffsets getIntersection(KeyGroupRange keyGroupRange) &#123;</span><br><span class="line">		Preconditions.checkNotNull(keyGroupRange);</span><br><span class="line">		KeyGroupRange intersection = this.keyGroupRange.getIntersection(keyGroupRange);</span><br><span class="line">		long[] subOffsets = new long[intersection.getNumberOfKeyGroups()];</span><br><span class="line">		if(subOffsets.length &gt; 0) &#123;</span><br><span class="line">			System.arraycopy(</span><br><span class="line">					offsets,</span><br><span class="line">					computeKeyGroupIndex(intersection.getStartKeyGroup()),</span><br><span class="line">					subOffsets,</span><br><span class="line">					0,</span><br><span class="line">					subOffsets.length);</span><br><span class="line">		&#125;</span><br><span class="line">		return new KeyGroupRangeOffsets(intersection, subOffsets);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p>KeyGroupsStateHandle是一个subtask的所有state的一个handle KeyGroupsStateHandle维护一个KeyGroupRangeOffsets， KeyGroupRangeOffsets维护一个KeyGroupRange和offsets KeyGroupRange维护多个KeyGroup KeyGroup维护多个key</p><p>KeyGroupsStateHandle和operatorStateHandle还有一个不同点，operatorStateHandle维护了metainfo中的offset信息用在restore时的reassign，原因在于KeyGroupsStateHandle的reassign不依赖这些信息，当然在restore的时候也需要keygroupOffset中的offset信息来重新构建keyGroupsStateHandle来进行各个task的状态分配。</p><p>参考：</p><p><a href="https://flink.apache.org/features/2017/07/04/flink-rescalable-state.html" target="_blank" rel="noopener">https://flink.apache.org/features/2017/07/04/flink-rescalable-state.html</a></p><p><a href="http://chenyuzhao.me/2017/12/24/Flink-%E5%88%86%E5%B8%83%E5%BC%8F%E5%BF%AB%E7%85%A7%E7%9A%84%E8%AE%BE%E8%AE%A1-%E5%AD%98%E5%82%A8/" target="_blank" rel="noopener">http://chenyuzhao.me/2017/12/24/Flink-分布式快照的设计-存储/</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/dig-protobuf.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/dig-protobuf.html" itemprop="url">Protobuf深入理解</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-28T23:28:01+08:00">2018-07-28 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/刨根问底/" itemprop="url" rel="index"><span itemprop="name">刨根问底</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/dig-protobuf.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="dig-protobuf.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">3.3k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">13</span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文带你深入理解和使用protobuf</p><p>&lt;!--more--&gt;</p><h2>简介</h2><p>Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。目前提供了 C++、Java、Python、Go 等语言的 API</p><p>使用protobuf需要这样几个步骤：</p><ul><li>在<code>.proto</code>文件中定义消息的格式</li><li>通过protoBuffer compiler编译生成相应的java类</li><li>通过Java protocol buffer Api来write和read相关的对象</li></ul><p>关于PB的操作方式见： <a href="https://developers.google.com/protocol-buffers/docs/javatutorial" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/docs/javatutorial</a></p><hr><p>protobuf的序列化快的原因主要在于其编码实现和封解包的速度</p><h2>Protobuf编码</h2><h3>Base 128 Varints 编码</h3><p>数据传输中出于IO的考虑，我们会希望尽可能的对数据进行压缩。 Varint就是一种对数字进行编码的方法，编码后二进制数据是不定长的，数值越小的数字使用的字节数越少。例如对于int32_t，采用Varint编码后需要1~5个bytes，小的数字使用1个byte，大的数字使用5个bytes。基于实际场景中小数字的使用远远多于大数字，因此通过Varint编码对于大部分场景都可以起到一个压缩的效果。Varint的主要想法就是以标志位替换掉高字节的若干个0</p><p>下图是数字131415的variant编码,通过3个字节来表示131415 <img src="http://or0igopk2.bkt.clouddn.com/18-7-28/50478975.jpg" alt></p><p>其中第一个字节的高位msb（Most Significant Bit ）为1表示下一个字节还有有效数据，msb为0表示该字节中的后7为是最后一组有效数字。踢掉最高位后的有效位组成真正的数字。注意到最终计算前将两个 byte 的位置相互交换过一次，这是因为 Google Protocol Buffer 字节序采用 little-endian（即低位字节排放在内存的低地址端） 的方式</p><p>从上面可以看出，variant编码存储比较小的整数时很节省空间，小于等于127的数字可以用一个字节存储。但缺点是对于大于</p><p>268,435,455（0xfffffff）的整数需要5个字节来存储。但是一般情况下（尤其在tag编码中）不会存储这么大的整数。</p><p>关于int32的varint编码代码</p><p></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">EncodeVarint32</span><span class="params">(<span class="keyword">char</span>* dst, <span class="keyword">uint32_t</span> v)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Operate on characters as unsigneds</span></span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">char</span>* ptr = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>*&gt;(dst);</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> B = <span class="number">128</span>;</span><br><span class="line">  <span class="keyword">if</span> (v &lt; (<span class="number">1</span>&lt;&lt;<span class="number">7</span>)) &#123;</span><br><span class="line">    *(ptr++) = v;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span>&lt;&lt;<span class="number">14</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = v&gt;&gt;<span class="number">7</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span>&lt;&lt;<span class="number">21</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = v&gt;&gt;<span class="number">14</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span>&lt;&lt;<span class="number">28</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">14</span>) | B;</span><br><span class="line">    *(ptr++) = v&gt;&gt;<span class="number">21</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">14</span>) | B;</span><br><span class="line">    *(ptr++) = (v&gt;&gt;<span class="number">21</span>) | B;</span><br><span class="line">    *(ptr++) = v&gt;&gt;<span class="number">28</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h3>Message Structure编码</h3><p>protocol buffer 中 message 是一系列键值对。message 的二进制版本只是使用字段号(field's number 和 wire_type)作为 key。每个字段的名称和声明类型只能在解码端通过引用消息类型的定义（即 .proto 文件）来确定。这一点也是人们常常说的 protocol buffer 比 JSON，XML 安全一点的原因，如果没有数据结构描述 .proto 文件，拿到数据以后是无法解释成正常的数据的。</p><p>当消息编码时，键和值被连接成一个字节流。当消息被解码时，解析器需要能够跳过它无法识别的字段。这样，可以将新字段添加到消息中，而不会破坏不知道它们的旧程序。这就是所谓的 “向后”兼容性。</p><p>为此，线性的格式消息中每对的“key”实际上是两个值，其中一个是来自.proto文件的字段编号，加上提供正好足够的信息来查找下一个值的长度。在大多数语言实现中，这个 key 被称为 tag</p><p>wireType</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-7-28/87891770.jpg" alt></p><p>key 的计算方法是 (field_number &lt;&lt; 3) | wire_type，换句话说，key 的最后 3 位表示的就是 wire_type。因此这里也涉及到前面proto文件定义的时候的宗旨，尽量将频繁使用的字段的字段号设置成1-15之间的数值，避免位数开销。这里的key的存储也是用了varint的方式</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-7-28/94576622.jpg" alt></p><p>举例，一般 message 的字段号都是 1 开始的，所以对应的 tag 可能是这样的：</p><p><code>000 1000</code></p><p>末尾3位表示的是value的类型，这里是000，即0，代表的是varint值。右移3位，即0001，这代表的就是字段号(field number)。tag的例子就举这么多，接下来举一个 value的例子，还是用varint来举例：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">96 01 = 1001 0110  0000 0001</span><br><span class="line">       → 000 0001  ++  001 0110 (drop the msb and reverse the groups of 7 bits)</span><br><span class="line">       → 10010110</span><br><span class="line">       → 128 + 16 + 4 + 2 = 150</span><br></pre></td></tr></table></figure><p></p><p>所以 96 01 代表的数据就是 150 。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">message Test1 &#123;</span><br><span class="line">  required int32 a = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>如果存在上面这样的一个 message 的结构，如果存入 150，在 Protocol Buffer 中显示的二进制应该为 08 96 01 <code>varint(1 &lt;&lt; 3 | 0) = 0x08</code>.</p><p>注意到varint编码也应用在了key的计算上，使用非常频繁，或许是基于这个原因，pb里实现了一种性能更高的方案（coded_stream.cc）</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">inline uint8* CodedOutputStream::WriteVarint32FallbackToArrayInline(</span><br><span class="line">    uint32 value, uint8* target) &#123;</span><br><span class="line">  target[0] = static_cast&lt;uint8&gt;(value | 0x80);</span><br><span class="line">  if (value &gt;= (1 &lt;&lt; 7)) &#123;</span><br><span class="line">    target[1] = static_cast&lt;uint8&gt;((value &gt;&gt;  7) | 0x80);</span><br><span class="line">    if (value &gt;= (1 &lt;&lt; 14)) &#123;</span><br><span class="line">      target[2] = static_cast&lt;uint8&gt;((value &gt;&gt; 14) | 0x80);</span><br><span class="line">      if (value &gt;= (1 &lt;&lt; 21)) &#123;</span><br><span class="line">        target[3] = static_cast&lt;uint8&gt;((value &gt;&gt; 21) | 0x80);</span><br><span class="line">        if (value &gt;= (1 &lt;&lt; 28)) &#123;</span><br><span class="line">          target[4] = static_cast&lt;uint8&gt;(value &gt;&gt; 28);</span><br><span class="line">          return target + 5;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          target[3] &amp;= 0x7F;</span><br><span class="line">          return target + 4;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        target[2] &amp;= 0x7F;</span><br><span class="line">        return target + 3;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      target[1] &amp;= 0x7F;</span><br><span class="line">      return target + 2;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    target[0] &amp;= 0x7F;</span><br><span class="line">    return target + 1;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>测试了1kw条数据，两种方案的时间对比为 196742us vs 269806us，在pb序列化反序列化大量使用varint的前提下，这个性能提升就很有必要了(这是原作者做的测试)</p><p>type 需要注意的是 type = 2 的情况，tag 里面除了包含 field number 和 wire_type ，还需要再包含一个 length，决定 value 从那一段取出来</p><h3>负数使用varint编码的问题</h3><p>varint编码希望以标志位能够节省掉高字节的0，但是负数的最高位一定是1， 所以varint在处理32位负数时会固定的占用5个字节。比如我们修改下之前的程序test.set_a(-1)，序列化之后的数据为</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08ff ffff ffff ffff ffff 01</span><br></pre></td></tr></table></figure><p></p><p>有11个字节之多！除了key=0x08占用的1个字节，value=-1占用了10个字节。</p><p>对应的代码（coded_stream.h）</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inline void CodedOutputStream::WriteVarint32SignExtended(int32 value) &#123;</span><br><span class="line">  if (value &lt; 0) &#123;</span><br><span class="line">    WriteVarint64(static_cast&lt;uint64&gt;(value));</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    WriteVarint32(static_cast&lt;uint32&gt;(value));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>int32被转换成了uint64(为什么？)原作者这里问为什么== 原因在文档中有提及</p><blockquote><p>If you use int32 or int64 as the type for a negative number, the resulting varint is always ten bytes long – it is, effectively, treated like a very large unsigned integer,即uint64，也就是上面代码写的那样。但是为什么生成是10个字节呢? 因为uint64是10个?</p></blockquote><p>再经过varint编码。这就是10个字节的原因了。当然如果你使用了signed types那么产出的varint编码结果使用了Zigzag编码就会相当的高效。</p><h3>Zigzag编码</h3><p>ZigZag是将有符号数统一映射到无符号数的一种编码方案，对于无符号数0 1 2 3 4，映射前的有符号数分别为0 -1 1 -2 2，负数以及对应的正数来回映射到从0变大的数字序列里，这也是”zig-zag”的名字来源。将所有整数映射成无符号整数，然后再采用 varint 编码方式编码，这样，绝对值小的整数，编码后也会有一个较小的 varint 编码值。</p><p>Zigzag 映射函数为：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Zigzag(n) = (n &lt;&lt; 1) ^ (n &gt;&gt; 31), n 为 sint32 时</span><br><span class="line">Zigzag(n) = (n &lt;&lt; 1) ^ (n &gt;&gt; 63), n 为 sint64 时</span><br></pre></td></tr></table></figure><p></p><p>按照这种方法，-1 将会被编码成 1，1 将会被编码成 2，-2 会被编码成 3，如下表所示：</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-7-28/17159197.jpg" alt></p><p>存疑？</p><p>目前仍有一个地方不大清楚，就是对于int32类型的负数，protobuf强制编码成10个字节，理论上5个字节就够了。 （来自别人的问题，我也没懂，确实想了下int32的负数5个就够了，int64的负数才需要10个？）</p><h3>负数及大整数的解决方案</h3><p>protobuf里提供了一种sint32/sint64来使用ZigZag编码。</p><p>修改proto:optional sint32 a = 1，这样在test.set_a(-1)并序列化后只有两个字节08 01</p><p>同理对于大整数，optional int32 a = 1;，test.set_a(1 &lt;&lt; 28)序列化后可以看到占用了6个字节0880 8080 8001，解决方案也是使用不同的类型定义optional <strong>fixed32</strong> a = 1来解决，使用这种方案后int32固定的占用4个字节。这种其实就是官网中的<code>Non-varint Numbers</code></p><h3>字符串</h3><p>wire_type 类型为 2 的数据，是一种指定长度的编码方式：key + length + content，key 的编码方式是统一的，length 采用 varints 编码方式，content 就是由 length 指定长度的 Bytes</p><p>举例，假设定义如下的 message 格式：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">message Test2 &#123;</span><br><span class="line">  optional string b = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>设置该值为&quot;testing&quot;，二进制格式查看：<code>12 07 74 65 73 74 69 6e 67</code>, <code>74 65 73 74 69 6e 67</code> 是“testing”的 UTF8 代码。</p><p>12 -&gt; 0001 0010，后三位 010 为 wire type = 2，0001 0010 右移三位为 0000 0010，即 tag = 2。</p><p>length 此处为 7，后边跟着 7 个bytes，即我们的字符串&quot;testing&quot;。</p><p>所以 wire_type 类型为 2 的数据，编码的时候会默认转换为 T-L-V (Tag - Length - Value)的形式. TLV的模式减少了分隔符的使用，数据存储更加紧凑。需要转变为 T - L - V 形式的还有 string, bytes, embedded messages, packed repeated fields。</p><h3>小结</h3><ul><li>Protocol Buffer 利用 varint 原理压缩数据以后，二进制数据非常紧凑，option 也算是压缩体积的一个举措。所以 pb 体积更小，如果选用它作为网络数据传输，势必相同数据，消耗的网络流量更少。但是并没有压缩到极限，float、double 浮点型都没有压缩。</li><li>Protocol Buffer 比 JSON 和 XML 少了 {、}、: 这些符号，体积也减少一些。再加上 varint 压缩，gzip 压缩以后体积更小！</li><li>Protocol Buffer 是 Tag - Value (Tag - Length - Value)的编码方式的实现，减少了分隔符的使用，数据存储更加紧凑。</li><li>Protocol Buffer 另外一个核心价值在于提供了一套工具，一个编译工具，自动化生成 get/set 代码。简化了多语言交互的复杂度，使得编码解码工作有了生产力。</li><li>Protocol Buffer 不是自我描述的，离开了数据描述 .proto 文件，就无法理解二进制数据流。这点即是优点，使数据具有一定的“加密性”，也是缺点，数据可读性极差。所以 Protocol Buffer 非常适合内部服务之间 RPC 调用和传递数据。</li><li>Protocol Buffer 具有向后兼容的特性，更新数据结构以后，老版本依旧可以兼容，这也是 Protocol Buffer 诞生之初被寄予解决的问题。因为编译器对不识别的新增字段会跳过不处理</li></ul><h2>Protobuf反序列化</h2><p><a href="https://halfrost.com/protobuf_encode/" target="_blank" rel="noopener">https://halfrost.com/protobuf_encode/</a></p><p>整个解析过程需要 Protobuf 本身的框架代码和由 Protobuf 编译器生成的代码共同完成。Protobuf 提供了基类 Message 以及 Message_lite 作为通用的 Framework，，CodedInputStream 类，WireFormatLite 类等提供了对二进制数据的 decode 功能，从 5.1 节的分析来看，Protobuf 的解码可以通过几个简单的数学运算完成，无需复杂的词法语法分析，因此 ReadTag() 等方法都非常快。 在这个调用路径上的其他类和方法都非常简单，感兴趣的读者可以自行阅读。 相对于 XML 的解析过程，以上的流程图实在是非常简单吧？这也就是 Protobuf 效率高的第二个原因了</p><p><img src="http://or0igopk2.bkt.clouddn.com/18-7-28/17159197.jpg" alt></p><h2>与json thift的性能比较</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDcyMTQyNQ==&amp;mid=2649257430&amp;idx=1&amp;sn=975b6123d8256221f6bac3b99e52af9a&amp;chksm=8767a428b0102d3e6ab7abdf797c481da570cb29e274aa4ff6ecd931f535166b776e6548941d&amp;scene=0&amp;key=399a205ce674169cbedcc1c459650908e22d6a2b81674195c3b251114acdf821dbde7bb49102c6b47f61b26a7a404d74e0e8440cea3675a7ea8f49eafd8639bfb733183a1bfb4603232d6cb8ecd230e5&amp;ascene=0&amp;uin=NTkxMDk2NjU=&amp;devicetype=iMac+MacBookPro12,1+OSX+OSX+10.12.4+build(16E195)&amp;version=12020510&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=wHPj0w18CV8zHl6HCfd9t9LQfs3I0ZULhUILuOHgL0E=" target="_blank" rel="noopener">Protobuf有没有比JSON快5倍？用代码来击破pb性能神话</a></p><h2>总结</h2><p>protobuf的性能来源于对存储的压缩，避免一切不必要的字节开销。flink中如过将大多数需要存储到state中的对象先转成PB格式会得到很大的性能提升。</p><p>和protobuf通常被同时提及的有Apache Thrift / Avro 本文已经没有空间介绍，待后续深入了解。</p><p>这篇文章介绍了3中数据结构如何做到对消息体格式演变的透明 <a href="https://martin.kleppmann.com/2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html" target="_blank" rel="noopener">https://martin.kleppmann.com/2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html</a></p><p>参考：</p><p><a href="https://developers.google.com/protocol-buffers/docs/javatutorial" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/docs/javatutorial</a> <a href="https://developers.google.com/protocol-buffers/docs/encoding#structure" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/docs/encoding#structure</a> <a href="https://halfrost.com/protobuf_encode/" target="_blank" rel="noopener">https://halfrost.com/protobuf_encode/</a> <a href="https://izualzhy.cn/protobuf-encode-varint-and-zigzag" target="_blank" rel="noopener">https://izualzhy.cn/protobuf-encode-varint-and-zigzag</a> <a href="https://izualzhy.cn/protobuf-encoding" target="_blank" rel="noopener">https://izualzhy.cn/protobuf-encoding</a> <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/index.html</a> <a href="https://segmentfault.com/a/1190000004891020" target="_blank" rel="noopener">https://segmentfault.com/a/1190000004891020</a> protobufstuff <a href="https://mp.weixin.qq.com/s?__biz=MzA3NDcyMTQyNQ==&amp;mid=2649257430&amp;idx=1&amp;sn=975b6123d8256221f6bac3b99e52af9a&amp;chksm=8767a428b0102d3e6ab7abdf797c481da570cb29e274aa4ff6ecd931f535166b776e6548941d&amp;scene=0&amp;key=399a205ce674169cbedcc1c459650908e22d6a2b81674195c3b251114acdf821dbde7bb49102c6b47f61b26a7a404d74e0e8440cea3675a7ea8f49eafd8639bfb733183a1bfb4603232d6cb8ecd230e5&amp;ascene=0&amp;uin=NTkxMDk2NjU=&amp;devicetype=iMac+MacBookPro12,1+OSX+OSX+10.12.4+build(16E195)&amp;version=12020510&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=wHPj0w18CV8zHl6HCfd9t9LQfs3I0ZULhUILuOHgL0E=" target="_blank" rel="noopener">1</a>: &quot;https://mp.weixin.qq.com/s&quot;</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article></section><nav class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="aitozi"><p class="site-author-name" itemprop="name">aitozi</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">34</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">10</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">19</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="gjying1314@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-globe"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://wuchong.me/" title="wuchong" target="_blank">wuchong</a></li><li class="links-of-blogroll-item"><a href="http://chenyuzhao.me/" title="yuzhao" target="_blank">yuzhao</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/yanghua_kobe?viewmode=contents" title="vinoyang" target="_blank">vinoyang</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/lmalds?viewmode=contents" title="Imalds" target="_blank">Imalds</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/androidlushangderen" title="hadoop" target="_blank">hadoop</a></li><li class="links-of-blogroll-item"><a href="http://www.cnblogs.com/xrq730/p/5260294.html" title="java开发" target="_blank">java开发</a></li><li class="links-of-blogroll-item"><a href="http://www.hollischuang.com/" title="阿里工程师" target="_blank">阿里工程师</a></li><li class="links-of-blogroll-item"><a href="http://www.cnblogs.com/fxjwind/" title="阿里流计算工程师" target="_blank">阿里流计算工程师</a></li><li class="links-of-blogroll-item"><a href="http://jm.taobao.org/" title="阿里中间件博客" target="_blank">阿里中间件博客</a></li><li class="links-of-blogroll-item"><a href="http://armsword.com/" title="duruofei" target="_blank">duruofei</a></li><li class="links-of-blogroll-item"><a href="http://blog.yufeng.info/" title="褚霸" target="_blank">褚霸</a></li><li class="links-of-blogroll-item"><a href="https://yuzhouwan.com" title="宇宙湾" target="_blank">宇宙湾</a></li><li class="links-of-blogroll-item"><a href="http://matt33.com" title="matt" target="_blank">matt</a></li><li class="links-of-blogroll-item"><a href="http://coding-geek.com/" title="coding-geek" target="_blank">coding-geek</a></li></ul></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">aitozi</span></div><div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div><div class="theme-info">主题 - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/jquery.lazyload/1.9.3/jquery.lazyload.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><script id="dsq-count-scr" src="https://aitozi.disqus.com/count.js" async></script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script></body></html><!-- rebuild by neat -->