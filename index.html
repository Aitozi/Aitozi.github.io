<!-- build time:Sun Mar 31 2019 01:39:12 GMT+0800 (中国标准时间) --><!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="google-site-verification" content="DO25iswIsaKZ5NZbYreVDjWtBKTyo1yFAROjSRcJD64"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css"><link href="//fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Aitozi" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2"><meta name="description" content="What makes a difference? Persistence!"><meta property="og:type" content="website"><meta property="og:title" content="Aitozi"><meta property="og:url" content="http://www.aitozi.com/index.html"><meta property="og:site_name" content="Aitozi"><meta property="og:description" content="What makes a difference? Persistence!"><meta property="og:locale" content="zh-Hans"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Aitozi"><meta name="twitter:description" content="What makes a difference? Persistence!"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post",offset:12,offset_float:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:!0,duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://www.aitozi.com/"><title>Aitozi</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Aitozi</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description"></h1></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/[Blink]Binary Row数据结构的实现.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/[Blink]Binary Row数据结构的实现.html" itemprop="url">Binary Row数据结构的实现</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-26T09:17:30+08:00">2019-03-26 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码解析/" itemprop="url" rel="index"><span itemprop="name">源码解析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/[Blink]Binary Row数据结构的实现.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="[Blink]Binary Row数据结构的实现.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">2.7k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">13</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>Binary Row是blink开源版本<a href="https://github.com/apache/flink/tree/blink" target="_blank" rel="noopener">https://github.com/apache/flink/tree/blink</a>中提到的一个runtime层面优化的特性，主要是应用于sql模块，简单来说，由于sql本身自带schema，在上下游数据传输的时候就可以利用这个schema信息来简化序列化和反序列化的过程，本文就来具体分析这个特性的实现。</p><p>&lt;!-- more --&gt;</p><p>主要实现代码在</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink-table org.apache.flink.table.typeutils</span><br><span class="line">flink-table-common org.apache.flink.table.dataformat</span><br><span class="line">flink-table-common org.apache.flink.table.typeutils</span><br></pre></td></tr></table></figure><p></p><h3>Binary Row</h3><p>我们要理解sql层的数据传输是用的什么结构，只需要去观察runtime层实现的算子的传输数据类型即可，通过查看代码可以发现中间算子传输的均为<code>BaseRow</code></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public TwoInputSelection processElement1(StreamRecord&lt;BaseRow&gt; element) throws Exception &#123;&#125;</span><br></pre></td></tr></table></figure><p></p><p>而之前版本的数据传输的是一个Row,内部是一个<code>Object[]</code>，在传输的过程中使用<code>RowSerializer</code>进行每一个字段的序列化和反序列化</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public void serialize(Row record, DataOutputView target) throws IOException &#123;</span><br><span class="line">	int len = fieldSerializers.length;</span><br><span class="line"></span><br><span class="line">	if (record.getArity() != len) &#123;</span><br><span class="line">		throw new RuntimeException(&quot;Row arity of from does not match serializers.&quot;);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// write a null mask</span><br><span class="line">	writeNullMask(len, record, target);</span><br><span class="line"></span><br><span class="line">	// serialize non-null fields</span><br><span class="line">	for (int i = 0; i &lt; len; i++) &#123;</span><br><span class="line">		Object o = record.getField(i);</span><br><span class="line">		if (o != null) &#123;</span><br><span class="line">			fieldSerializers[i].serialize(o, target);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>新的实现中以BaseRow代替了Row，baserow是一个基类，在不同的场景下有不同的子类去实现相应的功能。</p><h4>GenericRow</h4><p>能够方便的用以更新字段，其内部实现也是一个Object数组，</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// kafka source deserialization schema 从source处就解析成一个BaseRow</span><br><span class="line">public GenericRow deserialize(byte[] messageKey, byte[] message, String topic, int partition, long offset) throws IOException &#123;</span><br><span class="line">	GenericRow row = new GenericRow(5);</span><br><span class="line">	row.update(0, messageKey);</span><br><span class="line">	row.update(1, message);</span><br><span class="line">	row.update(2, BinaryString.fromString(topic));</span><br><span class="line">	row.update(3, partition);</span><br><span class="line">	row.update(4, offset);</span><br><span class="line">	return row;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>JoinedRow</h4><p>主要能够方便的将两个row进行拼接成一个baserow</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// windowoperator中发送一个key和aggRes的组合的row到下游</span><br><span class="line">reuseOutput.replace((BaseRow) getCurrentKey(), aggResult);</span><br></pre></td></tr></table></figure><p></p><h4>BinaryRow</h4><p>BaseRow序列化是先转化成BinaryRow，然后再通过BinaryRowSerializer进行序列化</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// BaseRowSerializer.java</span><br><span class="line">public void serialize(BaseRow row, DataOutputView target) throws IOException &#123;</span><br><span class="line">	BinaryRow binaryRow;</span><br><span class="line">	if (row.getClass() == BinaryRow.class) &#123;</span><br><span class="line">		binaryRow = (BinaryRow) row;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		binaryRow = baseRowToBinary(row);</span><br><span class="line">	&#125;</span><br><span class="line">	binarySerializer.serialize(binaryRow, target);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public BinaryRow baseRowToBinary(BaseRow baseRow) throws IOException &#123;</span><br><span class="line">	BinaryRow row = getProjection().apply(baseRow);</span><br><span class="line">	row.setHeader(baseRow.getHeader());</span><br><span class="line">	return row;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以看到baseToRow的过程中首先是会通过codeGen生成映射函数，然后将baserow转成binaryrow，测试将以下的GenericRow转化成BinaryRow生成如下代码</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GenericRow gR = new GenericRow(3);</span><br><span class="line">gR.update(0, 1);</span><br><span class="line">gR.update(1, 2L);</span><br><span class="line">gR.update(2, &quot;test&quot;);</span><br><span class="line"></span><br><span class="line">BaseRowSerializer&lt;GenericRow&gt; serializer = new BaseRowSerializer&lt;&gt;(Types.INT, Types.LONG, Types.STRING);</span><br><span class="line">BinaryRow row = serializer.baseRowToBinary(gR);</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">public class BaseRowSerializerProjection$0 extends org.apache.flink.table.codegen.Projection&lt;org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow&gt; &#123;</span><br><span class="line"></span><br><span class="line">        org.apache.flink.table.dataformat.BinaryString reuseBString$3 = new org.apache.flink.table.dataformat.BinaryString();</span><br><span class="line">        final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(3);</span><br><span class="line">        // 先构建一个BinaryRowWriter</span><br><span class="line">        final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);</span><br><span class="line"></span><br><span class="line">        public BaseRowSerializerProjection$0() throws Exception &#123;</span><br><span class="line">          </span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) &#123;</span><br><span class="line">          int field$1;</span><br><span class="line">          boolean isNull$1;</span><br><span class="line">          long field$2;</span><br><span class="line">          boolean isNull$2;</span><br><span class="line">          org.apache.flink.table.dataformat.BinaryString field$4;</span><br><span class="line">          boolean isNull$4;</span><br><span class="line">          outWriter.reset();</span><br><span class="line">          isNull$1 = in1.isNullAt(0);</span><br><span class="line">          field$1 = -1;</span><br><span class="line">          if (!isNull$1) &#123;</span><br><span class="line">            field$1 = in1.getInt(0);</span><br><span class="line">          &#125;</span><br><span class="line">          if (isNull$1) &#123;</span><br><span class="line">            outWriter.setNullAt(0);</span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            outWriter.writeInt(0, field$1);</span><br><span class="line">          &#125;</span><br><span class="line">          isNull$2 = in1.isNullAt(1);</span><br><span class="line">          field$2 = -1L;</span><br><span class="line">          if (!isNull$2) &#123;</span><br><span class="line">            field$2 = in1.getLong(1);</span><br><span class="line">          &#125;</span><br><span class="line">          if (isNull$2) &#123;</span><br><span class="line">            outWriter.setNullAt(1);</span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            outWriter.writeLong(1, field$2);</span><br><span class="line">          &#125;</span><br><span class="line">          isNull$4 = in1.isNullAt(2);</span><br><span class="line">          field$4 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;</span><br><span class="line">          if (!isNull$4) &#123;</span><br><span class="line">            field$4 = in1.getBinaryString(2, reuseBString$3);</span><br><span class="line">          &#125;</span><br><span class="line">          if (isNull$4) &#123;</span><br><span class="line">            outWriter.setNullAt(2);</span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            outWriter.writeBinaryString(2, field$4);</span><br><span class="line">          &#125;</span><br><span class="line">          outWriter.complete();</span><br><span class="line">          return out;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p></p><p>通过codeGen的代码可以得出，对于普通的baserow，通过BinaryRowWriter，将baserow的每个字段写入到BinaryRow中，写入完成后，序列化的工作就都通过BinaryRowSerializer来完成。这样的好处有以下几个:</p><ul><li>如果某个中间算子只需要获取上游传输下来的某几个字段的值，那么只需要通过getXXX来直接获取，减少反序列化的量</li><li>如果中间结果不发生改变，只需要将binaryRow直接拷贝出去，也减少了序列化的量</li></ul><p>BinaryRow序列化的过程，可以看到就是直接的内存拷贝的过程</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public void serialize(BinaryRow record, DataOutputView target) throws IOException &#123;</span><br><span class="line">	int sizeInBytes = record.getSizeInBytes();</span><br><span class="line">	target.writeInt(sizeInBytes);</span><br><span class="line">	int offset = record.getBaseOffset();</span><br><span class="line">	for (MemorySegment segment : record.getAllSegments()) &#123;</span><br><span class="line">		int remain = segment.size() - offset;</span><br><span class="line">		int copySize = remain &gt; sizeInBytes ? sizeInBytes : remain;</span><br><span class="line">		target.write(segment, offset, copySize);</span><br><span class="line"></span><br><span class="line">		sizeInBytes -= copySize;</span><br><span class="line">		offset = 0;</span><br><span class="line">	&#125;</span><br><span class="line">	if (sizeInBytes != 0) &#123;</span><br><span class="line">		throw new RuntimeException(&quot;No copy finished, this should be a bug, &quot; +</span><br><span class="line">				&quot;The remaining length is: &quot; + sizeInBytes);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>BinaryString</h4><p>在上面codegen的一段代码中，关于string的处理引入了一个概念BinaryString</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">field$4 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;</span><br><span class="line">if (!isNull$4) &#123;</span><br><span class="line">  field$4 = in1.getBinaryString(2, reuseBString$3);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// GenericRow的getBinaryString的实现</span><br><span class="line">public BinaryString getBinaryString(int ordinal) &#123;</span><br><span class="line">	Object value = this.fields[ordinal];</span><br><span class="line">	if (value instanceof BinaryString) &#123;</span><br><span class="line">		return (BinaryString) value;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		return BinaryString.fromString((String) value);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>那么BinaryString是什么作用呢? 看注释</p><blockquote><p>A utf8 string which is backed by {@link MemorySegment} instead of String. Its data may span multiple {@link MemorySegment}s. 一个直接存储在MemorySegment上的utf8的字符串，一个字符串数据可能会跨segment</p></blockquote><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private MemorySegment[] segments;</span><br><span class="line">private int offset;</span><br><span class="line">private int numBytes;</span><br><span class="line"></span><br><span class="line">/** Cache the java string for the binary string to avoid redundant decode. */</span><br><span class="line">private String javaString;</span><br></pre></td></tr></table></figure><p></p><p>针对string类型，会在codegen阶段，将其转化成一个binaryString。从binarystring初始化的时候没有存储在MemorySegment之上，而是仅仅只是保存string的字符串信息，等到有对string的操作的时候,才会通过这个方法将其序列化，并包装成memorysegments</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public void ensureEncoded() &#123;</span><br><span class="line">	if (!isEncoded()) &#123;</span><br><span class="line">		encodeToBytes();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void encodeToBytes() &#123;</span><br><span class="line">	if (javaString != null) &#123;</span><br><span class="line">		byte[] bytes = StringUtf8Utils.encodeUTF8(javaString);</span><br><span class="line">		pointTo(bytes, 0, bytes.length, javaString);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>序列化</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public void serialize(BinaryString record, DataOutputView target) throws IOException &#123;</span><br><span class="line">	byte[] bytes = record.getBytes();</span><br><span class="line">	target.writeInt(bytes.length);</span><br><span class="line">	target.write(bytes);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Maybe not copied, if want copy, please use copyTo.</span><br><span class="line"> */</span><br><span class="line">public static byte[] getBytes(MemorySegment[] segments, int baseOffset, int sizeInBytes) &#123;</span><br><span class="line">	// avoid copy if `base` is `byte[]`</span><br><span class="line">	if (segments.length == 1) &#123;</span><br><span class="line">		byte[] heapMemory = segments[0].getHeapMemory();</span><br><span class="line">		// 基于byte[]数组的memorysegment</span><br><span class="line">		if (baseOffset == 0</span><br><span class="line">				&amp;&amp; heapMemory != null</span><br><span class="line">				&amp;&amp; heapMemory.length == sizeInBytes) &#123;</span><br><span class="line">			return heapMemory;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			// 将内存从堆外内存拷贝出来</span><br><span class="line">			byte[] bytes = new byte[sizeInBytes];</span><br><span class="line">			segments[0].get(baseOffset, bytes, 0, sizeInBytes);</span><br><span class="line">			return bytes;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		byte[] bytes = new byte[sizeInBytes];</span><br><span class="line">		BinaryRowUtil.copySlow(segments, baseOffset, bytes, 0, sizeInBytes);</span><br><span class="line">		return bytes;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>BinaryString有什么好处呢？</p><ol><li>仅仅序列化一次</li><li>是可以修改的string，而不会产生中间对象</li><li>序列化的时候仅仅是内存的拷贝</li></ol><h4>BinaryArray</h4><p>同样的基于memorysegment实现的还有BinaryMap和BinaryArray，这两者都有一个Generic的实现用以快速的更新, GenericArray要求<strong>数据类型都是相同的类型</strong></p><p>BinaryArray的存储格式:</p><blockquote><p>[numElements(int)] + [null bits(4-byte word boundaries)] + [values or offset&amp;length] + [variable length part].</p></blockquote><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public void serialize(BaseArray record, DataOutputView target) throws IOException &#123;</span><br><span class="line">	BinaryArray binaryArray = baseArrayToBinary(record);</span><br><span class="line">	target.write(binaryArray.getBytes());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public BinaryArray baseArrayToBinary(BaseArray from) &#123;</span><br><span class="line">	if (from instanceof BinaryArray) &#123;</span><br><span class="line">		return (BinaryArray) from;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	int numElements = from.numElements();</span><br><span class="line">	if (reuseBinaryArray == null) &#123;</span><br><span class="line">		reuseBinaryArray = new BinaryArray();</span><br><span class="line">	&#125;</span><br><span class="line">	if (reuseBinaryWriter == null || reuseBinaryWriter.getNumElements() != numElements) &#123;</span><br><span class="line">		reuseBinaryWriter = new BinaryArrayWriter(</span><br><span class="line">			reuseBinaryArray, numElements, BinaryArray.calculateElementSize(eleType));</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		reuseBinaryWriter.reset();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; numElements; i++) &#123;</span><br><span class="line">		if (from.isNullAt(i)) &#123;</span><br><span class="line">			reuseBinaryWriter.setNullAt(i, eleType);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			BaseRowUtil.write(reuseBinaryWriter, i,</span><br><span class="line">					TypeGetterSetters.get(from, i, eleType), eleType, elementSerializer);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	reuseBinaryWriter.complete();</span><br><span class="line"></span><br><span class="line">	return reuseBinaryArray;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>从BinaryArraySerializer可以看到，处理方式和BaseRow很像，先baseToBinary，然后直接从segments拷贝byte。</p><h4>DataStructureConverters</h4><p>以上的类型和这个类型convert搭配使用才发挥出相应的效果，这个工具类的作用在于在codegen的阶段，根据输入的类型去转化为相对应的InternalType</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def genToInternal(ctx: CodeGeneratorContext, t: DataType): String =&gt; String = &#123;</span><br><span class="line">    val iTerm = boxedTypeTermForType(t.toInternalType)</span><br><span class="line">    val eTerm = externalBoxedTermForType(t)</span><br><span class="line">    if (isIdentity(t)) &#123;</span><br><span class="line">      term =&gt; s&quot;($iTerm) $term&quot;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      val scalarFuncTerm = classOf[BuildInScalarFunctions].getCanonicalName</span><br><span class="line">      TypeConverters.createExternalTypeInfoFromDataType(t) match &#123;</span><br><span class="line">        case Types.STRING =&gt; term =&gt; s&quot;$BINARY_STRING.fromString($term)&quot;</span><br><span class="line">        case Types.SQL_DATE | Types.SQL_TIME =&gt;</span><br><span class="line">          term =&gt; s&quot;$scalarFuncTerm.safeToInt(($eTerm) $term)&quot;</span><br><span class="line">        case Types.SQL_TIMESTAMP =&gt; term =&gt; s&quot;$scalarFuncTerm.safeToLong(($eTerm) $term)&quot;</span><br><span class="line">        case _ =&gt;</span><br><span class="line">          val converter = genConvertField(ctx, createToInternalConverter(t))</span><br><span class="line">          term =&gt; s&quot;($iTerm) $converter.apply($term)&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">// 生成的类型转化函数</span><br><span class="line">val internal = genToInternalIfNeeded(ctx, resultExternalType, resultClass, javaTerm)</span><br><span class="line">        s&quot;&quot;&quot;</span><br><span class="line">            |$javaTypeTerm $javaTerm = ($javaTypeTerm) $evalResult;</span><br><span class="line">            |$resultTerm = $javaTerm == null ? null : ($internal);</span><br><span class="line">            &quot;&quot;&quot;.stripMargin</span><br></pre></td></tr></table></figure><p></p><p>这样在codegen阶段就完成了相应类型的替换</p><h4>BinaryRow和BinaryArray的底层存储</h4><p>上面我们看到了binaryRow的使用方式，通过writeXXX的方式将数据写入到一个row中，一个row中可以写入基本类型，也可以写入binaryString, binaryArray，binaryMap等等变长的数据结构，其存储方式如下所示：</p><p><img src="https://github.com/Aitozi/images/blob/master/flink/flink-binaryrow.jpg?raw=true" alt="BinaryRow"></p><blockquote><p>A Row has two part: Fixed-length part and variable-length part. Fixed-length part contains null bit set and field values. Null bit set is used for null tracking and is aligned to 8-byte word boundaries. <code>Field values</code> holds fixed-length primitive types and variable-length values which can be stored in 8 bytes inside. If it do not fit the variable-length field, then store the length and offset of variable-length part. Fixed-length part will certainly fall into a MemorySegment, which will speed up the read and write of field. Variable-length part may fall into multiple MemorySegments.</p></blockquote><p>在将其他格式通过baseRowToBinaryRow的时候，确定了BinaryRow包含的field个数，</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public BinaryRowWriter(BinaryRow row, int initialSize) &#123;</span><br><span class="line">	this.nullBitsSizeInBytes = BinaryRow.calculateBitSetWidthInBytes(row.getArity());</span><br><span class="line">	this.fixedSize = row.getFixedLengthPartSize();</span><br><span class="line">	this.cursor = fixedSize;</span><br><span class="line"></span><br><span class="line">	this.segment = MemorySegmentFactory.wrap(new byte[fixedSize + initialSize]);</span><br><span class="line">	this.row = row;</span><br><span class="line">	this.row.pointTo(segment, 0, segment.size());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public static int calculateBitSetWidthInBytes(int arity) &#123;</span><br><span class="line">	// add 8 bit header</span><br><span class="line">	return ((arity + 63 + 8) / 64) * 8;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>这个函数是计算出null值得Flag位需要多少Byte来表示，这里的+63是将其对其到8的倍数（向上去整的意思），+8和spark代码相比其实是因为flink多了一个header存储回撤消息的标志位,null bits中第一个byte存储了header位的信息，这里的null bits的作用主要是用在runtime处理时可以快速判断一条数据是不是null值。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public boolean anyNull() &#123;</span><br><span class="line">	// 这里有一个疑问，判断null的时候不是应该跳过第一个header位吗</span><br><span class="line">	for (int i = 0; i &lt; nullBitsSizeInBytes; i += 8) &#123;</span><br><span class="line">		if (segment.getLong(i) != 0) &#123;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public int getFixedLengthPartSize() &#123;</span><br><span class="line">	return nullBitsSizeInBytes + 8 * arity;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>获取整个固定长度字段的长度，再写变长区时就从这个offset写起。</p><p><strong>写定长数据</strong></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public void writeByte(int pos, byte value) &#123;</span><br><span class="line">	segment.put(getFieldOffset(pos), value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p><strong>写不定长的数据</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void writeString(int pos, String input) &#123;</span><br><span class="line">	byte[] bytes = StringUtf8Utils.allocateBytes(input.length() * MAX_BYTES_PER_CHAR);</span><br><span class="line">	int len = StringUtf8Utils.encodeUTF8(input, bytes);</span><br><span class="line">	if (len &lt;= 7) &#123;</span><br><span class="line">		// 小于记录length的长度时直接写在固定长度区</span><br><span class="line">		writeLittleBytes(segment, getFieldOffset(pos), bytes, len);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		writeBigBytes(pos, bytes, len);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>BinaryRow/BinaryRowWriter的实现和Spark中UnsafeRow/UnsafeRowWriter的实现非常相似，spark中的对此数据结构解释更为清晰一些。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * An Unsafe implementation of Row which is backed by raw memory instead of Java objects.</span><br><span class="line"> *</span><br><span class="line"> * Each tuple has three parts: [null bit set] [values] [variable length portion]</span><br><span class="line"> *</span><br><span class="line"> * The bit set is used for null tracking and is aligned to 8-byte word boundaries.  It stores</span><br><span class="line"> * one bit per field.</span><br><span class="line"> *</span><br><span class="line"> * In the `values` region, we store one 8-byte word per field. For fields that hold fixed-length</span><br><span class="line"> * primitive types, such as long, double, or int, we store the value directly in the word. For</span><br><span class="line"> * fields with non-primitive or variable-length values, we store a relative offset (w.r.t. the</span><br><span class="line"> * base address of the row) that points to the beginning of the variable-length field, and length</span><br><span class="line"> * (they are combined into a long).</span><br><span class="line"> *</span><br><span class="line"> */</span><br></pre></td></tr></table></figure><p></p><h3>题外话</h3><p>看代码的时候遵循的是一种推理加源码追踪的手段，但是代码在初始设计的时候应该是另一种维度的思考，因此应该换一种思路去想如果自己来实现这个feature需要考虑什么地方，多多思考。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-sql-tutorial.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-sql-tutorial.html" itemprop="url">flink sql与calcite</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-25T16:45:30+08:00">2019-03-25 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码解析/" itemprop="url" rel="index"><span itemprop="name">源码解析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-sql-tutorial.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-sql-tutorial.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.5k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">7</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>基于Flink1.4.2版本分析flink与calcite结合构建的flink sql模块。</p><p>&lt;!--more--&gt;</p><p>Flink SQL是现在Flink社区中着重发展的一个模块，我理解主要原因是因为</p><ol><li>SQL是一门发展很有的通用的描述性语言，接入门槛较低</li><li>有希望在sql层面实现流批计算的统一</li><li>能够通过sql优化器内置优化能力，避免需要每个用户方需要理解低阶任务的调优，屏蔽实现细节</li></ol><h3>概述</h3><p>Flink SQL的总体执行流程为：</p><ul><li><em>SELECT</em>查询语句经过caclite parse成SqlNode</li><li>SqlNode经过validate校验</li><li>SqlNode经过calcite转化为relNode</li><li><em>Insert</em>语句将relNode经过calcite的优化和转化成FlinkRelNode</li><li>将相应的FlinkRelNode和codeGen生成的Function结合生成相应的执行算子</li></ul><p>下面以一个查询sql来讲解整体流程:</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">val stream = env</span><br><span class="line">        .fromCollection(data)</span><br><span class="line">        .assignTimestampsAndWatermarks(</span><br><span class="line">          new TimestampAndWatermarkWithOffset[(Long, String, String)](0L))</span><br><span class="line">val table = stream.toTable(tEnv, &apos;a, &apos;b, &apos;c, &apos;rowtime.rowtime)</span><br><span class="line"></span><br><span class="line">tEnv.registerTable(&quot;T1&quot;, table)</span><br><span class="line"></span><br><span class="line">val sqlQuery = &quot;SELECT c, COUNT(*), COUNT(1), COUNT(b) FROM T1 &quot; +</span><br><span class="line">  &quot;GROUP BY TUMBLE(rowtime, interval &apos;5&apos; SECOND), c&quot;</span><br><span class="line"></span><br><span class="line">val result = tEnv.sqlQuery(sqlQuery).toAppendStream[Row]</span><br><span class="line">result.addSink(new StreamITCase.StringSink[Row])</span><br><span class="line"></span><br><span class="line">env.execute()</span><br></pre></td></tr></table></figure><p></p><h3>parse</h3><h4>SqlNode</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val parser: SqlParser = SqlParser.create(sql, parserConfig)</span><br><span class="line">val sqlNode: SqlNode = parser.parseStmt</span><br><span class="line">sqlNode</span><br></pre></td></tr></table></figure><p></p><p><img src="https://github.com/Aitozi/images/blob/master/flink/flink-sql-node.png?raw=true" alt="SqlNode" title="SqlNode"></p><p>SqlNode表示的是一颗sql解析树，由于Flink暂时只支持SELECT查询，所以我们这里得到的其实是一个<code>SqlSelect</code>实例，SqlSelect是一个SqlCall，SqlCall继承自SqlNode，每一个无叶子节点的节点就是一个Sqlcall，常见的SqlNode的子类就是，SqlKind是所有SqlNode类型的枚举类:</p><ul><li>SqlCall 表示一个树的无叶子节点的调用，例如图中的Count(*)</li><li>SqlNodeList 表示SqlNode的集合</li><li>SqlIdentifer 表示某个标识符</li></ul><h4>SqlOperator</h4><p>SqlNode的成员方法：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public List&lt;SqlNode&gt; getOperandList() &#123;</span><br><span class="line">  return ImmutableNullableList.of(keywordList, selectList, from, where,</span><br><span class="line">      groupBy, having, windowDecls, orderBy, offset, fetch);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public SqlOperator getOperator() &#123;</span><br><span class="line">  return SqlSelectOperator.INSTANCE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>getOperator返回的是这个是个什么操作，operands得到的运算对象。每一个SqlNode是由作用于一系列SqlNode的SqlOperator组成，SqlFunction也是一种SqlOperator. 这里SqlSelect node是SqlSelectOperator作用于以下的SqlNode节点</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SqlNodeList keywordList;</span><br><span class="line">SqlNodeList selectList;</span><br><span class="line">SqlNode from;</span><br><span class="line">SqlNode where;</span><br><span class="line">SqlNodeList groupBy;</span><br><span class="line">SqlNode having;</span><br><span class="line">SqlNodeList windowDecls;</span><br><span class="line">SqlNodeList orderBy;</span><br><span class="line">SqlNode offset;</span><br><span class="line">SqlNode fetch;</span><br><span class="line">SqlMatchRecognize matchRecognize;</span><br></pre></td></tr></table></figure><p></p><h3>rel</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val rexBuilder: RexBuilder = createRexBuilder</span><br><span class="line">val cluster: RelOptCluster = FlinkRelOptClusterFactory.create(planner, rexBuilder)</span><br><span class="line">val config = SqlToRelConverter.configBuilder()</span><br><span class="line">  .withTrimUnusedFields(false).withConvertTableAccess(false).build()</span><br><span class="line">val sqlToRelConverter: SqlToRelConverter = new SqlToRelConverter(</span><br><span class="line">  new ViewExpanderImpl, validator, createCatalogReader, cluster, convertletTable, config)</span><br><span class="line">root = sqlToRelConverter.convertQuery(validatedSqlNode, false, true)</span><br></pre></td></tr></table></figure><p></p><p>这个过程是将SqlNode转化为RelNode的过程，RelNode表示关系型表达式,代表的是对数据的一个操作常见的有Project,Scan,Filter,Join等。通过explain可以看到相应的逻辑执行计划，以下还包括优化后的物理执行计划的一部分</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"> == Abstract Syntax Tree ==</span><br><span class="line">LogicalProject(c=[$1], EXPR$1=[$2], EXPR$2=[$2], EXPR$3=[$3])</span><br><span class="line">  LogicalAggregate(group=[&#123;0, 1&#125;], EXPR$1=[COUNT()], EXPR$3=[COUNT($3)])</span><br><span class="line">    LogicalProject($f0=[TUMBLE($3, 5000)], c=[$2], $f2=[1], b=[$1])</span><br><span class="line">      LogicalTableScan(table=[[T1]])</span><br><span class="line"></span><br><span class="line">== Optimized Logical Plan ==</span><br><span class="line">DataStreamCalc(select=[c, EXPR$1, EXPR$1 AS EXPR$2, EXPR$3])</span><br><span class="line">  DataStreamGroupWindowAggregate(groupBy=[c], window=[TumblingGroupWindow(&apos;w$, &apos;rowtime, 5000.millis)], select=[c, COUNT(*) AS EXPR$1, COUNT(b) AS EXPR$3])</span><br><span class="line">    DataStreamCalc(select=[rowtime, c, 1 AS $f2, b])</span><br><span class="line">      DataStreamScan(table=[[_DataStreamTable_0]])</span><br><span class="line"></span><br><span class="line">== Physical Execution Plan ==</span><br><span class="line">Stage 1 : Data Source</span><br><span class="line">	content : collect elements with CollectionInputFormat</span><br><span class="line"></span><br><span class="line">	Stage 2 : Operator</span><br><span class="line">		content : Timestamps/Watermarks</span><br><span class="line">		ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">		Stage 3 : Operator</span><br><span class="line">			content : from: (a, b, c, rowtime)</span><br><span class="line">			ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">			Stage 4 : Operator</span><br><span class="line">				content : select: (rowtime, c, 1 AS $f2, b)</span><br><span class="line">				ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">				Stage 5 : Operator</span><br><span class="line">					content : time attribute: (rowtime)</span><br><span class="line">					ship_strategy : FORWARD</span><br><span class="line"></span><br><span class="line">					Stage 7 : Operator</span><br><span class="line">						content : groupBy: (c), window: (TumblingGroupWindow(&apos;w$, &apos;rowtime, 5000.millis)), select: (c, COUNT(*) AS EXPR$1, COUNT(b) AS EXPR$3)</span><br><span class="line">						ship_strategy : HASH</span><br><span class="line"></span><br><span class="line">						Stage 8 : Operator</span><br><span class="line">							content : select: (c, EXPR$1, EXPR$1 AS EXPR$2, EXPR$3)</span><br><span class="line">							ship_strategy : FORWARD</span><br></pre></td></tr></table></figure><p></p><p>Flink sql查询的时候只做到这里的LogicalNode生成之后就完成了，等待sink才会触发下一步优化和转化逻辑。</p><h4>RelNode，RexNode</h4><p>RelNode的实现类有LogicalProject，LogicalScan等表示的是数据处理方式，rexnode表示的是行表达式，是包含在一个RelNode中的,RexNode类中的exps字段就存储了相应的数据操作所需要的行表达式</p><p>参考以下讨论:</p><blockquote><p>Difference between sqlnode and relnode and rexnode https://www.mail-archive.com/dev@calcite.apache.org/msg01674.html</p></blockquote><h4>RexTraits, RelTraitDef</h4><p>这个表示的是一个RelNode的物理特性，用于在convertRule中使用</p><p>在一个<code>ConverterRule</code>中的convert</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val scan: FlinkLogicalNativeTableScan = rel.asInstanceOf[FlinkLogicalNativeTableScan]</span><br><span class="line">val traitSet: RelTraitSet = rel.getTraitSet.replace(FlinkConventions.DATASTREAM)</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public RelTraitSet replace(</span><br><span class="line">    RelTrait trait) &#123;</span><br><span class="line">  // Quick check for common case</span><br><span class="line">  if (containsShallow(traits, trait)) &#123;</span><br><span class="line">    return this;</span><br><span class="line">  &#125;</span><br><span class="line">  final RelTraitDef traitDef = trait.getTraitDef();</span><br><span class="line">  int index = findIndex(traitDef);</span><br><span class="line">  if (index &lt; 0) &#123;</span><br><span class="line">    // Trait is not present. Ignore it.</span><br><span class="line">    return this;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return replace(index, trait);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>实际上是把某一类relTraitsDef的trait实现更换掉，相当于变更了RelNode的物理实现，planner转化过程应该只是trait的转化过程以及相应的RelNode的物理化的过程，按照论文中的解释:</p><blockquote><p>Traits. Calcite does not use different entities to represent logical and physical operators. Instead, it describes the physical properties associated with an operator using traits. These traits help the optimizer evaluate the cost of different alternative plans. Changing a trait value does not change the logical expression being evaluated, i.e., the rows produced by the given operator will still be the same</p></blockquote><p>因此在Flink中的转化<code>StreamTableEnvironment#optimize</code>,match之后根据HepPlanner和VocanoPlanner进行convert转化成物理算子，例如将</p><p><code>LogicalJoin(RelNode) -&gt; DataStreamJoin(FlinkRelNode) -&gt; translateToPlan -&gt; NonWindowJoin (runtime)</code></p><h3>总结</h3><p>Flink SQL具体在flink中的实现分为LogicalPlan层，经过应用rule optimize之后的RelNode层，例如: DataStreamJoin, 再通过translate的时候code generator以及调用相应的runtime层的具体算子实现（这个对应的是physical plan的翻译），以上就完成了从SQL到Flink执行计划的翻译。从整个流程看calcite全程参与，使用方式非常的方便，足见整个calcite框架的扩展性做的很好。 Flink SQL中还有许多其他的细节：SQL中的回撤消息，join，distinct的具体通用算子的实现，还有sql优化，分流，ddl的实现，antlr的实现,窗口聚合等等这些实现细节后文再具体分析。</p><h3>参考</h3><p>介绍calcite与flink sql比较好的几篇文章：</p><p><a href="https://zhuanlan.zhihu.com/p/48735419" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/48735419</a> <a href="https://arxiv.org/pdf/1802.10233.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1802.10233.pdf</a> calcite的论文 <a href="https://zhuanlan.zhihu.com/p/51221350" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51221350</a> <a href="https://zhuanlan.zhihu.com/p/58249033" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/58249033</a> <a href="https://zhuanlan.zhihu.com/p/59643962" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59643962</a></p><hr><p><a href="http://matt33.com/2019/03/17/apache-calcite-planner/" target="_blank" rel="noopener">http://matt33.com/2019/03/17/apache-calcite-planner/</a> <a href="http://matt33.com/2019/03/07/apache-calcite-process-flow/" target="_blank" rel="noopener">http://matt33.com/2019/03/07/apache-calcite-process-flow/</a> <a href="https://www.slideshare.net/julianhyde/costbased-query-optimization-in-apache-phoenix-using-apache-calcite?qid=b7a1ca0f-e7bf-49ad-bc51-0615ec8a4971&amp;v=&amp;b=&amp;from_search=4" target="_blank" rel="noopener">https://www.slideshare.net/julianhyde/costbased-query-optimization-in-apache-phoenix-using-apache-calcite?qid=b7a1ca0f-e7bf-49ad-bc51-0615ec8a4971&amp;v=&amp;b=&amp;from_search=4</a></p><hr><p><a href="https://issues.apache.org/jira/browse/FLINK-7146" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/FLINK-7146</a> Flink SQL DDL支持 <a href="https://docs.google.com/document/d/1TTP-GCC8wSsibJaSUyFZ_5NBAHYEB1FVmPpP7RgDGBA/edit#heading=h.wpsqidkaaoil" target="_blank" rel="noopener">https://docs.google.com/document/d/1TTP-GCC8wSsibJaSUyFZ_5NBAHYEB1FVmPpP7RgDGBA/edit#heading=h.wpsqidkaaoil</a> doc</p><p><a href="https://github.com/TatianaJin/calcite_playground/wiki/Query-Planning-&amp;-Optimization-II.a:-VolcanoPlanner-Basics" target="_blank" rel="noopener">https://github.com/TatianaJin/calcite_playground/wiki/Query-Planning-&amp;-Optimization-II.a:-VolcanoPlanner-Basics</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-timerservice-based-on-rocksdb-2.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-timerservice-based-on-rocksdb-2.html" itemprop="url">下篇·flink基于rocksdb的timerService</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T12:13:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-timerservice-based-on-rocksdb-2.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-timerservice-based-on-rocksdb-2.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">2.2k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">9</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>接上文分析，要将timer改成基于rocksdb，其实就是要对存储timer的set和queue提供基于rocksdb的存储方案。以下我们基于flink1.7版本源码分析</p><p>&lt;!--more--&gt;</p><p><strong>registerProcessingTimeTimer</strong></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public void registerProcessingTimeTimer(N namespace, long time) &#123;</span><br><span class="line">	InternalTimer&lt;K, N&gt; oldHead = processingTimeTimersQueue.peek();</span><br><span class="line">	if (processingTimeTimersQueue.add(new TimerHeapInternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace))) &#123;</span><br><span class="line">		long nextTriggerTime = oldHead != null ? oldHead.getTimestamp() : Long.MAX_VALUE;</span><br><span class="line">		// check if we need to re-schedule our timer to earlier</span><br><span class="line">		// 如果新加入的timer的时间更早触发，那么就需要把先前的timer取消</span><br><span class="line">		if (time &lt; nextTriggerTime) &#123;</span><br><span class="line">			if (nextTimer != null) &#123;</span><br><span class="line">				nextTimer.cancel(false);</span><br><span class="line">			&#125;</span><br><span class="line">			nextTimer = processingTimeService.registerTimer(time, this);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以和看到1.4版本中的基本逻辑是一致的，只是存储方式变化了，下面我们就来分析一下新的存储方式是怎么实现的。在存储的选择上依然有Heap和RocksDB两个方式</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">switch (priorityQueueStateType) &#123;</span><br><span class="line">			case HEAP:</span><br><span class="line">				this.priorityQueueFactory = new HeapPriorityQueueSetFactory(keyGroupRange, numberOfKeyGroups, 128);</span><br><span class="line">				break;</span><br><span class="line">			case ROCKSDB:</span><br><span class="line">				this.priorityQueueFactory = new RocksDBPriorityQueueSetFactory();</span><br><span class="line">				break;</span><br><span class="line">			default:</span><br><span class="line">				throw new IllegalArgumentException(&quot;Unknown priority queue state type: &quot; + priorityQueueStateType);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><p>从timerService的需求来看我们可以看到这样的几个需求：</p><ol><li>能够每次poll出最近需要触发的timer，实际上是需要维护一个小顶堆</li><li>能够对每一个key的timer去重</li></ol><p>针对这两个需求，总体来看基于Heap的实现是通过基于数组实现了一个二叉堆，具体实现类为<code>HeapPriorityQueue</code>, 然后针对去重的功能又继承该<code>PQ</code>，通过一个hashmap数组，数组的每一个元素代表一个KG的一组不重复timer，同时这组timer内部也维护了timer在二叉堆中存储的下标，方便<code>deleteTimer</code>时的快速删除。</p><h4>基于Heap的实现</h4><p><code>HeapPriorityQueueElement</code>,<code>AbstractHeapPriorityQueue</code>,<code>HeapPriorityQueue</code>,<code>HeapPriorityQueueSet</code></p><ol><li>存储基于数组，通过<code>HeapPriorityQueueElement</code>记录自己所在的index，可以达到快速删除的目的</li><li>数组中存储的是一个二叉树，数组的起始位置是从1开始，为了使一些热点方法做更少的计算</li></ol><p>在实现上是采用template的设计模式，主要实现逻辑交由子类来实现:</p><ul><li>addInternal</li><li>removeInternal</li><li>getHeadElementIndex</li></ul><h5>addInternal</h5><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public boolean add(@Nonnull T toAdd) &#123;</span><br><span class="line">	addInternal(toAdd);</span><br><span class="line">	return toAdd.getInternalIndex() == getHeadElementIndex();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>添加一个timer至数组中，返回值<code>false</code>表示队首的元素没有改变，<code>true</code>则表示改变了或者不确定</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">protected void addInternal(@Nonnull T element) &#123;</span><br><span class="line">	final int newSize = increaseSizeByOne();</span><br><span class="line">	moveElementToIdx(element, newSize);</span><br><span class="line">	siftUp(newSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">private int increaseSizeByOne() &#123;</span><br><span class="line">	final int oldArraySize = queue.length;</span><br><span class="line">	final int minRequiredNewSize = ++size;</span><br><span class="line">	if (minRequiredNewSize &gt;= oldArraySize) &#123;</span><br><span class="line">		final int grow = (oldArraySize &lt; 64) ? oldArraySize + 2 : oldArraySize &gt;&gt; 1;</span><br><span class="line">		// 当存储元素的个数大于数组长度时，需要进行扩容，通过`Arrays.copyOf`进行数组内容的拷贝</span><br><span class="line">		resizeQueueArray(oldArraySize + grow, minRequiredNewSize);</span><br><span class="line">	&#125;</span><br><span class="line">	// TODO implement shrinking as well?</span><br><span class="line">	return minRequiredNewSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 将新加入的元素存储到相应的idx处，并且记录该元素在queue中的位置</span><br><span class="line">protected void moveElementToIdx(T element, int idx) &#123;</span><br><span class="line">		queue[idx] = element;</span><br><span class="line">		element.setInternalIndex(idx);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private void siftUp(int idx) &#123;</span><br><span class="line">		final T[] heap = this.queue;</span><br><span class="line">		final T currentElement = heap[idx];</span><br><span class="line">		int parentIdx = idx &gt;&gt;&gt; 1;</span><br><span class="line">		</span><br><span class="line">		// 每次将比较的index，缩小一半，如果被比较元素的优先级高于新插入的元素就将被比较元素后移，直至比较到第一个元素。这样能够保证idx为1的元素是最早时间触发的</span><br><span class="line">		while (parentIdx &gt; 0 &amp;&amp; isElementPriorityLessThen(currentElement, heap[parentIdx])) &#123;</span><br><span class="line">			moveElementToIdx(heap[parentIdx], idx);</span><br><span class="line">			idx = parentIdx;</span><br><span class="line">			parentIdx &gt;&gt;&gt;= 1;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		moveElementToIdx(currentElement, idx);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 比较两个值的优先级</span><br><span class="line">private boolean isElementPriorityLessThen(T a, T b) &#123;</span><br><span class="line">		return elementPriorityComparator.comparePriority(a, b) &lt; 0;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><h5>removeInternal</h5><ol><li>抽取第一个timer用以触发</li><li>用户删除某个timer的行为</li></ol><p>删除的方式是通过idx下标来实现快速删除的，这也就是<code>HeapPriorityQueueElement</code>中记录idx的作用</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">protected T removeInternal(int removeIdx) &#123;</span><br><span class="line">	T[] heap = this.queue;</span><br><span class="line">	T removedValue = heap[removeIdx];</span><br><span class="line"></span><br><span class="line">	// 要删除的idx应该和内部存储value值保存的idx一致</span><br><span class="line">	assert removedValue.getInternalIndex() == removeIdx;</span><br><span class="line"></span><br><span class="line">	final int oldSize = size;</span><br><span class="line"></span><br><span class="line">	// 删除的不是数组的最后一个元素需要进行位置的调整</span><br><span class="line">	if (removeIdx != oldSize) &#123;</span><br><span class="line">		T element = heap[oldSize];</span><br><span class="line">		// 将原先的最后一个元素放置到要删除的idx处，但是这样的放置没有考虑优先级</span><br><span class="line">		moveElementToIdx(element, removeIdx);</span><br><span class="line">		adjustElementAtIndex(element, removeIdx);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	heap[oldSize] = null;</span><br><span class="line"></span><br><span class="line">	--size;</span><br><span class="line">	return removedValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private void adjustElementAtIndex(T element, int index) &#123;</span><br><span class="line">	siftDown(index);</span><br><span class="line">	if (queue[index] == element) &#123;</span><br><span class="line">		siftUp(index);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">private void siftDown(int idx) &#123;</span><br><span class="line">	final T[] heap = this.queue;</span><br><span class="line">	final int heapSize = this.size;</span><br><span class="line"></span><br><span class="line">	final T currentElement = heap[idx];</span><br><span class="line">	int firstChildIdx = idx &lt;&lt; 1;</span><br><span class="line">	int secondChildIdx = firstChildIdx + 1;</span><br><span class="line"></span><br><span class="line">	if (isElementIndexValid(secondChildIdx, heapSize) &amp;&amp;</span><br><span class="line">		isElementPriorityLessThen(heap[secondChildIdx], heap[firstChildIdx])) &#123;</span><br><span class="line">		firstChildIdx = secondChildIdx;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	while (isElementIndexValid(firstChildIdx, heapSize) &amp;&amp;</span><br><span class="line">		isElementPriorityLessThen(heap[firstChildIdx], currentElement)) &#123;</span><br><span class="line">		moveElementToIdx(heap[firstChildIdx], idx);</span><br><span class="line">		idx = firstChildIdx;</span><br><span class="line">		firstChildIdx = idx &lt;&lt; 1;</span><br><span class="line">		secondChildIdx = firstChildIdx + 1;</span><br><span class="line"></span><br><span class="line">		if (isElementIndexValid(secondChildIdx, heapSize) &amp;&amp;</span><br><span class="line">			isElementPriorityLessThen(heap[secondChildIdx], heap[firstChildIdx])) &#123;</span><br><span class="line">			firstChildIdx = secondChildIdx;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	moveElementToIdx(currentElement, idx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>以上的操作大致上是一个二叉堆的增删的调整过程，涉及的具体算法可以查阅下文末的资料。</p><hr><p>以下来分析rocksdb存储的实现</p><h4>KeyGroupPartitionedPriorityQueue</h4><p>基于rocksdb的存储是通过这个<code>KeyGroupPartitionedPriorityQueue</code>类来实现的，这个类中通过一个内存优先级队列，也就是上文中提到的内部实现的<code>HeapPriorityQueue</code>，用以存储所有KG的timer，而每一个分组的timer是如何存储呢？</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (int i = 0; i &lt; keyGroupedHeaps.length; i++) &#123;</span><br><span class="line">			final PQ keyGroupSubHeap =</span><br><span class="line">				orderedCacheFactory.create(firstKeyGroup + i, totalKeyGroups, keyExtractor, elementPriorityComparator);</span><br><span class="line">			keyGroupedHeaps[i] = keyGroupSubHeap;</span><br><span class="line">			heapOfKeyGroupedHeaps.add(keyGroupSubHeap);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><p>在这里的构造函数可以看到，其实是通过<code>orderedCacheFactory</code>,从字面意思看是一个有序的缓存，也就是为每一个KG创建一个有序的缓存类，并将其添加到优先级队列中，这里的<code>subHeap</code>也是一个可比较的类，相当于去取这两个<code>subHeap</code>的堆顶的元素拿出来比较下就可以知道这两个subheap的排序方式了。</p><p>比如<code>poll</code>的逻辑,首先先从HeapPQ中挑出堆顶（一个subPQ），然后再从这个PQ中取出堆顶就是要触发的timer了，而这个subPQ就是真是数据（timer）存储的地方了。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public T poll() &#123;</span><br><span class="line">	final PQ headList = heapOfKeyGroupedHeaps.peek();</span><br><span class="line">	final T head = headList.poll();</span><br><span class="line">	heapOfKeyGroupedHeaps.adjustModifiedElement(headList);</span><br><span class="line">	return head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>RocksDBCachingPriorityQueueSet</h4><p>这个是上节中<code>subHeap</code>的实现类</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">private void checkRefillCacheFromStore() &#123;</span><br><span class="line">		// 不是所有的元素都在cache(treeset)中，并且cache为空  </span><br><span class="line">		if (!allElementsInCache &amp;&amp; orderedCache.isEmpty()) &#123;</span><br><span class="line">			try (final RocksBytesIterator iterator = orderedBytesIterator()) &#123;</span><br><span class="line">				// 捞取rocksdb中这个columnFamily的部分数据填充treeset至maxsize</span><br><span class="line">				orderedCache.bulkLoadFromOrderedIterator(iterator);</span><br><span class="line">				allElementsInCache = !iterator.hasNext();</span><br><span class="line">			&#125; catch (Exception e) &#123;</span><br><span class="line">				throw new FlinkRuntimeException(&quot;Exception while refilling store from iterator.&quot;, e);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public E peek() &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		if (peekCache != null) &#123;</span><br><span class="line">			// 这个是维护的全局变量，只有在堆顶改变后在会置为null</span><br><span class="line">			return peekCache;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		byte[] firstBytes = orderedCache.peekFirst();</span><br><span class="line">		if (firstBytes != null) &#123;</span><br><span class="line">			peekCache = deserializeElement(firstBytes);</span><br><span class="line">			return peekCache;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			return null;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public E poll() &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] firstBytes = orderedCache.pollFirst();</span><br><span class="line"></span><br><span class="line">		if (firstBytes == null) &#123;</span><br><span class="line">			return null;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// write-through sync</span><br><span class="line">		// 为什么不需要删除treeset中的元素呢？</span><br><span class="line">		removeFromRocksDB(firstBytes);</span><br><span class="line"></span><br><span class="line">		// 删除了这个columnFamily最后一个元素</span><br><span class="line">		if (orderedCache.isEmpty()) &#123;</span><br><span class="line">			seekHint = firstBytes;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// 少一步反序列化的操作</span><br><span class="line">		if (peekCache != null) &#123;</span><br><span class="line">			E fromCache = peekCache;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return fromCache;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			return deserializeElement(firstBytes);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public boolean add(@Nonnull E toAdd) &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] toAddBytes = serializeElement(toAdd);</span><br><span class="line"></span><br><span class="line">		final boolean cacheFull = orderedCache.isFull();</span><br><span class="line"></span><br><span class="line">		// 如果cache没满并且之前所有元素都在cache中了  或者新加入的元素的优先级通过byte数组的优先级比较发现应该在堆顶</span><br><span class="line">		if ((!cacheFull &amp;&amp; allElementsInCache) ||</span><br><span class="line">			LEXICOGRAPHIC_BYTE_COMPARATOR.compare(toAddBytes, orderedCache.peekLast()) &lt; 0) &#123;</span><br><span class="line"></span><br><span class="line">			if (cacheFull) &#123;</span><br><span class="line">				// we drop the element with lowest priority from the cache</span><br><span class="line">				orderedCache.pollLast();</span><br><span class="line">				// the dropped element is now only in the store</span><br><span class="line">				allElementsInCache = false;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			// 用来判重</span><br><span class="line">			if (orderedCache.add(toAddBytes)) &#123;</span><br><span class="line">				// write-through sync</span><br><span class="line">				addToRocksDB(toAddBytes);</span><br><span class="line">				if (toAddBytes == orderedCache.peekFirst()) &#123;</span><br><span class="line">					// 说明新的写入导致了堆顶变化</span><br><span class="line">					peekCache = null;</span><br><span class="line">					return true;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			// 如果cache满了，或者不是所有的元素都在cache中，说明新来的数据一定不是堆顶的数据</span><br><span class="line">			// we only added to the store</span><br><span class="line">			addToRocksDB(toAddBytes);</span><br><span class="line">			allElementsInCache = false;</span><br><span class="line">		&#125;</span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(@Nonnull E toRemove) &#123;</span><br><span class="line"></span><br><span class="line">		checkRefillCacheFromStore();</span><br><span class="line"></span><br><span class="line">		final byte[] oldHead = orderedCache.peekFirst();</span><br><span class="line"></span><br><span class="line">		if (oldHead == null) &#123;</span><br><span class="line">			return false;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		final byte[] toRemoveBytes = serializeElement(toRemove);</span><br><span class="line"></span><br><span class="line">		// write-through sync</span><br><span class="line">		removeFromRocksDB(toRemoveBytes);</span><br><span class="line">		orderedCache.remove(toRemoveBytes);</span><br><span class="line"></span><br><span class="line">		if (orderedCache.isEmpty()) &#123;</span><br><span class="line">			seekHint = toRemoveBytes;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (oldHead != orderedCache.peekFirst()) &#123;</span><br><span class="line">			peekCache = null;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p></p><p>Iterator中seekHint的作用：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private RocksBytesIterator(@Nonnull RocksIteratorWrapper iterator) &#123;</span><br><span class="line">			this.iterator = iterator;</span><br><span class="line">			try &#123;</span><br><span class="line">				// We use our knowledge about the lower bound to issue a seek that is as close to the first element in</span><br><span class="line">				// the key-group as possible, i.e. we generate the next possible key after seekHint by appending one</span><br><span class="line">				// zero-byte.</span><br><span class="line">				iterator.seek(Arrays.copyOf(seekHint, seekHint.length + 1));</span><br><span class="line">				currentElement = nextElementIfAvailable();</span><br><span class="line">			&#125; catch (Exception ex) &#123;</span><br><span class="line">				// ensure resource cleanup also in the face of (runtime) exceptions in the constructor.</span><br><span class="line">				iterator.close();</span><br><span class="line">				throw new FlinkRuntimeException(&quot;Could not initialize ordered iterator.&quot;, ex);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><p></p><h4>再说checkpoint</h4><p>在doc中作者也提到之所以要做这个feature除了因为timer过多会导致OOM等问题，还有一个原因是因为timer的属性虽然和keyed state很类似，但是代码管理以及checkpoint的方式都是单独的一块逻辑，并且checkpoint的持久化过程还是同步的（因为是以raw keyedstate的方式去进行的），再修改之后，每次注册的timeservice都会注册到<code>kvstatInfo</code>中，将checkpoint的逻辑统一到statebackend中并且实现了异步化。</p><p><a href="https://blog.csdn.net/u010224394/article/details/8834969" target="_blank" rel="noopener">https://blog.csdn.net/u010224394/article/details/8834969</a></p><p><a href="https://github.com/apache/flink/pull/6159" target="_blank" rel="noopener">https://github.com/apache/flink/pull/6159</a></p><p><a href="https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-timerservice-based-on-rocksdb.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-timerservice-based-on-rocksdb.html" itemprop="url">上篇·flink基于rocksdb的timerService</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T12:08:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-timerservice-based-on-rocksdb.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-timerservice-based-on-rocksdb.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.6k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">7</span></div></div></header><div class="post-body" itemprop="articleBody"><p>[toc]</p><p>本文主要介绍flink中<code>TimerService based on Rocksdb</code>实现以及和之前版本的一个比较。</p><p>&lt;!--more--&gt;</p><p><strong>动机</strong></p><ol><li>timer和keyed state分开单独管理，keyed state是由<code>KeyedStateBackend</code>管理，而timer是由<code>InternalTimerServeice</code>管理</li><li><code>InternalTimerServeice</code>现有的实现是基于heap的<code>HeapInternalTimerService</code>，当timer数量较多时会有OOM的问题.如果能像keyed state一样基于<code>KeyedStateBackend</code>管理，就能在timer数量比较多的时候选用rocksdb作为backend来解决扩展性的问题</li><li>timer目前的checkpoint过程是通过raw keyed state的方式，在同步的过程中完成写出到外置存储，并且对于snapshot和restore timer都单独维护了一份代码。这块代码和其他的keyed state的实现有很多相同之处（分隔到keygroup来实现rescale，元数据的序列化和持久化..）</li></ol><p><strong>实现目标</strong></p><ol><li>Have an implementation of timer services that operates on RocksDB.</li><li>Support asynchronous snapshots for all timer state.</li><li>Support incremental snapshots for timer state in RocksDB.</li><li>Integrate timer state as another form of keyed state in keyed state backends in a way that leverages the existing snapshotting code to eliminate special casing code paths that do similar things. As as nice side effect, this would also free the raw keyed state for user state.</li></ol><p><strong>源码分析</strong></p><p>首先我们来看一下1.4版本中timerService是怎么实现的,timerService 实现了以下两个接口：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">InternalTimerService</span><br><span class="line">    long currentProcessingTime();</span><br><span class="line">    long currentWatermark();</span><br><span class="line">    void registerProcessingTimeTimer(N namespace, long time);</span><br><span class="line">    void deleteProcessingTimeTimer(N namespace, long time);</span><br><span class="line">    void registerEventTimeTimer(N namespace, long time);</span><br><span class="line">    void deleteEventTimeTimer(N namespace, long time);</span><br><span class="line">提供的是当前时间获取和注册timer的方法</span><br><span class="line"></span><br><span class="line">ProcessingTimeCallback</span><br><span class="line">    void onProcessingTime(long timestamp) throws Exception;</span><br></pre></td></tr></table></figure><p></p><p>在<code>HeapInternalTimerService</code>中分别维护了processing time和event time的timer集合</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private final Set&lt;InternalTimer&lt;K, N&gt;&gt;[] processingTimeTimersByKeyGroup;</span><br><span class="line">private final PriorityQueue&lt;InternalTimer&lt;K, N&gt;&gt; processingTimeTimersQueue;</span><br><span class="line"></span><br><span class="line">private final Set&lt;InternalTimer&lt;K, N&gt;&gt;[] eventTimeTimersByKeyGroup;</span><br><span class="line">private final PriorityQueue&lt;InternalTimer&lt;K, N&gt;&gt; eventTimeTimersQueue;</span><br></pre></td></tr></table></figure><p></p><p><code>InternalTimer</code>是一个<code>Comparable</code>, 按照timer触发的时间进行比较，timer是由<code>key</code>,<code>namespace</code>,<code>timestamp</code>唯一确定，其实也可以理解成如果同一个key，namespace下只可以有一个时间事件被触发。<code>regsterTimer</code>实际上就是在executor中注册一个任务</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">return timerService.schedule(</span><br><span class="line">                    new TriggerTask(status, task, checkpointLock, target, timestamp), delay, TimeUnit.MILLISECONDS);</span><br></pre></td></tr></table></figure><p></p><p>同时每个timerService中还维护了一个<code>ProcessingTimeService</code>用以处理和processing time相关的时间操作，是对<code>ScheduledThreadPoolExecutor</code>的包装，提供一些周期性执行和将来某时执行一次的操作.</p><p>我们在回头看<code>HeapInternalTimerService</code>的实现：</p><h4>registerProcessingTimeTimer</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public void registerProcessingTimeTimer(N namespace, long time) &#123;</span><br><span class="line">    InternalTimer&lt;K, N&gt; timer = new InternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace);</span><br><span class="line"></span><br><span class="line">    // make sure we only put one timer per key into the queue</span><br><span class="line">    // 在存储timer的时候会存储两份，一份是通过Set的形式将各个Keygroup的区分开，另一份是按照时间顺序排除存储在一个`PriorityQueue`中</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getProcessingTimeTimerSetForTimer(timer);</span><br><span class="line">    if (timerSet.add(timer)) &#123;</span><br><span class="line"></span><br><span class="line">        InternalTimer&lt;K, N&gt; oldHead = processingTimeTimersQueue.peek();</span><br><span class="line">        long nextTriggerTime = oldHead != null ? oldHead.getTimestamp() : Long.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">        processingTimeTimersQueue.add(timer);</span><br><span class="line"></span><br><span class="line">        // check if we need to re-schedule our timer to earlier</span><br><span class="line">        // 如果新注册的timer比最近要触发的timer时间早，那么就会终止最近要触发的timer（如果已经跑起来了就不中断了）</span><br><span class="line">        if (time &lt; nextTriggerTime) &#123;</span><br><span class="line">            if (nextTimer != null) &#123;</span><br><span class="line">                nextTimer.cancel(false);</span><br><span class="line">            &#125;</span><br><span class="line">            // 通过ScheduledThreadPoolExecutor注册一个task</span><br><span class="line">            nextTimer = processingTimeService.registerTimer(time, this);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 获取这个timer的key所属的已经注册的timer列表，从上面的注释我们可以看出是为了保证不注册重复timer</span><br><span class="line">private Set&lt;InternalTimer&lt;K, N&gt;&gt; getProcessingTimeTimerSetForTimer(InternalTimer&lt;K, N&gt; timer) &#123;</span><br><span class="line">    checkArgument(localKeyGroupRange != null, &quot;The operator has not been initialized.&quot;);</span><br><span class="line">    int keyGroupIdx = KeyGroupRangeAssignment.assignToKeyGroup(timer.getKey(), this.totalKeyGroups);</span><br><span class="line">    return getProcessingTimeTimerSetForKeyGroup(keyGroupIdx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private Set&lt;InternalTimer&lt;K, N&gt;&gt; getProcessingTimeTimerSetForKeyGroup(int keyGroupIdx) &#123;</span><br><span class="line">    int localIdx = getIndexForKeyGroup(keyGroupIdx);</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timers = processingTimeTimersByKeyGroup[localIdx];</span><br><span class="line">    // 如过这个set没有出现过，就构建一个新的set存放这个key的timer</span><br><span class="line">    if (timers == null) &#123;</span><br><span class="line">        timers = new HashSet&lt;&gt;();</span><br><span class="line">        processingTimeTimersByKeyGroup[localIdx] = timers;</span><br><span class="line">    &#125;</span><br><span class="line">    return timers;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private int getIndexForKeyGroup(int keyGroupIdx) &#123;</span><br><span class="line">    checkArgument(localKeyGroupRange.contains(keyGroupIdx),</span><br><span class="line">        &quot;Key Group &quot; + keyGroupIdx + &quot; does not belong to the local range.&quot;);</span><br><span class="line">    return keyGroupIdx - this.localKeyGroupRangeStartIdx;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>registerEventTimeTimer</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void registerEventTimeTimer(N namespace, long time) &#123;</span><br><span class="line">    InternalTimer&lt;K, N&gt; timer = new InternalTimer&lt;&gt;(time, (K) keyContext.getCurrentKey(), namespace);</span><br><span class="line">    Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getEventTimeTimerSetForTimer(timer);</span><br><span class="line">    if (timerSet.add(timer)) &#123;</span><br><span class="line">        eventTimeTimersQueue.add(timer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以看到eventtimer注册就不需要校验是否有将要执行的任务，因为eventtimer的实现不依赖于schedulerExxecutor。</p><h4>onProcessingTime</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">// 这个方法是配合registerProcessingTimer，通过SystemProcessingTimeService来实现timer语义，在timer中注册的任务会回调这个onProcessing方法</span><br><span class="line">public void onProcessingTime(long time) throws Exception &#123;</span><br><span class="line">    // null out the timer in case the Triggerable calls registerProcessingTimeTimer()</span><br><span class="line">    // inside the callback.</span><br><span class="line">    // 如果不置为null，在执行triggerTarget.onProcessingTime(timer);里面执行了registerProcessingTimeTimer会调用本任务的cancel</span><br><span class="line">    nextTimer = null;</span><br><span class="line"></span><br><span class="line">    InternalTimer&lt;K, N&gt; timer;</span><br><span class="line"></span><br><span class="line">    // 将processingTimeTimersQueue中所有小于当前时间的任务都取出进行出发</span><br><span class="line">    while ((timer = processingTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;</span><br><span class="line"></span><br><span class="line">        // 删除set中存储的timer</span><br><span class="line">        Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getProcessingTimeTimerSetForTimer(timer);</span><br><span class="line"></span><br><span class="line">        timerSet.remove(timer);</span><br><span class="line">        processingTimeTimersQueue.remove();</span><br><span class="line"></span><br><span class="line">        // 每次触发之前需要设置当前的key</span><br><span class="line">        keyContext.setCurrentKey(timer.getKey());</span><br><span class="line">        triggerTarget.onProcessingTime(timer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 说明队列中还存在还没到时间需要触发的timer，需要注册新的FutureTask</span><br><span class="line">    if (timer != null) &#123;</span><br><span class="line">        if (nextTimer == null) &#123;</span><br><span class="line">            nextTimer = processingTimeService.registerTimer(timer.getTimestamp(), this);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>advanceWatermark</h4><p>processing timer是基于executor来实现的，eventtime 的timer触发就依赖于watermark来触发，每次收到上游的watermark会触发调用<code>advanceWatermark</code>来将eventtime queue中的timer取出进行触发</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public void processWatermark(Watermark mark) throws Exception &#123;</span><br><span class="line">    if (timeServiceManager != null) &#123;</span><br><span class="line">        timeServiceManager.advanceWatermark(mark);</span><br><span class="line">    &#125;</span><br><span class="line">    output.emitWatermark(mark);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 这里的time就是最近的这次watermark的时间</span><br><span class="line">public void advanceWatermark(long time) throws Exception &#123;</span><br><span class="line">    currentWatermark = time;</span><br><span class="line"></span><br><span class="line">    InternalTimer&lt;K, N&gt; timer;</span><br><span class="line"></span><br><span class="line">    // 同样是取出所有的小于watermark的timer进行触发</span><br><span class="line">    while ((timer = eventTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) &#123;</span><br><span class="line"></span><br><span class="line">        Set&lt;InternalTimer&lt;K, N&gt;&gt; timerSet = getEventTimeTimerSetForTimer(timer);</span><br><span class="line">        timerSet.remove(timer);</span><br><span class="line">        eventTimeTimersQueue.remove();</span><br><span class="line"></span><br><span class="line">        keyContext.setCurrentKey(timer.getKey());</span><br><span class="line">        triggerTarget.onEventTime(timer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>snapshot</h4><p>之前在分析state实现的时候也分析过，在对operator进行snapshot的时候有一步就是对timerservice的数据进行snapshot</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">KeyGroupsList allKeyGroups = out.getKeyGroupList();</span><br><span class="line">for (int keyGroupIdx : allKeyGroups) &#123;</span><br><span class="line">    out.startNewKeyGroup(keyGroupIdx);</span><br><span class="line"></span><br><span class="line">    timeServiceManager.snapshotStateForKeyGroup(</span><br><span class="line">        new DataOutputViewStreamWrapper(out), keyGroupIdx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public void snapshotStateForKeyGroup(DataOutputView stream, int keyGroupIdx) throws IOException &#123;</span><br><span class="line">    InternalTimerServiceSerializationProxy&lt;K, N&gt; serializationProxy =</span><br><span class="line">        new InternalTimerServiceSerializationProxy&lt;&gt;(timerServices, keyGroupIdx);</span><br><span class="line"></span><br><span class="line">    serializationProxy.write(stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>proxy这块主要是为兼容做了很多的工作</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public void write(DataOutputView out) throws IOException &#123;</span><br><span class="line">    super.write(out);</span><br><span class="line"></span><br><span class="line">    out.writeInt(timerServices.size());</span><br><span class="line">    for (Map.Entry&lt;String, HeapInternalTimerService&lt;K, N&gt;&gt; entry : timerServices.entrySet()) &#123;</span><br><span class="line">        String serviceName = entry.getKey();</span><br><span class="line">        HeapInternalTimerService&lt;K, N&gt; timerService = entry.getValue();</span><br><span class="line"></span><br><span class="line">        out.writeUTF(serviceName);</span><br><span class="line">        InternalTimersSnapshotReaderWriters</span><br><span class="line">            .getWriterForVersion(VERSION, timerService.snapshotTimersForKeyGroup(keyGroupIdx))</span><br><span class="line">            .writeTimersSnapshot(out);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>restore</h4><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">protected void read(DataInputView in, boolean wasVersioned) throws IOException &#123;</span><br><span class="line">    int noOfTimerServices = in.readInt();</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; noOfTimerServices; i++) &#123;</span><br><span class="line">        String serviceName = in.readUTF();</span><br><span class="line"></span><br><span class="line">        HeapInternalTimerService&lt;K, N&gt; timerService = timerServices.get(serviceName);</span><br><span class="line">        if (timerService == null) &#123;</span><br><span class="line">            timerService = new HeapInternalTimerService&lt;&gt;(</span><br><span class="line">                totalKeyGroups,</span><br><span class="line">                localKeyGroupRange,</span><br><span class="line">                keyContext,</span><br><span class="line">                processingTimeService);</span><br><span class="line">            timerServices.put(serviceName, timerService);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        int readerVersion = wasVersioned ? getReadVersion() : InternalTimersSnapshotReaderWriters.NO_VERSION;</span><br><span class="line">        InternalTimersSnapshot&lt;?, ?&gt; restoredTimersSnapshot = InternalTimersSnapshotReaderWriters</span><br><span class="line">            .getReaderForVersion(readerVersion, userCodeClassLoader)</span><br><span class="line">            .readTimersSnapshot(in);</span><br><span class="line"></span><br><span class="line">        timerService.restoreTimersForKeyGroup(restoredTimersSnapshot, keyGroupIdx);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><p>本文主要是对1.4版本的分析，下一篇文章基于1.7版本再分析<code>timerservice on rocksdb</code>的实现</p><p>参考:</p><p><a href="https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit#heading=h.17v0k3363r6q" target="_blank" rel="noopener">https://docs.google.com/document/d/1XbhJRbig5c5Ftd77d0mKND1bePyTC26Pz04EvxdA7Jc/edit#heading=h.17v0k3363r6q</a></p><p><a href="https://issues.apache.org/jira/browse/FLINK-9485" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/FLINK-9485</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/flink-network-feature.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/flink-network-feature.html" itemprop="url">flink网络传输的前世今生</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T11:57:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/flink-network-feature.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="flink-network-feature.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">2k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">8</span></div></div></header><div class="post-body" itemprop="articleBody"><p>flink的网络传输在1.5版本进行了重构，本文就这个feature来对flink网络传输进行系统的源码分析</p><p>&lt;!--more--&gt;</p><h3>发送端</h3><p>首先我们先来看数据发送端的主要流程如下：</p><p><strong>数据发送链路</strong></p><blockquote><p><code>RecordWriter =&gt; ResultPartition =&gt; ResultSubPartition =&gt; ResultSubpartitionView =&gt; BufferAvailabilityListener =&gt; PartitionRequestQueue</code> 解释一下： 用户程序中调用<code>output.collect()</code>,首先会通过<code>RecordWriter</code>进行数据或者event的序列化。并且将其从堆内内存拷贝至堆外内存，然后添加至相应的<code>ResultPartition</code>中。<code>ResultPartition</code>根据数据<code>selectChannel</code>发送给下游的哪个<code>subIndex</code>,<code>BufferConsumer</code>就会被添加到相应的subpartition所维护的一个双端队列中。在某些条件下需要通过,在服务启动最开始注册上来的<code>ResultSubpartitionView</code>去通知消费端来进行消费buffer，view做的事情就是通过调用<code>BufferAvailableListener</code>的具体实现来进行通知事件通知。最终在netty端，通过<code>PartitionRequestQueue</code>进行最终的buffer发送。</p></blockquote><p>上面讲述了大体的流程，下面我们来结合代码来进行细节分析，下面代码可能会结合1.4和1.7两个版本来进行讲解</p><h4>RecordWriter</h4><h4>RecordSerializer</h4><p>在1.4版本中序列化器是和下游的并发度一一绑定的，这样会导致一个问题，比如发送下游是hash的分区模式的话，在上游的每一个并发度就会存储5MB的序列化后的缓存数据，当下游的并发较大的时候就会占据比较大的内存，带来一定的gc问题。序列化器会负责做这样几件事情：</p><ul><li>数据的序列化<ul><li>在写数据的时候并不会校验缓存块的大小</li><li>写的时候同时用一个4字节的bytebuffer记录数据的大小，有多少个字节</li></ul></li><li>数据序列化结果的拷贝，对拷贝结果的判断<ul><li>数据拷贝了一部分，memorysegment已经满了</li><li>拷贝了完整记录</li><li>拷贝了完整记录，并且segment满了</li></ul></li><li>缓存清理</li><li>...</li></ul><p>重点拷贝过程</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">private boolean copyFromSerializerToTargetChannel(int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	// We should reset the initial position of the intermediate serialization buffer before</span><br><span class="line">	// copying, so the serialization results can be copied to multiple target buffers.</span><br><span class="line">	// 这一步reset是为了在数据发送如果是broadcast这种一份数据需要发送多个下游通道的时候，就可以只序列化一次，后续数据发送的时候只需要将bytebuffer</span><br><span class="line">	// 的position值值置到0就可以了。</span><br><span class="line">	serializer.reset();</span><br><span class="line"></span><br><span class="line">	boolean pruneTriggered = false;</span><br><span class="line">	BufferBuilder bufferBuilder = getBufferBuilder(targetChannel);</span><br><span class="line">	SerializationResult result = serializer.copyToBufferBuilder(bufferBuilder);</span><br><span class="line">	// buffer没写满说明数据肯定已经写完了，直接进行下面的逻辑</span><br><span class="line">	while (result.isFullBuffer()) &#123;</span><br><span class="line">		// buffer写满了，首先将bufferBuilder标记为写完了，就是将positionMarker置为相反数</span><br><span class="line">		numBytesOut.inc(bufferBuilder.finish());</span><br><span class="line">		numBuffersOut.inc();</span><br><span class="line"></span><br><span class="line">		// If this was a full record, we are done. Not breaking out of the loop at this point</span><br><span class="line">		// will lead to another buffer request before breaking out (that would not be a</span><br><span class="line">		// problem per se, but it can lead to stalls in the pipeline).</span><br><span class="line">		// buffer写满，并且记录也写满了，那么发送到这个channel就完成了，否则就需要继续申请bufferBuilder继续拷贝</span><br><span class="line">		if (result.isFullRecord()) &#123;</span><br><span class="line">			pruneTriggered = true;</span><br><span class="line">			bufferBuilders[targetChannel] = Optional.empty();</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		bufferBuilder = requestNewBufferBuilder(targetChannel);</span><br><span class="line">		result = serializer.copyToBufferBuilder(bufferBuilder);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public SerializationResult copyToBufferBuilder(BufferBuilder targetBuffer) &#123;</span><br><span class="line">	targetBuffer.append(lengthBuffer);</span><br><span class="line">	targetBuffer.append(dataBuffer);</span><br><span class="line">	targetBuffer.commit();</span><br><span class="line"></span><br><span class="line">	return getSerializationResult(targetBuffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public int append(ByteBuffer source) &#123;</span><br><span class="line">	checkState(!isFinished());</span><br><span class="line"></span><br><span class="line">	int needed = source.remaining();</span><br><span class="line">	int available = getMaxCapacity() - positionMarker.getCached();</span><br><span class="line">	// segment不一定足够大，可能存不下这批buffer, 堆外内存拷贝的时候需要提前计算好可以拷贝的量，否则会有异常</span><br><span class="line">	int toCopy = Math.min(needed, available);</span><br><span class="line"></span><br><span class="line">	// 将source buffer中的数据/堆内存，put至memorySegment中，利用Unsafe进行数据拷贝</span><br><span class="line">	memorySegment.put(positionMarker.getCached(), source, toCopy);</span><br><span class="line">	// 设置新的position</span><br><span class="line">	positionMarker.move(toCopy);</span><br><span class="line">	return toCopy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>BufferBuilder，BufferConsumer，PositionMarker</h4><p>在上面copy代码中看到其实拷贝的时候是依赖buffer的,如果没有申请到<code>BufferBuiler</code>,是会一直blocking的，那么这个bufferbuilder是什么呢？</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">private BufferBuilder requestNewBufferBuilder(int targetChannel) throws IOException, InterruptedException &#123;</span><br><span class="line">	checkState(!bufferBuilders[targetChannel].isPresent() || bufferBuilders[targetChannel].get().isFinished());</span><br><span class="line"></span><br><span class="line">	BufferBuilder bufferBuilder = targetPartition.getBufferProvider().requestBufferBuilderBlocking();</span><br><span class="line">	bufferBuilders[targetChannel] = Optional.of(bufferBuilder);</span><br><span class="line">	// 一个bufferbuilder对应一个bufferconsumer</span><br><span class="line">	targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(), targetChannel);</span><br><span class="line">	return bufferBuilder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>在向<code>BufferProvider</code>，一般是localBufferPool申请完得到一个memorysegment后，将其封装成一个bufferbuilder，每一个bufferbuilder会对应 一个bufferconsumer和positionMarker，positionMarker会标记生产端的数据写到多少个字节了，这个在消费端的时候也会用到这个position， 由于是多线程使用所以position的值需要被标记成<code>volatile</code>来保证数据的可见性，每次消费端拉取数据的时候，对于没有写完的buffer同样可以进行消费， 消费前更新一个buffer的position真实位置，这里用到了一个小技巧，由于数据在生产的时候需要频繁的更新position，如果是<code>volatile</code>的， 虽然比较轻量，频繁更新也是比较大的开销，因此加入了一个<code>cachedPosition</code>，在写数据的时候只需要更新builder中的<code>cachedPosition</code>，生产端每次 完成一批的书写才会commit给<code>volatile position</code>，以此来减少缓存刷新。</p><p>从一个正在写的bufferbuiler中构建一个可消费的slice</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public Buffer build() &#123;</span><br><span class="line">	// 获取最近builder，commit到的position</span><br><span class="line">	writerPosition.update();</span><br><span class="line">	int cachedWriterPosition = writerPosition.getCached();</span><br><span class="line">	// slice 切分只读区块</span><br><span class="line">	Buffer slice = buffer.readOnlySlice(currentReaderPosition, cachedWriterPosition - currentReaderPosition);</span><br><span class="line">	currentReaderPosition = cachedWriterPosition;</span><br><span class="line">	// 增加引用计数</span><br><span class="line">	return slice.retainBuffer();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4>PartitionRequestQueue</h4><p>在将bufferConsumer添加到subpartition的队列之后，同时会在partitionRequestQueue中维护一个availableReader的队列，这个队列表示可以往下 下游发送的buffer数据，这样通过一个<code>while true</code>循环持续的将队列中的数据往下游发送，当然这个<code>availableReader</code>队列的维护既考量了上游subpartition 有没有buffer的因素，也考量了下游要发送的receiver端的credit的情况，如果没有credit也是无法进入这个待发送队列的。</p><h3>消费端</h3><p><strong>数据接收链路</strong></p><blockquote><p><code>CreditBasedPartitionRequestClientHandler =&gt; RemoteInputChannel =&gt; SingleInputGate =&gt; BarrierHandler =&gt; StreamInputProcessor =&gt; StreamOperator</code> 首先会通过netty client进行数据的接收，然后从localbufferpool申请内存接收数据，然后根据backlog的信息去决定是不是要给上游分发credit，以及数据处理的流程</p></blockquote><p>这里主要分析下credit的判断逻辑</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Receives the backlog from the producer&apos;s buffer response. If the number of available</span><br><span class="line"> * buffers is less than backlog + initialCredit, it will request floating buffers from the buffer</span><br><span class="line"> * pool, and then notify unannounced credits to the producer.</span><br><span class="line"> *</span><br><span class="line"> * @param backlog The number of unsent buffers in the producer&apos;s sub partition.</span><br><span class="line"> */</span><br><span class="line">void onSenderBacklog(int backlog) throws IOException &#123;</span><br><span class="line">	int numRequestedBuffers = 0;</span><br><span class="line"></span><br><span class="line">	synchronized (bufferQueue) &#123;</span><br><span class="line">		// Similar to notifyBufferAvailable(), make sure that we never add a buffer</span><br><span class="line">		// after releaseAllResources() released all buffers (see above for details).</span><br><span class="line">		if (isReleased.get()) &#123;</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		numRequiredBuffers = backlog + initialCredit;</span><br><span class="line">		// 检查当前input通道的buffer是否做够上游produce所需要的buffer，如果不够就去bufferpool申请</span><br><span class="line">		while (bufferQueue.getAvailableBufferSize() &lt; numRequiredBuffers &amp;&amp; !isWaitingForFloatingBuffers) &#123;</span><br><span class="line">			Buffer buffer = inputGate.getBufferPool().requestBuffer();</span><br><span class="line">			if (buffer != null) &#123;</span><br><span class="line">				// 申请到buffer之后先占据住</span><br><span class="line">				bufferQueue.addFloatingBuffer(buffer);</span><br><span class="line">				numRequestedBuffers++;</span><br><span class="line">				//  没有足够的buffer，那么注册回调等buffer回收</span><br><span class="line">			&#125; else if (inputGate.getBufferProvider().addBufferListener(this)) &#123;</span><br><span class="line">				// If the channel has not got enough buffers, register it as listener to wait for more floating buffers.</span><br><span class="line">				isWaitingForFloatingBuffers = true;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	// 如果生产端有buffer需求，并且之前的unannouncedCredit为0那么就需要通知上游有buffer了</span><br><span class="line">	if (numRequestedBuffers &gt; 0 &amp;&amp; unannouncedCredit.getAndAdd(numRequestedBuffers) == 0) &#123;</span><br><span class="line">		notifyCreditAvailable();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h3>整理流程图</h3><p><img src="https://raw.githubusercontent.com/Aitozi/images/master/flink/flink%E7%BD%91%E7%BB%9C%E6%A0%88%E5%9B%BE%E8%A7%A3.png" alt="flink-network" title="flink-network"></p><h3>netty内存的优化</h3><p>以下是message encode的时候的一段代码</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// only allocate header buffer - we will combine it with the data buffer below</span><br><span class="line">headerBuf = allocateBuffer(allocator, ID, messageHeaderLength, buffer.readableBytes(), false);</span><br><span class="line"></span><br><span class="line">receiverId.writeTo(headerBuf);</span><br><span class="line">headerBuf.writeInt(sequenceNumber);</span><br><span class="line">headerBuf.writeInt(backlog);</span><br><span class="line">headerBuf.writeBoolean(isBuffer);</span><br><span class="line">headerBuf.writeInt(buffer.readableBytes());</span><br><span class="line"></span><br><span class="line">CompositeByteBuf composityBuf = allocator.compositeDirectBuffer();</span><br><span class="line">composityBuf.addComponent(headerBuf);</span><br><span class="line">composityBuf.addComponent(buffer);</span><br><span class="line">// update writer index since we have data written to the components:</span><br><span class="line">composityBuf.writerIndex(headerBuf.writerIndex() + buffer.writerIndex());</span><br><span class="line">return composityBuf;</span><br></pre></td></tr></table></figure><p></p><p>可以看到这里和以前版本不一样的地方就是不需要再去申请一块netty内存做一次拷贝，因为这里将buffer对象的实现直接改成了继承netty的ByteBuf类， 所以减少了一次netty申请directBuffer以及从堆外拷贝到netty directBuffer的开销。在buffer处理完由netty回收时会放回<code>localBufferPool</code>中</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void deallocate() &#123;</span><br><span class="line">	recycler.recycle(memorySegment); // 在网络传输完内存释放的时候直接将segment回收到localbufferpool中</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h3>和flink1.4相比有了哪些改进</h3><p>https://docs.google.com/document/d/1chTOuOqe0sBsjldA_r-wXYeSIhU2zRGpUaTaik7QZ84</p><p>https://issues.apache.org/jira/browse/FLINK-7282?subTaskView=all</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/git-advance-tips-keeping-on-updating.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/git-advance-tips-keeping-on-updating.html" itemprop="url">git常用命令大全</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-16T11:40:03+08:00">2019-03-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/编程工具/" itemprop="url" rel="index"><span itemprop="name">编程工具</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/git-advance-tips-keeping-on-updating.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="git-advance-tips-keeping-on-updating.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">686 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">3</span></div></div></header><div class="post-body" itemprop="articleBody"><p>主要是工作中常用的一些git命令和一些场景的使用方式</p><p>&lt;!--more--&gt;</p><h2>常见命令</h2><h3>checkout</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b release-1.7.2 origin/release-1.7.2  # 从远端仓库checkout出release-1.7.2分支</span><br><span class="line">git checkout -- filename # 回退某文件至修改前的状态，也可用于误删文件恢复</span><br><span class="line">git checkout 0c6ded6af7068ff9fa4505d81855a38fc9861871 filename # 将某文件回退至某个版本</span><br></pre></td></tr></table></figure><p></p><h3>commit</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit --amend   # 修改commit信息</span><br></pre></td></tr></table></figure><p></p><h3>stash</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git stash # 保存工作现场  没有commit的内容</span><br><span class="line">git stash list # 查看stash队列</span><br><span class="line">git stash apply stash@&#123;num&#125;  # 恢复对应的stash</span><br><span class="line">git stash pop # 应用并删除最上面的stash</span><br></pre></td></tr></table></figure><p></p><h3>push</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br><span class="line">git push origin yarn_hdfs:yarn_and_hdfs_tools</span><br></pre></td></tr></table></figure><p></p><h3>tag</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git ls-remote --tags upstream # 查看远端的tag列表</span><br><span class="line">git fetch --all --tags --prune # 获取远程所有的tag，如果有origin和upstream两个，那么都会拉下来 https://stackoverflow.com/questions/35979642/what-is-git-tag-how-to-create-tags-how-to-checkout-git-remote-tags  有时远端仓库更新了tag就需要拉一次</span><br><span class="line">git tag --list # 列出所有的tag</span><br><span class="line">git checkout -b tset v0.1.0  # checkout到某tag</span><br></pre></td></tr></table></figure><p></p><h3>rebase</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git rebase -i commid # [当前commit,指定commitId) 左开右闭 # 修改commit信息，合并commit, 调整commit顺序，将一个类型的commit合并在一起</span><br><span class="line">git rebase -i HEAD~2</span><br></pre></td></tr></table></figure><p></p><h3>cherry-pick</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git cherry-pick A..B # 合并单个和多个</span><br><span class="line">git cherry-pick A</span><br></pre></td></tr></table></figure><p></p><h3>reset</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard &lt;sha1-commit-id&gt; # 直接删除到这个commitId</span><br><span class="line">git reset --soft</span><br></pre></td></tr></table></figure><p></p><h3>branch</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch -m &lt;old_name&gt; &lt;new_name&gt; # 重命名 branch 名称</span><br><span class="line">git branch -m &lt;new_name&gt; # 重命名 branch 名称</span><br></pre></td></tr></table></figure><p></p><h3>log</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git log --graph --oneline --decorate # 查看提交历史,https://segmentfault.com/a/1190000008039809</span><br><span class="line">git log --merges # merge 历史</span><br></pre></td></tr></table></figure><p></p><h2>常见操作方式</h2><h3>为仓库添加一个源</h3><p>例如在内部flink仓库添加一个社区的源用以合并代码</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add upstream https://github.com/apache/flink.git</span><br><span class="line">git pull upstream master # 指定上游和分支拉取代码</span><br></pre></td></tr></table></figure><p></p><h3>设置新的分支与远程分支的对应关系</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch --set-upstream-to=origin/dev_1.3.2_minwenjun</span><br><span class="line">git branch --set-upstream release-1.2.0-100 origin/release-1.2.0-100</span><br></pre></td></tr></table></figure><p></p><h3>克隆单个分支的代码</h3><p>常用于review大的MR，单独拉取用户提交的一个分支</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone [url] -b [branch-name] --single-branch</span><br><span class="line">git clone https://github.com/sihuazhou/flink.git -b FLINK-9804 --single-branch</span><br></pre></td></tr></table></figure><p></p><h3>cherry-pick merge commit</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://stackoverflow.com/questions/9229301/git-cherry-pick-says-38c74d-is-a-merge-but-no-m-option-was-given</span><br><span class="line">git cherry-pick -m 1 fd9f578</span><br><span class="line">git show --pretty=raw fd48e1ab722c20c196adb3e68583ba0d046b9cad (merge commit)</span><br></pre></td></tr></table></figure><p></p><h3>将当前代码提交到另一个仓库</h3><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin_repo_b git@server_ip:/path/repo_b.git</span><br><span class="line">git push origin_repo_b branch_a(要推的那个本地分支的名字)</span><br></pre></td></tr></table></figure><p></p><h3>git修改传输协议</h3><p>修改你本地的ssh remote url. 不用https协议，改用git协议</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br><span class="line">git remote set-url origin</span><br><span class="line"></span><br><span class="line">[minwenjun@bigdata-test04 flink-metric-analyse]$ git remote set-url origin git@github.com:minwenjun/flink-metric-analyse.git</span><br><span class="line">[minwenjun@bigdata-test04 flink-metric-analyse]$ git remote -v</span><br><span class="line">origin	git@ github.com:minwenjun/flink-metric-analyse.git (fetch)</span><br><span class="line">origin	git@github.com:minwenjun/flink-metric-analyse.git (push)</span><br></pre></td></tr></table></figure><p></p><p>参考资料:</p><p><a href="https://yuzhouwan.com/posts/30041/" target="_blank" rel="noopener">https://yuzhouwan.com/posts/30041/</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/maven-noclassdeffounderror.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/maven-noclassdeffounderror.html" itemprop="url">maven java.lang.NoClassDefFoundError with provided scope</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T23:12:03+08:00">2019-03-15 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/问题排查/" itemprop="url" rel="index"><span itemprop="name">问题排查</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/maven-noclassdeffounderror.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="maven-noclassdeffounderror.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">327 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">1</span></div></div></header><div class="post-body" itemprop="articleBody"><p>关于maven中执行类遇到的<code>java.lang.NoClassDefFoundError</code>的问题</p><p>&lt;!-- more --&gt;</p><p>昨天有个同事问我，在Flink某个包中加了一个类用来进行测试，结果运行就会报如下错误</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/flink/api/common/serialization/DeserializationSchema</span><br><span class="line">	at com.didi.flink.app.FlinkTableSinkTest.main(FlinkTableSinkTest.scala)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.flink.api.common.serialization.DeserializationSchema</span><br><span class="line">	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">	... 1 more</span><br></pre></td></tr></table></figure><p></p><p>排查后怀疑是pom中该jar的依赖scope是provided导致的,测试删除后就解决了。</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;flink-streaming-java_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</span><br><span class="line">	&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><p>但是觉得这样会很麻烦，所有其他用到的类都需要去除provided了？顺手Google了一下，Stack Overflow上有人问过同样的问题（这个人竟然是之前blink meetup上的flink+zeppelin的演讲者<em>章剑锋（简锋）</em>）</p><p><a href="https://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij" target="_blank" rel="noopener">https://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij</a></p><p>简单的说是因为provided的scope只在编译期和test期间有效，所以正确的姿势应该是测试类就放在测试包下面测试，这样provided的包依然是有效的</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/2019-flag.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2019-flag.html" itemprop="url">to be or not to be in 2019</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T01:25:03+08:00">2019-03-15 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/杂七杂八/" itemprop="url" rel="index"><span itemprop="name">杂七杂八</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2019-flag.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019-flag.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">100 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">1</span></div></div></header><div class="post-body" itemprop="articleBody"><p>2019年的flag</p><p>&lt;!-- more --&gt;</p><p>2019年的Q1快接近尾声了，是时候给今年来一个flag了，今年有以下3个目标：</p><ol><li>跑步500公里</li><li>读书10本+ <em>技术书籍不低于3本</em></li><li>flink，netty，hbase系列的源码分析博客及仓库更新</li><li>机器学习简单入门</li><li>简单学会尤克里里的弹奏</li><li>努力工作，攒钱</li></ol><p>截止时间:</p><p>-----------------------------------2020.01.01-----------------------------------------------</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/string-stringbuilder-stringbuffer.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/string-stringbuilder-stringbuffer.html" itemprop="url">String,StringBuffer,StringBuilder的区别</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-28T00:13:48+08:00">2018-08-28 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/源码分析/" itemprop="url" rel="index"><span itemprop="name">源码分析</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/string-stringbuilder-stringbuffer.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="string-stringbuilder-stringbuffer.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.7k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">6</span></div></div></header><div class="post-body" itemprop="articleBody"><p>常用的jdk的组件的源码分析之：<code>String</code>,<code>StringBuffer</code>,<code>StringBuilder</code></p><p>&lt;!-- more --&gt;</p><p>String 字符串常量 StringBuffer 字符串变量（线程安全） StringBuilder 字符串变量（非线程安全）</p><p>String和StringBuffer的主要性能区别其实在于 String是不可变的对象, 因此在每次对String类型进行改变的时候其实都等同于生成了一个新的 String对象，然后将指针指向新的String对象，所以经常改变内容的字符串最好不要用String，因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后，JVM的GC就会开始工作，那速度是一定会相当慢的。</p><p>那么String为什么要是不可变的呢？</p><h3>String类不可变的好处</h3><ol><li>只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现，String interning是指对不同的字符串仅仅只保存一个，即不会保存多个相同的字符串。因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。</li><li>如果字符串是可变的，那么会引起很严重的安全问题。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变字符串指向的对象的值，造成安全漏洞。</li><li>因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。</li><li>类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。譬如你想加载java.sql.Connection类，而这个值被改成了myhacked.Connection，那么会对你的数据库造成不可知的破坏。</li><li>因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。也同时指出一个理念，千万不要把可变类型作为HashMap和HashSet的键值</li></ol><h3>在java中如何设计不可变</h3><ol><li>对于属性不提供设值的方法</li><li>所有的属性定义为private final</li><li>类声明为final不允许继承</li><li>return deep cloned objects with copied content for all mutable fields in class</li></ol><p>翻看string的源码，可以看到string的本质是个char数组，并且使用final关键字修饰。但是char数组用final修饰只能让数组的引用地址不变，array数组还是可变的，主要是SUN的工程师没有暴露内部成员字段，所以String不可变主要在底层实现，而不是在final。</p><h3>String的内存存储</h3><p>一般而言，Java 对象在虚拟机的结构如下：</p><ul><li>对象头（object header）：8 个字节</li><li>Java 原始类型数据：如 int, float, char 等类型的数据，各类型数据占内存。<ul><li>boolean 1</li><li>byte</li><li>char 2</li><li>short</li><li>int 4</li><li>long 8</li></ul></li><li>引用（reference）：4 个字节</li><li>填充符（padding）</li></ul><p>然而，一个 Java 对象实际还会占用些额外的空间，如：对象的 class 信息、ID、在虚拟机中的状态。在 Oracle JDK 的 Hotspot 虚拟机中，一个普通的对象需要额外 8 个字节。</p><p>String对象的声明</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private final char value[]; </span><br><span class="line">private final int offset; </span><br><span class="line">private final int count; </span><br><span class="line">private int hash;</span><br></pre></td></tr></table></figure><p></p><p>那么因该如何计算该 String 所占的空间？</p><p>首先计算一个空的 char 数组所占空间，在 Java 里数组也是对象，因而数组也有对象头，故一个数组所占的空间为对象头所占的空间加上数组长度，即 8 + 4 = 12 字节 , 经过填充后为 16 字节。</p><p>那么一个空 String 所占空间为：</p><p>对象头（8 字节）+ char 数组（16 字节）+ 3 个 int（3 × 4 = 12 字节）+1 个 char 数组的引用 (4 字节 ) = 40 字节。</p><p>因此一个实际的 String 所占空间的计算公式如下：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8*( ( 8+2*n+4+12)+7 ) / 8 = 8*(int) ( ( ( (n) *2 )+43) /8 )</span><br></pre></td></tr></table></figure><p></p><p>在java中对String对象特殊对待，所以在heap上分为两块，一块是String constant pool存储java字符串常量，另一块存储普通对象和字符串对象，主要区别：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String a = &quot;abc&quot;;</span><br><span class="line">String b = new String(&quot;acb&quot;)</span><br></pre></td></tr></table></figure><p></p><p>第一种jvm会先去查找constant pool是否存在此常量，不存在就在constant pool上进行创建，第二种是在堆上创建对象，并且不会加入到constant pool上，因此可能会带来字符串重复占用内存的问题。可以调用String.intern()加入到String constant pool中，其实是JVM heap 中 PermGen 相应的区域。</p><p>jdk1.6和1.7还有所不同，jdk1.7的常量池是在堆中的</p><h3>StringBuffer</h3><p>StringBuffer和String不同，每次修改都会对 StringBuffer 对象本身进行操作，而不是生成新的对象，再改变对象引用。所以在一般情况下我们推荐使用 StringBuffer ，特别是字符串对象经常改变的情况下。而在某些特别情况下， String 对象的字符串拼接其实是被JVM解释成了 StringBuffer 对象的拼接，所以这些时候 String 对象的速度并不会比 StringBuffer 对象慢，而特别是以下的字符串对象生成中， String效率是远要比 StringBuffer 快的：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String S1 = “This is only a” + “ simple” + “ test”;</span><br><span class="line">StringBuffer Sb = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);</span><br></pre></td></tr></table></figure><p></p><p>你会很惊讶的发现，生成 String S1 对象的速度简直太快了，而这个时候 StringBuffer 居然速度上根本一点都不占优势。其实这是 JVM 的一个把戏，在 JVM 眼里，这个</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String S1 = “This is only a” + “ simple” + “test”;</span><br><span class="line">其实就是：</span><br><span class="line">String S1 = “This is only a simple test”;</span><br></pre></td></tr></table></figure><p></p><p>当然不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的 String 对象的话，速度就没那么快了，譬如：</p><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String S2 = “This is only a”;</span><br><span class="line">String S3 = “ simple”;</span><br><span class="line">String S4 = “ test”;</span><br><span class="line">String S1 = S2 +S3 + S4;</span><br></pre></td></tr></table></figure><p></p><p>这时候 JVM 会规规矩矩的按照原来的方式去做</p><p><a href="https://www.ibm.com/developerworks/cn/java/j-lo-optmizestring/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/java/j-lo-optmizestring/index.html</a></p><p><a href="https://blog.csdn.net/qq_36357995/article/details/79985538" target="_blank" rel="noopener">https://blog.csdn.net/qq_36357995/article/details/79985538</a></p><p><a href="https://segmentfault.com/a/1190000004261063" target="_blank" rel="noopener">https://segmentfault.com/a/1190000004261063</a></p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://www.aitozi.com/rocksdb-wiki.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="aitozi"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Aitozi"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a class="post-title-link" href="/rocksdb-wiki.html" itemprop="url">rocksdb概念简介</a></h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-23T23:20:44+08:00">2018-08-23 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/刨根问底/" itemprop="url" rel="index"><span itemprop="name">刨根问底</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/rocksdb-wiki.html#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="rocksdb-wiki.html" itemprop="commentCount"></span> </a><span class="post-meta-divider">|</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计</span> <span title="字数统计">1.6k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长</span> <span title="阅读时长">5</span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文翻译自：https://github.com/facebook/rocksdb/wiki/rocksdb-basics</p><p>主要是rocksdb的一些概念理解和介绍</p><p>&lt;!-- more --&gt;</p><p>rocksdb主要组成部分memtable,sstfile,logfile，rocksdb 支持将database切分成多个columnFamily，所有的数据库创建如果没有指定的话会是一个default column 他支持批量原子写入，key和value都是纯byte流，key和value的大小都没有做限制</p><p>所有database中的数据都是以一个有序的形式被放置（怎么做的呢？后append的数据怎么有序），应用可以指定key的comparison方法，来指定key的排序方式，Iterator API可以在database做一个RangeScan操作，他会指向一个特定的key，然后进行一个一个遍历。在调用iterator的时候会创建database的即时视图，因此所有查询的key都是一致的。</p><h3>Snapshot</h3><p>Snapshot Api也支持创建database某一时间点的视图，Get和Iterator Api可以用以读取指定snapshot的数据，从某种意义上说，snapshot和iterator都会提供database的当前视图，但是他们的实现不同。iterator是短期的/前台线程的scan，而长期/后台的scan最好是通过snapshot。iterator会对所有底层与pint-in-time database视图相关的的文件保留一个引用计数，这些文件知道iterator结束之后才会被删除。然而snapshot不会阻碍文件的删除，取而代之的是在compaction的过程会意识到snapshots的存在，直接不会删除在已经存在于snapshot中的key。snapshot在database重启的会丢失，reload rocksdb library会释放所有的snapshot</p><h3>Prefix Iterators</h3><p>大多数基于LSM设计的存储引擎都不太能支持高效的RangeScan API，因为他需要查阅每个文件，但是真正的应用并不是纯粹的随机读取key，一般会以一个key-prefix去查询，rocksdb利用了这个特点做了一些优化。应用可以配置prefix_extractor来指定key-prefix，rocksdb决定，存储的blooms，iterator可以通过ReadOptios指定prefix，然后rocksDB将会使用这些bloom bits来避免查询那些不包含那些key-perfix开始的key的文件。</p><h3>Persistence</h3><p>rocksdb有一个事务日志，所有的puts操作会被存储在memtables中，同时也会可选的写入事务日志中，在重启的时候，会重新执行事务日志中的记录。事务日志可以配置和sst文件放在不同的目录。这是因为有时你并不想持久化数据文件，同时又可以将事务日志持久化到一个相对较慢的持久化存储中，来确保数据不会丢失。 每一个Put都有一个标志，通过WriteOptios来标志是否需要写入事务日志中，同时也可以配置是否需要同步等到数据已经被写入到事务日志完成之后才将Put操作标记为commit完成。</p><p>在内部实现中，RocksDB会使用batch-commit的机制去批量的将事务操作提交到事务日志中，所以在一次同步调用中会提交多个transactions</p><h3>Fault Tolerance</h3><p>Rocksdb使用checksum去检测存储是否有损坏</p><h3>Multi-Threaded Compactions</h3><p>compaction的存在是为了删除同一个key的多个副本，这种情况发生在用户更新了某个key的值，compaction也负责将要删除的key进行删除。整个database是存储在sstable中的，当memtable满了的时候会写入到Level-0（L0）的文件中，RocksDB在将数据从memtable flush到文件的时候会先将重复的key进行删除。然后一些文件会周期性的读入并形成更大的文件，这就是compaction的过程。</p><p>对于一个LSM的database的写入的吞吐量取决于compaction所能达到的速度，特别是数据存储在ssd或者RAM中。RocksDB可以配置为启用多个并发compaction线程。据观察，与单线程compaction相比，基于ssd的数据库的持续写入速率可能在多线程compaction的情况下增加10倍之多</p><h3>compaction Styles</h3><p>通常的style的compaction是完全基于排序的，运行与L0文件或者L1+. Compaction会挑选一些按时间顺序相邻文件，然后将其合并成一个新的sstable</p><p>level style compaction在数据库存储会分为多个等级，最近的数据存储在L0层，最老的数据存储在Lmax层，只有L0层会存在重叠的key，一次compaction会将Ln的file和Ln+1的file做compaction然后形成新的文件替换Ln+1的文件，Universal Style 和Level style相比通常会有较低的写入放大但是较高的磁盘占用和读放大</p><p>（写入放大）： https://www.zhihu.com/question/31024021 https://www.wikiwand.com/zh-hans/%E5%86%99%E5%85%A5%E6%94%BE%E5%A4%A7</p><p>同时RocksDB也支持用户自定义compaction方式，可以通过<code>Options.disable_auto_compaction</code>关闭原生的compaction算法，同时<code>GetLiveFilesMetaData</code>接口可以让外置组件查看每一个database中的数据文件从而决定哪些数据需要merge和合并。通过调用<code>CompactFiles</code>来进行文件的合并，<code>DeleteFile</code>来进行文件的删除</p><h3>metadata storage</h3><p>数据库中的MANIFEST文件记录了数据库的状态，compaction线程会新增新文件，删除旧文件，这些操作会通过 MANIFEST记录来持久化，同样记录操作也是用了batch-commit的算法来缓冲重复的对MANIFEST文件的同步写入</p><h3>Avoiding Stalls</h3><p>后台的compaction线程会将memtable中的内容flush到文件中，如果所有的后台线程都忙着做长时间的compaction，那么突然一个大流量的写入可能就会把memtable写满，这就会导致新的写入被hung住，这个问题可以通过配置rocksdb保持特定的几个线程专门保留来进行flush操作</p><h3>Compaction Filter</h3><p>一些应用可能在compaction的时候可能期望对key做出一些处理，比如数据库内部实现可能需要支持TTL，来删除过期的key，这可以通过自定义实现compaction filter来实现。他提供了用户在compaction的过程中修改key value以及丢弃这个key的数据的能力</p><h3>Read only mode</h3><p>database可以以read only的模式打开这样数据库保证所有的数据都不可修改，同时也会极大的提升读性能，因为完全了避免了锁</p><h3>Full Backups, Incremental Backups and Replication</h3><p>RocksDB支持增量的备份，BackupableDB使得Rocksdb的备份很简单，后续会深入介绍</p><p>增量的复制需要能够找到数据库最近的改变，GetUpdatesSince API支持应用tail最近的事务日志，因此他能够连续的获取事务日志，然后将其应用于远程的复制或者备份</p><p>未完待续</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article></section><nav class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="aitozi"><p class="site-author-name" itemprop="name">aitozi</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">27</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">9</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">15</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="gjying1314@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-globe"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://wuchong.me/" title="wuchong" target="_blank">wuchong</a></li><li class="links-of-blogroll-item"><a href="http://chenyuzhao.me/" title="yuzhao" target="_blank">yuzhao</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/yanghua_kobe?viewmode=contents" title="vinoyang" target="_blank">vinoyang</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/lmalds?viewmode=contents" title="Imalds" target="_blank">Imalds</a></li><li class="links-of-blogroll-item"><a href="http://blog.csdn.net/androidlushangderen" title="hadoop" target="_blank">hadoop</a></li><li class="links-of-blogroll-item"><a href="http://www.cnblogs.com/xrq730/p/5260294.html" title="java开发" target="_blank">java开发</a></li><li class="links-of-blogroll-item"><a href="http://www.hollischuang.com/" title="阿里工程师" target="_blank">阿里工程师</a></li><li class="links-of-blogroll-item"><a href="http://www.cnblogs.com/fxjwind/" title="阿里流计算工程师" target="_blank">阿里流计算工程师</a></li><li class="links-of-blogroll-item"><a href="http://jm.taobao.org/" title="阿里中间件博客" target="_blank">阿里中间件博客</a></li><li class="links-of-blogroll-item"><a href="http://armsword.com/" title="duruofei" target="_blank">duruofei</a></li><li class="links-of-blogroll-item"><a href="http://blog.yufeng.info/" title="褚霸" target="_blank">褚霸</a></li><li class="links-of-blogroll-item"><a href="https://yuzhouwan.com" title="宇宙湾" target="_blank">宇宙湾</a></li><li class="links-of-blogroll-item"><a href="http://matt33.com" title="matt" target="_blank">matt</a></li><li class="links-of-blogroll-item"><a href="http://coding-geek.com/" title="coding-geek" target="_blank">coding-geek</a></li></ul></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">aitozi</span></div><div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div><div class="theme-info">主题 - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user"></i> <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="site-pv"><i class="fa fa-eye"></i> <span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/jquery.lazyload/1.9.3/jquery.lazyload.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><script id="dsq-count-scr" src="https://aitozi.disqus.com/count.js" async></script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script></body></html><!-- rebuild by neat -->